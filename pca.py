import streamlit as st
import numpy as np
import pandas as pd
from sklearn.datasets import fetch_openml
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import plotly.express as px
import mlflow
import mlflow.sklearn
import matplotlib.pyplot as plt
import os
import time

# Thi·∫øt l·∫≠p logging v·ªõi MLflow
mlflow.set_tracking_uri("file:./mlruns")

# T·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML
@st.cache_data
def load_mnist_data():
    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)
    return X, y

# L·∫•y m·∫´u d·ªØ li·ªáu ng·∫´u nhi√™n
def sample_data(X, y, sample_size):
    if sample_size > len(X):
        sample_size = len(X)
    indices = np.random.choice(len(X), sample_size, replace=False)
    return X[indices], y[indices]

# H√†m gi·∫£m chi·ªÅu b·∫±ng PCA
def apply_pca(X, n_components):
    pca = PCA(n_components=n_components)
    X_reduced = pca.fit_transform(X)
    explained_variance = np.sum(pca.explained_variance_ratio_)
    return X_reduced, explained_variance

# H√†m gi·∫£m chi·ªÅu b·∫±ng t-SNE
def apply_tsne(X, n_components, perplexity, learning_rate):
    tsne = TSNE(n_components=n_components, perplexity=perplexity, learning_rate=learning_rate, random_state=42)
    X_reduced = tsne.fit_transform(X)
    return X_reduced

# V·∫Ω bi·ªÉu ƒë·ªì ph√¢n t√°n
def plot_scatter(X_reduced, y, title):
    df = pd.DataFrame({
        'x': X_reduced[:, 0],
        'y': X_reduced[:, 1],
        'label': y
    })
    fig = px.scatter(df, x='x', y='y', color='label', title=title,
                     labels={'x': 'Component 1', 'y': 'Component 2'})
    return fig

def main():
    st.title("Gi·∫£m Chi·ªÅu D·ªØ Li·ªáu MNIST v·ªõi PCA v√† t-SNE")
    
    # T·∫°o c√°c tab
    tab1, tab2, tab3 = st.tabs(["T·ªïng quan", "Ph∆∞∆°ng ph√°p PCA v√† t-SNE", "MLflow"])

    # Tab 1: T·ªïng quan
    with tab1:
        X, y = load_mnist_data()
        # Hi·ªÉn th·ªã nhi·ªÅu ·∫£nh m·∫´u
        st.subheader("M·ªôt s·ªë ·∫£nh m·∫´u t·ª´ t·∫≠p d·ªØ li·ªáu MNIST")
        
        # S·ªë l∆∞·ª£ng ·∫£nh mu·ªën hi·ªÉn th·ªã
        num_samples = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh m·∫´u", 1, 20, 5)
        
        # T·∫°o c√°c c·ªôt ƒë·ªÉ hi·ªÉn th·ªã ·∫£nh
        cols = st.columns(5)  # Hi·ªÉn th·ªã t·ªëi ƒëa 5 ·∫£nh tr√™n m·ªôt h√†ng
        
        for i in range(num_samples):
            with cols[i % 5]:  # Chia ·∫£nh v√†o c√°c c·ªôt
                st.image(X[i].reshape(28, 28), caption=f"Ch·ªØ s·ªë {y[i]}", width=100)

        st.subheader("üîπThu·∫≠t to√°n gi·∫£m chi·ªÅu d·ªØ li·ªáu")
        st.write("##### 1. PCA (Principal Component Analysis)")
        st.write("""- PCA l√† m·ªôt ph∆∞∆°ng ph√°p gi·∫£m chi·ªÅu d·ªØ li·ªáu (dimensionality reduction) t∆∞∆°ng ƒë·ªëi hi·ªáu qu·∫£ d·ª±a tr√™n ph√©p ph√¢n t√≠ch
         suy bi·∫øn (singular decomposition) m√† ·ªü ƒë√≥ ch√∫ng 
         ta s·∫Ω chi·∫øu c√°c ƒëi·ªÉm d·ªØ li·ªáu trong kh√¥ng gian cao chi·ªÅu xu·ªëng m·ªôt s·ªë √≠t
         nh·ªØng v√©c t∆° th√†nh ph·∫ßn ch√≠nh trong kh√¥ng gian th·∫•p chi·ªÅu
         m√† ƒë·ªìng th·ªùi v·∫´n b·∫£o to√†n t·ªëi ƒëa ƒë·ªô bi·∫øn ƒë·ªông c·ªßa d·ªØ li·ªáu sau bi·∫øn ƒë·ªïi. ∆Øu ƒëi·ªÉm c·ªßa PCA ƒë√≥ l√†
         s·ª≠ d·ª•ng t·∫•t c·∫£ c√°c bi·∫øn ƒë·∫ßu v√†o n√™n ph∆∞∆°ng ph√°p n√†y kh√¥ng b·ªè s√≥t nh·ªØng bi·∫øn quan tr·ªçng.""")
        st.write("- C√°c b∆∞·ªõc th·ª±c hi·ªán PCA :")
        st.image("p1.png")
        st.image("p2.png")
        st.write("##### 2. t-SNE (t-Distributed Stochastic Neighbor Embedding) ")
        st.write("""-  t-SNE l√† x√°c ƒë·ªãnh m·ªôt h√†m ph√¢n ph·ªëi x√°c su·∫•t chung d·ª±a tr√™n Gaussian cho c√°c ƒëi·ªÉm d·ªØ li·ªáu chi·ªÅu cao, x√°c ƒë·ªãnh m·ªôt h√†m ph√¢n ph·ªëi x√°c su·∫•t 
        chung d·ª±a tr√™n ph√¢n ph·ªëi t cho c√°c ƒëi·ªÉm d·ªØ li·ªáu chi·ªÅu th·∫•p v√† sau ƒë√≥ s·∫Øp x·∫øp l·∫°i d·ªØ li·ªáu chi·ªÅu th·∫•p ƒëi·ªÉm ƒë·ªÉ gi·∫£m ƒë·ªô ch√™nh l·ªách (v·ªÅ KL ph√¢n k√¨) gi·ªØa hai l·∫ßn ph√¢n b·ªë. """)
        st.write("C√°c b∆∞·ªõc th·ª±c hi·ªán t-SNE :")
        st.write("""+ B∆∞·ªõc 1: t-SNE m√¥ h√¨nh h√≥a m·ªôt ƒëi·ªÉm ƒë∆∞·ª£c ch·ªçn l√†m l√¢n c·∫≠n c·ªßa m·ªôt ƒëi·ªÉm kh√°c ·ªü c·∫£ chi·ªÅu cao h∆°n v√† chi·ªÅu th·∫•p h∆°n. N√≥ b·∫Øt ƒë·∫ßu b·∫±ng c√°ch t√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng t·ª´ng c·∫∑p gi·ªØa
        t·∫•t c·∫£ c√°c ƒëi·ªÉm d·ªØ li·ªáu trong kh√¥ng gian chi·ªÅu cao b·∫±ng c√°ch s·ª≠ d·ª•ng h·∫°t nh√¢n Gaussian. C√°c ƒëi·ªÉm xa nhau c√≥ x√°c su·∫•t ƒë∆∞·ª£c ch·ªçn th·∫•p h∆°n c√°c ƒëi·ªÉm g·∫ßn nhau. """)
        st.write("+ B∆∞·ªõc 2: Sau ƒë√≥, thu·∫≠t to√°n s·∫Ω c·ªë g·∫Øng √°nh x·∫° c√°c ƒëi·ªÉm d·ªØ li·ªáu c√≥ chi·ªÅu cao h∆°n v√†o kh√¥ng gian c√≥ chi·ªÅu th·∫•p h∆°n trong khi v·∫´n b·∫£o to√†n c√°c ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng theo t·ª´ng c·∫∑p.")  
        st.write("""+ B∆∞·ªõc 3: N√≥ ƒë·∫°t ƒë∆∞·ª£c b·∫±ng c√°ch gi·∫£m thi·ªÉu s·ª± ph√¢n k·ª≥ gi·ªØa ph√¢n ph·ªëi x√°c su·∫•t chi·ªÅu cao ban ƒë·∫ßu v√† chi·ªÅu th·∫•p ban ƒë·∫ßu. Thu·∫≠t to√°n s·ª≠ d·ª•ng gradient descent ƒë·ªÉ gi·∫£m thi·ªÉu s·ª± 
        ph√¢n k·ª≥. Nh√∫ng chi·ªÅu th·∫•p ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a ƒë·∫øn tr·∫°ng th√°i ·ªïn ƒë·ªãnh.""")

    # Tab 2: Ph∆∞∆°ng ph√°p PCA v√† t-SNE
    with tab2:
        st.header("Ph∆∞∆°ng ph√°p PCA v√† t-SNE")

        # T·∫£i d·ªØ li·ªáu
        X, y = load_mnist_data()

        # T√πy ch·ªçn m·∫´u d·ªØ li·ªáu
        st.subheader("T√πy ch·ªçn m·∫´u d·ªØ li·ªáu")
        sample_size = st.slider("Ch·ªçn k√≠ch th∆∞·ªõc m·∫´u d·ªØ li·ªáu", 100, 10000, 1000, key="sample_size_tab2")
        X_sample, y_sample = sample_data(X, y, sample_size)
        st.write(f"K√≠ch th∆∞·ªõc d·ªØ li·ªáu sau khi l·∫•y m·∫´u: {X_sample.shape}")

        # Nh·∫≠p t√™n th√≠ nghi·ªám
        experiment_name = st.text_input("Nh·∫≠p t√™n th√≠ nghi·ªám")
        if not experiment_name:
            experiment_name = "Default_Model"
        mlflow.set_experiment(experiment_name)

        # Ch·ªçn ph∆∞∆°ng ph√°p gi·∫£m chi·ªÅu
        method = st.selectbox("Ch·ªçn ph∆∞∆°ng ph√°p gi·∫£m chi·ªÅu", ["PCA", "t-SNE"], key="method_tab2")

        # Tham s·ªë cho t·ª´ng ph∆∞∆°ng ph√°p
        if method == "PCA":
            n_components = st.slider("S·ªë l∆∞·ª£ng th√†nh ph·∫ßn PCA", 2, 50, 2, key="n_components_tab2")
        elif method == "t-SNE":
            n_components = 2
            perplexity = st.slider("Perplexity", 5, 50, 30, key="perplexity_tab2",help="""**Perplexity** : Tham s·ªë ki·ªÉm so√°t s·ªë l∆∞·ª£ng ƒëi·ªÉm l√¢n c·∫≠n m√† t-SNE xem x√©t khi x√¢y d·ª±ng ph√¢n ph·ªëi x√°c su·∫•t trong kh√¥ng gian nhi·ªÅu chi·ªÅu. 
            \n- Perplexity th·∫•p (5-10), t·∫≠p trung v√†o c√°c ƒëi·ªÉm l√¢n c·∫≠n g·∫ßn nh·∫•t, t·∫°o ra c√°c c·ª•m nh·ªè v√† chi ti·∫øt h∆°n , c√≥ th·ªÉ d·∫´n ƒë·∫øn vi·ªác ph√¢n t√°ch qu√° m·ª©c.
            \n- Perplexity cao (40-50), xem x√©t nhi·ªÅu ƒëi·ªÉm l√¢n c·∫≠n h∆°n,t·∫°o ra c√°c c·ª•m l·ªõn h∆°n v√† t·ªïng qu√°t h∆°n, c√≥ th·ªÉ l√†m m·∫•t ƒëi c√°c chi ti·∫øt nh·ªè trong d·ªØ li·ªáu.
            """)
            learning_rate = st.slider("Learning Rate", 10, 1000, 200, key="learning_rate_tsne",help=""" **learning_rate** : T·ªëc ƒë·ªô h·ªçc c·ªßa thu·∫≠t to√°n t-SNE, ki·ªÉm so√°t c√°ch thu·∫≠t to√°n c·∫≠p nh·∫≠t c√°c ƒëi·ªÉm trong kh√¥ng gian chi·ªÅu th·∫•p.
            \n- Learning rate th·∫•p (10-100):Thu·∫≠t to√°n h·ªçc ch·∫≠m h∆°n, c√≥ th·ªÉ d·∫´n ƒë·∫øn k·∫øt qu·∫£ kh√¥ng ·ªïn ƒë·ªãnh ho·∫∑c kh√¥ng h·ªôi t·ª•.
            \n- Learning rate cao (500-1000):Thu·∫≠t to√°n h·ªçc nhanh h∆°n, c√≥ th·ªÉ d·∫´n ƒë·∫øn vi·ªác c√°c ƒëi·ªÉm "nh·∫£y" qu√° m·ª©c, l√†m m·∫•t ƒëi c·∫•u tr√∫c c·ª•m.
            """)

        # N√∫t b·∫•m gi·∫£m chi·ªÅu
        if st.button("Gi·∫£m chi·ªÅu", key="reduce_button_tab2"):
            with st.spinner("ƒêang th·ª±c hi·ªán gi·∫£m chi·ªÅu..."):
                start_time = time.time()
                if method == "PCA":
                    with mlflow.start_run(run_name=f"PCA_{n_components}_components"):
                        X_reduced, explained_variance = apply_pca(X_sample, n_components)
                        st.write(f"T·ª∑ l·ªá ph∆∞∆°ng sai gi·∫£i th√≠ch: {explained_variance:.4f}")
                        
                        # Logging v·ªõi MLflow
                        mlflow.log_param("method", "PCA")
                        mlflow.log_param("n_components", n_components)
                        mlflow.log_param("sample_size", sample_size)
                        mlflow.log_metric("explained_variance", explained_variance)
                        
                        # Visual h√≥a
                        fig = plot_scatter(X_reduced, y_sample, f"PCA - {n_components} Components")
                        st.plotly_chart(fig)

                elif method == "t-SNE":
                    with mlflow.start_run(run_name=f"t-SNE_perplexity_{perplexity}"):
                        X_reduced = apply_tsne(X_sample, n_components, perplexity, learning_rate)
                        
                        # Logging v·ªõi MLflow
                        mlflow.log_param("method", "t-SNE")
                        mlflow.log_param("n_components", n_components)
                        mlflow.log_param("perplexity", perplexity)
                        mlflow.log_param("sample_size", sample_size)
                        mlflow.log_param("learning_rate", learning_rate)
                        
                        # Visual h√≥a
                        fig = plot_scatter(X_reduced, y_sample, f"t-SNE - Perplexity: {perplexity}")
                        st.plotly_chart(fig)
                
                # ƒêo th·ªùi gian th·ª±c thi
                execution_time = time.time() - start_time
                # st.write(f"Th·ªùi gian th·ª±c thi: {execution_time:.2f} gi√¢y")
                mlflow.log_metric("execution_time", execution_time)
            
            time.sleep(1)
            st.success(f"ƒê√£ ho√†n th√†nh gi·∫£m chi·ªÅu v√† l∆∞u v√†o th√≠ nghi·ªám '{experiment_name}'!")

    # Tab 3: MLflow
    with tab3:
        st.header("MLflow Tracking")
        st.write("Ch·ªçn m·ªôt th√≠ nghi·ªám v√† m·ªôt k·∫øt qu·∫£ ƒë·ªÉ xem chi ti·∫øt.")

        # L·∫•y danh s√°ch experiment
        experiments = mlflow.search_experiments()
        experiment_names = [exp.name for exp in experiments]
        experiment_dict = {exp.name: exp.experiment_id for exp in experiments}

        if not experiment_names:
            st.write("Ch∆∞a c√≥ th√≠ nghi·ªám n√†o ƒë∆∞·ª£c l∆∞u.")
        else:
            # Ch·ªçn th√≠ nghi·ªám
            selected_experiment = st.selectbox("Ch·ªçn th√≠ nghi·ªám", experiment_names, key="select_exp_tab3")
            selected_exp_id = experiment_dict[selected_experiment]

            # T√¨m ki·∫øm theo t·ª´ kh√≥a trong experiment ƒë√£ ch·ªçn
            search_query = st.text_input("T√¨m ki·∫øm trong th√≠ nghi·ªám (theo ph∆∞∆°ng ph√°p, ...)", "", key="search_tab3")
            runs = mlflow.search_runs(experiment_ids=[selected_exp_id])

            if not runs.empty:
                # Th√™m c·ªôt t√™n th√≠ nghi·ªám
                runs['experiment_name'] = selected_experiment
                
                # L·ªçc d·ªØ li·ªáu d·ª±a tr√™n t·ª´ kh√≥a
                if search_query:
                    runs = runs[runs.apply(lambda row: search_query.lower() in str(row).lower(), axis=1)]
                
                st.write(f"T√¨m th·∫•y {len(runs)} k·∫øt qu·∫£ trong th√≠ nghi·ªám '{selected_experiment}'.")
                # Hi·ªÉn th·ªã danh s√°ch run
                available_columns = [col for col in ['run_id', 'experiment_name', 'start_time', 'params.method', 
                                                    'params.n_components', 'params.perplexity', 'params.sample_size', 
                                                    'metrics.explained_variance', 'params.learning_rate', 
                                                    'metrics.execution_time'] if col in runs.columns]
                st.dataframe(runs[available_columns])

                # Ch·ªçn m·ªôt run ƒë·ªÉ xem chi ti·∫øt
                run_ids = runs['run_id'].tolist()
                selected_run_id = st.selectbox("Ch·ªçn m·ªôt k·∫øt qu·∫£ (run) ƒë·ªÉ xem chi ti·∫øt", run_ids, key="select_run_tab3")
                
                if selected_run_id:
                    selected_run = runs[runs['run_id'] == selected_run_id].iloc[0]
                    st.subheader(f"Chi ti·∫øt c·ªßa Run ID: {selected_run_id}")
                    
                    # Hi·ªÉn th·ªã th√¥ng tin chung
                    st.write("**Th√¥ng tin chung:**")
                    general_info = {
                        'Run ID': selected_run['run_id'],
                        'Experiment Name': selected_run['experiment_name']
                    }
                    for key, value in general_info.items():
                        if pd.notna(value):
                            st.write(f"{key}: {value}")

                    # Hi·ªÉn th·ªã th√¥ng tin li√™n quan ƒë·∫øn ph∆∞∆°ng ph√°p
                    st.write("**Th√¥ng tin li√™n quan ƒë·∫øn ph∆∞∆°ng ph√°p:**")
                    method = selected_run.get('params.method', 'N/A')
                    if method == "PCA":
                        method_info = {
                            'Ph∆∞∆°ng ph√°p': method,
                            'S·ªë l∆∞·ª£ng th√†nh ph·∫ßn (n_components)': selected_run.get('params.n_components', 'N/A'),
                            'T·ª∑ l·ªá ph∆∞∆°ng sai gi·∫£i th√≠ch (explained_variance)': selected_run.get('metrics.explained_variance', 'N/A'),
                            'K√≠ch th∆∞·ªõc m·∫´u (sample_size)': selected_run.get('params.sample_size', 'N/A'),
                        }
                    elif method == "t-SNE":
                        method_info = {
                            'Ph∆∞∆°ng ph√°p': method,
                            'Perplexity': selected_run.get('params.perplexity', 'N/A'),
                            'Learning Rate': selected_run.get('params.learning_rate', 'N/A'),
                            'S·ªë l∆∞·ª£ng th√†nh ph·∫ßn (n_components)': selected_run.get('params.n_components', 'N/A'),
                            'K√≠ch th∆∞·ªõc m·∫´u (sample_size)': selected_run.get('params.sample_size', 'N/A'),
                        }
                    else:
                        method_info = {'Ph∆∞∆°ng ph√°p': 'Kh√¥ng x√°c ƒë·ªãnh'}

                    for key, value in method_info.items():
                        if pd.notna(value):
                            st.write(f"{key}: {value}")

            else:
                st.write(f"Ch∆∞a c√≥ run n√†o trong th√≠ nghi·ªám '{selected_experiment}'.")

if __name__ == "__main__":
    main()
