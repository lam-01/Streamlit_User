import streamlit as st
import numpy as np
import pandas as pd
from sklearn.datasets import fetch_openml
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import plotly.express as px
import mlflow
import mlflow.sklearn
import matplotlib.pyplot as plt
import os
import time
import plotly.graph_objects as go
import plotly.express as px
import matplotlib.pyplot as plt
from scipy.stats import linregress

# Thi·∫øt l·∫≠p logging v·ªõi MLflow
mlflow.set_tracking_uri("file:./mlruns")
# Disable MLflow autologging to prevent unintended runs
mlflow.sklearn.autolog(disable=True)

# T·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML
@st.cache_data
def load_mnist_data():
    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)
    return X, y

# L·∫•y m·∫´u d·ªØ li·ªáu ng·∫´u nhi√™n
def sample_data(X, y, sample_size):
    if sample_size > len(X):
        sample_size = len(X)
    indices = np.random.choice(len(X), sample_size, replace=False)
    return X[indices], y[indices]

# H√†m gi·∫£m chi·ªÅu b·∫±ng PCA v·ªõi ti·∫øn tr√¨nh
def apply_pca(X, n_components, progress_bar):
    progress_bar.progress(20)  # 20% sau khi b·∫Øt ƒë·∫ßu PCA
    pca = PCA(n_components=n_components)
    X_reduced = pca.fit_transform(X)
    explained_variance = np.sum(pca.explained_variance_ratio_)
    progress_bar.progress(60)  # 60% sau khi gi·∫£m chi·ªÅu xong
    return X_reduced, explained_variance

# H√†m gi·∫£m chi·ªÅu b·∫±ng t-SNE v·ªõi ti·∫øn tr√¨nh
def apply_tsne(X, n_components, progress_bar):
    progress_bar.progress(20)  # 20% sau khi b·∫Øt ƒë·∫ßu t-SNE
    tsne = TSNE(n_components=n_components, random_state=42)
    X_reduced = tsne.fit_transform(X)
    progress_bar.progress(60)  # 60% sau khi gi·∫£m chi·ªÅu xong
    return X_reduced

# V·∫Ω bi·ªÉu ƒë·ªì ph√¢n t√°n (2D ho·∫∑c 3D)
def plot_scatter(X_reduced, y, title):
    if X_reduced.shape[1] == 2:
        df = pd.DataFrame({
            'x': X_reduced[:, 0],
            'y': X_reduced[:, 1],
            'label': y
        })
        fig = px.scatter(df, x='x', y='y', color='label', title=title,
                         labels={'x': 'Component 1', 'y': 'Component 2'})
        return fig
    elif X_reduced.shape[1] == 3:
        df = pd.DataFrame({
            'x': X_reduced[:, 0],
            'y': X_reduced[:, 1],
            'z': X_reduced[:, 2],
            'label': y
        })
        fig = px.scatter_3d(df, x='x', y='y', z='z', color='label', title=title,
                            labels={'x': 'Component 1', 'y': 'Component 2', 'z': 'Component 3'})
        return fig
    return None

def main():
    st.title("Gi·∫£m Chi·ªÅu D·ªØ Li·ªáu MNIST v·ªõi PCA v√† t-SNE")
    
    if 'run_in_progress' not in st.session_state:
        st.session_state.run_in_progress = False
    if 'last_run_id' not in st.session_state:
        st.session_state.last_run_id = None

    tab1, tab2, tab3 = st.tabs(["T·ªïng quan", "PCA v√† t-SNE", "MLflow"])

    with tab1:
        algorithm =st.selectbox("Ch·ªçn thu·∫≠t to√°n:", ["PCA","t-SNE"])
        
        if algorithm == "PCA":
            st.write("##### Thu·∫≠t to√°n PCA")
            st.write("""**PCA (Principal Component Analysis)** l√† m·ªôt ph∆∞∆°ng ph√°p gi·∫£m chi·ªÅu d·ªØ li·ªáu tuy·∫øn t√≠nh, t√¨m ra c√°c th√†nh ph·∫ßn ch√≠nh (principal components) ƒë·ªÉ chi·∫øu d·ªØ li·ªáu t·ª´ kh√¥ng gian chi·ªÅu cao xu·ªëng kh√¥ng gian chi·ªÅu th·∫•p h∆°n m√† v·∫´n gi·ªØ t·ªëi ƒëa th√¥ng tin (ph∆∞∆°ng sai).""")
            st.write("**C√°c b∆∞·ªõc th·ª±c hi·ªán PCA** :")
        
            # T·∫°o d·ªØ li·ªáu gi·∫£ l·∫≠p 2D
            st.write("üîπMinh h·ªça PCA tr√™n d·ªØ li·ªáu gi·∫£ l·∫≠p 2D")
            st.write("Ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng m·ªôt t·∫≠p d·ªØ li·ªáu 2D gi·∫£ l·∫≠p v·ªõi 300 ƒëi·ªÉm, ph√¢n b·ªë theo d·∫°ng elip nghi√™ng.")
        
            # T·∫°o d·ªØ li·ªáu gi·∫£ l·∫≠p
            np.random.seed(42)
            n_samples = 300
            cov = [[1, 0.8], [0.8, 1]]  # Ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai v·ªõi t∆∞∆°ng quan cao
            X_sim = np.random.multivariate_normal(mean=[0, 0], cov=cov, size=n_samples)
            y_sim = (X_sim[:, 0] + X_sim[:, 1] > 0).astype(int)
        
            # B∆∞·ªõc 1: Chu·∫©n h√≥a d·ªØ li·ªáu
            st.write("- **B∆∞·ªõc 1: Chu·∫©n h√≥a d·ªØ li·ªáu**")
            st.write("ƒê·ªìng nh·∫•t h√≥a thang ƒëo v√† m·ª©c ƒë·ªô bi·∫øn thi√™n c·ªßa c√°c bi·∫øn s·ªë, nh·∫±m lo·∫°i b·ªè s·ª± thi√™n l·ªách do kh√°c bi·ªát v·ªÅ ƒë∆°n v·ªã ho·∫∑c ph·∫°m vi gi√° tr·ªã, th·ª±c hi·ªán b·∫±ng c√¥ng th·ª©c Z-score:")
            st.latex(r"""
            X' = \frac{X - \mu}{\sigma}
            """)
            st.write("Trong ƒë√≥:")
            st.latex(r"""
            \begin{aligned}
            &X: \text{Gi√° tr·ªã g·ªëc c·ªßa d·ªØ li·ªáu} \\
            &\mu: \text{Trung b√¨nh c·ªßa m·ªói chi·ªÅu}, \quad \mu = \frac{1}{n} \sum_{i=1}^{n} X_i \\
            &\sigma: \text{ƒê·ªô l·ªách chu·∫©n c·ªßa m·ªói chi·ªÅu}, \quad \sigma = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (X_i - \mu)^2}
            \end{aligned}
            """)

            # Chu·∫©n h√≥a d·ªØ li·ªáu
            X_mean = X_sim.mean(axis=0)
            X_std = X_sim.std(axis=0)
            X_std[X_std == 0] = 1e-10  # Tr√°nh chia cho 0
            X_normalized = (X_sim - X_mean) / X_std
        
            # V·∫Ω d·ªØ li·ªáu tr∆∞·ªõc v√† sau chu·∫©n h√≥a
            fig, ax = plt.subplots(1, 2, figsize=(10, 4))
            ax[0].scatter(X_sim[:, 0], X_sim[:, 1], c=y_sim, cmap="viridis", alpha=0.6)
            ax[0].set_title("D·ªØ li·ªáu g·ªëc")
            ax[0].set_xlabel("X")
            ax[0].set_ylabel("Y")
            ax[0].grid(True)
        
            ax[1].scatter(X_normalized[:, 0], X_normalized[:, 1], c=y_sim, cmap="viridis", alpha=0.6)
            ax[1].set_title("D·ªØ li·ªáu sau chu·∫©n h√≥a")
            ax[1].set_xlabel("X (chu·∫©n h√≥a)")
            ax[1].set_ylabel("Y (chu·∫©n h√≥a)")
            ax[1].grid(True)
            plt.tight_layout()
            st.pyplot(fig)
            st.write("D·ªØ li·ªáu g·ªëc c√≥ ph√¢n b·ªë elip nghi√™ng. Sau chu·∫©n h√≥a h√¨nh d·∫°ng ph√¢n b·ªë kh√¥ng thay ƒë·ªïi.")
        
            # B∆∞·ªõc 2: T√≠nh ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai (Bi·ªÉu ƒë·ªì ph√¢n t√°n v·ªõi ƒë∆∞·ªùng h·ªìi quy)
            st.write("- **B∆∞·ªõc 2: T√≠nh ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai (Covariance Matrix)**")
            st.write("Ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai bi·ªÉu di·ªÖn m·ª©c ƒë·ªô t∆∞∆°ng quan gi·ªØa c√°c bi·∫øn:")
            st.latex(r"""
            \Sigma = \frac{1}{n-1} X^T X
            """)
            st.write("Trong ƒë√≥:")
            st.latex(r"""
            \begin{aligned}
            &X: \text{Ma tr·∫≠n d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a} \, (n \times d, \text{v·ªõi } n \text{ l√† s·ªë m·∫´u, } d \text{ l√† s·ªë chi·ªÅu}) \\
            &X^T: \text{Ma tr·∫≠n chuy·ªÉn v·ªã c·ªßa } X \\
            &\Sigma_{ij}: \text{Ph·∫ßn t·ª≠ t·∫°i h√†ng } i, \text{ c·ªôt } j \text{ l√† hi·ªáp ph∆∞∆°ng sai gi·ªØa chi·ªÅu } i \text{ v√† chi·ªÅu } j \\
            &\quad \Sigma_{ij} = \frac{1}{n-1} \sum_{k=1}^{n} (X_{ki} - \mu_i)(X_{kj} - \mu_j)
            \end{aligned}
            """)
            st.write("N·∫øu hai bi·∫øn c√≥ hi·ªáp ph∆∞∆°ng sai l·ªõn, ch√∫ng c√≥ xu h∆∞·ªõng thay ƒë·ªïi c√πng nhau. ƒê·ªÉ minh h·ªça, ch√∫ng ta v·∫Ω bi·ªÉu ƒë·ªì ph√¢n t√°n c·ªßa hai chi·ªÅu v·ªõi ƒë∆∞·ªùng h·ªìi quy tuy·∫øn t√≠nh, ph·∫£n √°nh m·ª©c ƒë·ªô t∆∞∆°ng quan.")
        
            # T√≠nh ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai
            covariance_matrix = np.cov(X_normalized.T)
        
            # T√≠nh ƒë∆∞·ªùng h·ªìi quy tuy·∫øn t√≠nh
            from scipy.stats import linregress
            slope, intercept, r_value, p_value, std_err = linregress(X_normalized[:, 0], X_normalized[:, 1])
            line = slope * X_normalized[:, 0] + intercept
        
            # V·∫Ω bi·ªÉu ƒë·ªì ph√¢n t√°n v·ªõi ƒë∆∞·ªùng h·ªìi quy
            fig, ax = plt.subplots(figsize=(3, 2))
            ax.scatter(X_normalized[:, 0], X_normalized[:, 1], c=y_sim, cmap="viridis", alpha=0.6)
            ax.plot(X_normalized[:, 0], line, color="red", linestyle="--", label=f"ƒê∆∞·ªùng h·ªìi quy (R¬≤ = {r_value**2:.2f})")
            ax.set_title("Ph√¢n t√°n v√† ƒë∆∞·ªùng h·ªìi quy gi·ªØa X v√† Y",fontsize=6)
            ax.set_xlabel("X (chu·∫©n h√≥a)",fontsize=6)
            ax.set_ylabel("Y (chu·∫©n h√≥a)",fontsize=6)
            ax.tick_params(axis='both', labelsize=6)  # Gi·∫£m k√≠ch th∆∞·ªõc ch·ªØ tr√™n c√°c d·∫•u tick
            ax.grid(True)
            ax.legend(fontsize=6) 
            st.pyplot(fig)
            st.write(f"ƒê∆∞·ªùng h·ªìi quy (m√†u ƒë·ªè) cho th·∫•y m·ª©c ƒë·ªô t∆∞∆°ng quan gi·ªØa X v√† Y, v·ªõi h·ªá s·ªë R¬≤ = {r_value**2:.2f}. Ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai s·∫Ω c√≥ gi√° tr·ªã ngo√†i ƒë∆∞·ªùng ch√©o (kho·∫£ng {covariance_matrix[0, 1]:.2f}) ph·∫£n √°nh t∆∞∆°ng quan n√†y.")
        
            # B∆∞·ªõc 3: T√≠nh to√°n gi√° tr·ªã ri√™ng v√† vector ri√™ng
            st.write("- **B∆∞·ªõc 3: T√≠nh to√°n gi√° tr·ªã ri√™ng v√† vector ri√™ng**")
            st.write("Gi·∫£i ph∆∞∆°ng tr√¨nh eigenvalue decomposition:")
            st.latex(r"""
            \Sigma v = \lambda v
            """)
            st.write("Trong ƒë√≥:")
            st.latex(r"""
            \begin{aligned}
            &\Sigma: \text{Ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai} \\
            &v: \text{Vector ri√™ng (h∆∞·ªõng c·ªßa th√†nh ph·∫ßn ch√≠nh, l√† vector ƒë∆°n v·ªã, } ||v|| = 1\text{)} \\
            &\lambda: \text{Gi√° tr·ªã ri√™ng (s·ªë th·ª±c, th·ªÉ hi·ªán ph∆∞∆°ng sai theo h∆∞·ªõng } v\text{)}
            \end{aligned}
            """)
            st.markdown("Ph∆∞∆°ng tr√¨nh n√†y ƒë∆∞·ª£c gi·∫£i b·∫±ng ph√¢n r√£ gi√° tr·ªã ri√™ng (eigen decomposition), t√¨m t·∫•t c·∫£ $$( (\lambda, v) $$) sao cho ph∆∞∆°ng tr√¨nh th·ªèa m√£n.")
        
            # T√≠nh gi√° tr·ªã ri√™ng v√† vector ri√™ng
            eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)
            idx = np.argsort(eigenvalues)[::-1]
            eigenvalues = eigenvalues[idx]
            eigenvectors = eigenvectors[:, idx]
        
            # V·∫Ω d·ªØ li·ªáu v·ªõi vector ri√™ng
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=X_normalized[:, 0], y=X_normalized[:, 1], mode="markers",
                                    marker=dict(color=y_sim, colorscale="Viridis", size=8, opacity=0.6),
                                    name="D·ªØ li·ªáu"))
            
            # Th√™m vector ri√™ng
            scale = 2
            for i in range(2):
                fig.add_shape(type="line", x0=0, y0=0, x1=eigenvectors[0, i] * scale * np.sqrt(eigenvalues[i]),
                            y1=eigenvectors[1, i] * scale * np.sqrt(eigenvalues[i]),
                            line=dict(color="red", width=3))
                fig.add_annotation(x=eigenvectors[0, i] * scale * np.sqrt(eigenvalues[i]),
                                y=eigenvectors[1, i] * scale * np.sqrt(eigenvalues[i]),
                                text=f"PC{i+1}", showarrow=False)
        
            fig.update_layout(title="D·ªØ li·ªáu v·ªõi vector ri√™ng (PC1, PC2)",
                            xaxis_title="X (chu·∫©n h√≥a)", yaxis_title="Y (chu·∫©n h√≥a)",
                            showlegend=True)
            st.plotly_chart(fig)
            st.write(f"Gi√° tr·ªã ri√™ng: PC1 = {eigenvalues[0]:.2f}, PC2 = {eigenvalues[1]:.2f}. Vector ri√™ng (PC1, PC2) l√† c√°c h∆∞·ªõng ch√≠nh, th·ªÉ hi·ªán ƒë·ªô bi·∫øn thi√™n l·ªõn nh·∫•t.")
        
            # B∆∞·ªõc 4: Ch·ªçn s·ªë l∆∞·ª£ng th√†nh ph·∫ßn ch√≠nh
            st.write("- **B∆∞·ªõc 4: Ch·ªçn s·ªë l∆∞·ª£ng th√†nh ph·∫ßn ch√≠nh**")
            st.write("Ch·ªçn s·ªë th√†nh ph·∫ßn ch√≠nh d·ª±a tr√™n t·ª∑ l·ªá ph∆∞∆°ng sai t√≠ch l≈©y:")
            st.latex(r"""
            \text{Explained Variance Ratio}_i = \frac{\lambda_i}{\sum_{j=1}^{d} \lambda_j}
            """)
            st.latex(r"""
            \text{Cumulative Explained Variance} = \sum_{i=1}^{k} \frac{\lambda_i}{\sum_{j=1}^{d} \lambda_j}
            """)
            st.write("Trong ƒë√≥:")
            st.latex(r"""
            \begin{aligned}
            &\lambda_i: \text{Gi√° tr·ªã ri√™ng c·ªßa th√†nh ph·∫ßn th·ª© } i \\
            &d: \text{T·ªïng s·ªë chi·ªÅu c·ªßa d·ªØ li·ªáu} \\
            &k: \text{S·ªë th√†nh ph·∫ßn ch√≠nh ƒë∆∞·ª£c ch·ªçn}
            \end{aligned}
            """)
            st.write("Th∆∞·ªùng ch·ªçn \( k \) sao cho t·ªïng ph∆∞∆°ng sai ƒë·∫°t 85-95%.")
        
            # T√≠nh t·ª∑ l·ªá ph∆∞∆°ng sai t√≠ch l≈©y
            explained_variance_ratio = eigenvalues / eigenvalues.sum()
            cumulative_variance = np.cumsum(explained_variance_ratio)
        
            # V·∫Ω bi·ªÉu ƒë·ªì t·ª∑ l·ªá ph∆∞∆°ng sai t√≠ch l≈©y
            fig = px.bar(x=["PC1", "PC2"], y=explained_variance_ratio,
                        title="T·ª∑ l·ªá ph∆∞∆°ng sai gi·∫£i th√≠ch b·ªüi t·ª´ng th√†nh ph·∫ßn ch√≠nh",
                        labels={'x': 'Th√†nh ph·∫ßn ch√≠nh', 'y': 'T·ª∑ l·ªá ph∆∞∆°ng sai'})
            st.plotly_chart(fig)
            st.write(f"PC1 gi·∫£i th√≠ch {explained_variance_ratio[0]*100:.2f}% ph∆∞∆°ng sai, PC2 gi·∫£i th√≠ch {explained_variance_ratio[1]*100:.2f}%. T·ªïng c·ªông: {cumulative_variance[-1]*100:.2f}%. Trong v√≠ d·ª• n√†y, ch√∫ng ta ch·ªçn c·∫£ 2 th√†nh ph·∫ßn ch√≠nh ƒë·ªÉ tr·ª±c quan h√≥a.")
        
            # B∆∞·ªõc 5: Bi·∫øn ƒë·ªïi d·ªØ li·ªáu sang kh√¥ng gian m·ªõi
            st.write("- **B∆∞·ªõc 5: Bi·∫øn ƒë·ªïi d·ªØ li·ªáu sang kh√¥ng gian m·ªõi**")
            st.write("Chuy·ªÉn d·ªØ li·ªáu sang h·ªá t·ªça ƒë·ªô m·ªõi b·∫±ng c√°ch nh√¢n v·ªõi ma tr·∫≠n ch·ª©a c√°c vector ri√™ng:")
            st.latex(r"""
            X_{\text{new}} = X V_k
            """)
            st.write("Trong ƒë√≥:")
            st.latex(r"""
            \begin{aligned}
            &X: \text{Ma tr·∫≠n d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a} \, (n \times d) \\
            &V_k: \text{Ma tr·∫≠n ch·ª©a } k \text{ vector ri√™ng ƒë·∫ßu ti√™n} \, (d \times k), \text{ v·ªõi c√°c c·ªôt l√† vector ri√™ng} \\
            &X_{\text{new}}: \text{Ma tr·∫≠n d·ªØ li·ªáu sau khi gi·∫£m chi·ªÅu} \, (n \times k)
            \end{aligned}
            """)
        
            # Chi·∫øu d·ªØ li·ªáu l√™n kh√¥ng gian m·ªõi
            X_new = np.dot(X_normalized, eigenvectors)
        
            # V·∫Ω d·ªØ li·ªáu trong kh√¥ng gian m·ªõi
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=X_new[:, 0], y=X_new[:, 1], mode="markers",
                                    marker=dict(color=y_sim, colorscale="Viridis", size=8, opacity=0.6),
                                    name="D·ªØ li·ªáu"))
            fig.update_layout(title="D·ªØ li·ªáu trong kh√¥ng gian m·ªõi (PC1, PC2)",
                            xaxis_title="PC1", yaxis_title="PC2",
                            showlegend=True)
            st.plotly_chart(fig)
            st.write("D·ªØ li·ªáu ƒë∆∞·ª£c chi·∫øu l√™n kh√¥ng gian m·ªõi, v·ªõi tr·ª•c t·ªça ƒë·ªô l√† c√°c th√†nh ph·∫ßn ch√≠nh PC1 v√† PC2. PC1 (tr·ª•c X) l√† h∆∞·ªõng c√≥ ƒë·ªô bi·∫øn thi√™n l·ªõn nh·∫•t.")
        elif algorithm == "t-SNE":
            st.write("##### Thu·∫≠t to√°n t-SNE")
            st.write("**t-SNE (T-distributed Stochastic Neighbor Embedding)** l√† m·ªôt k·ªπ thu·∫≠t gi·∫£m k√≠ch th∆∞·ªõc phi tuy·∫øn kh√¥ng gi√°m s√°t ƒë·ªÉ kh√°m ph√° d·ªØ li·ªáu v√† tr·ª±c quan h√≥a d·ªØ li·ªáu chi·ªÅu cao. Gi·∫£m k√≠ch th∆∞·ªõc phi tuy·∫øn t√≠nh c√≥ nghƒ©a l√† thu·∫≠t to√°n cho ph√©p ch√∫ng ta t√°ch d·ªØ li·ªáu kh√¥ng th·ªÉ ph√¢n t√°ch b·∫±ng ƒë∆∞·ªùng th·∫≥ng.")
            st.write("**Nguy√™n l√≠ ho·∫°t ƒë·ªông**")
            st.write("- üí†**B∆∞·ªõc 1**:  t-SNE m√¥ h√¨nh h√≥a m·ªôt ƒëi·ªÉm ƒë∆∞·ª£c ch·ªçn l√†m h√†ng x√≥m c·ªßa m·ªôt ƒëi·ªÉm kh√°c ·ªü c·∫£ chi·ªÅu cao h∆°n v√† th·∫•p h∆°n. N√≥ b·∫Øt ƒë·∫ßu b·∫±ng c√°ch t√≠nh to√°n s·ª± t∆∞∆°ng ƒë·ªìng theo c·∫∑p gi·ªØa t·∫•t c·∫£ c√°c ƒëi·ªÉm d·ªØ li·ªáu trong kh√¥ng gian chi·ªÅu cao b·∫±ng c√°ch s·ª≠ d·ª•ng h·∫°t nh√¢n Gaussian.")
            st.image("tnse.png",caption="Ngu·ªìn : https://statquest.org")
            st.write("S·ª≠ d·ª•ng ph√¢n ph·ªëi chu·∫©n n·∫øu c√°c ƒëi·ªÉm c√°ch xa nhau, ch√∫ng c√≥ √≠t ƒëi·ªÉm gi·ªëng nhau, v√† n·∫øu ch√∫ng g·∫ßn nhau, ch√∫ng c√≥ nhi·ªÅu ƒëi·ªÉm gi·ªëng nhau")
            st.image("tnse2.png",caption="Ngu·ªìn : https://statquest.org")
            st.image("tnse3.png",caption="Ngu·ªìn : https://statquest.org")
            st.write("L·∫∑p l·∫°i thao t√°c n√†y cho t·∫•t c·∫£ c√°c ƒëi·ªÉm n·∫±m trong ph·∫°m vi ƒë√£ x√°c ƒë·ªãnh tr∆∞·ªõc ƒë√≥")
            st.image("tnse4.png",caption="Ngu·ªìn : https://statquest.org")
            st.write("Sau khi t√≠nh to√°n c√°c kho·∫£ng c√°ch ƒë∆∞·ª£c bi·ªÉu di·ªÖn tr√™n ph√¢n ph·ªëi chu·∫©n, chuy·ªÉn ƒë·ªïi ch√∫ng th√†nh m·ªôt t·∫≠p h·ª£p x√°c su·∫•t c·ªßa t·∫•t c·∫£ c√°c ƒëi·ªÉm (cchia t·ª∑ l·ªá ch√∫ng sao cho t·∫•t c·∫£ c√°c gi√° tr·ªã c√≥ t·ªïng b·∫±ng 1). ƒêi·ªÅu n√†y cung c·∫•p cho ch√∫ng ta m·ªôt t·∫≠p h·ª£p x√°c su·∫•t cho t·∫•t c·∫£ c√°c ƒëi·ªÉm ·ªü ƒë√≥")
            st.image("tnse5.png",caption="Ngu·ªìn : https://statquest.org")

            st.write("- üí†**B∆∞·ªõc 2** : Sau ƒë√≥, thu·∫≠t to√°n c·ªë g·∫Øng √°nh x·∫° c√°c ƒëi·ªÉm d·ªØ li·ªáu chi·ªÅu cao h∆°n v√†o kh√¥ng gian chi·ªÅu th·∫•p h∆°n trong khi v·∫´n gi·ªØ nguy√™n c√°c ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng theo c·∫∑p.")
            st.image("tnse6.png",caption="Ngu·ªìn : https://statquest.org")
            st.write("Khi t-SNE chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu t·ª´ kh√¥ng gian cao chi·ªÅu xu·ªëng kh√¥ng gian th·∫•p chi·ªÅu (2D ho·∫∑c 3D), n√≥ kh√¥ng s·ª≠ d·ª•ng ph√¢n ph·ªëi Gaussian n·ªØa m√† thay v√†o ƒë√≥ d√πng ph√¢n ph·ªëi t hay c√≤n g·ªçi l√† ph√¢n ph·ªëi Cauchy")
            st.write("a. T√≠nh to√°n t·∫•t c·∫£ c√°c kho·∫£ng c√°ch",caption="Ngu·ªìn : https://statquest.org")
            st.image("tnse7.png")
            st.write("b. Danh s√°ch c√°c ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng",caption="Ngu·ªìn : https://statquest.org")
            st.image("tnse8.png")
            st.write("c. T√≠nh to√°n t·∫≠p x√°c su·∫•t  trong kh√¥ng gian c√≥ chi·ªÅu th·∫•p")
            st.image("tnse9.png",caption="Ngu·ªìn : https://statquest.org")
            st.write("- üí†**B∆∞·ªõc 3**: N√≥ ƒë·∫°t ƒë∆∞·ª£c b·∫±ng c√°ch gi·∫£m thi·ªÉu s·ª± ph√¢n k·ª≥ gi·ªØa ph√¢n ph·ªëi x√°c su·∫•t chi·ªÅu cao v√† chi·ªÅu th·∫•p h∆°n ban ƒë·∫ßu. Thu·∫≠t to√°n s·ª≠ d·ª•ng ƒë·ªô d·ªëc gradient ƒë·ªÉ gi·∫£m thi·ªÉu s·ª± ph√¢n k·ª≥. Vi·ªác nh√∫ng chi·ªÅu th·∫•p h∆°n ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a ·ªü tr·∫°ng th√°i ·ªïn ƒë·ªãnh.")
            st.write("L√†m cho t·∫≠p h·ª£p c√°c x√°c su·∫•t t·ª´ kh√¥ng gian chi·ªÅu th·∫•p ph·∫£n √°nh c√†ng s√°t c√†ng t·ªët c√°c x√°c su·∫•t t·ª´ kh√¥ng gian chi·ªÅu cao gi√∫p hai c·∫•u tr√∫c t·∫≠p h·ª£p n√†y ph·∫£i gi·ªëng nhau.")
            st.image("tnse10.png",caption="Ngu·ªìn : https://statquest.org")
            st.write("Trong thu·∫≠t to√°n t-SNE, ƒë·ªÉ so s√°nh hai ph√¢n ph·ªëi x√°c su·∫•t gi·ªØa kh√¥ng gian cao chi·ªÅu (tr∆∞·ªõc khi gi·∫£m chi·ªÅu) v√† kh√¥ng gian th·∫•p chi·ªÅu (sau khi gi·∫£m chi·ªÅu), ta s·ª≠ d·ª•ng ph√¢n k·ª≥ Kullback-Leibler (KL Divergence).")
            st.image("tnse11.png",caption="Ngu·ªìn : https://statquest.org")
       
    with tab2:
        X, y = load_mnist_data()
        st.write("**üñºÔ∏è M·ªôt v√†i m·∫´u d·ªØ li·ªáu t·ª´ MNIST**")
        num_samples = 10  
        cols = st.columns(10)
        for i in range(num_samples):
            with cols[i % 10]:
                fig, ax = plt.subplots()
                ax.imshow(X[i].reshape(28, 28), cmap="gray")
                ax.axis("off")
                st.pyplot(fig)
                st.caption(f"{y[i]}")

        st.write("##### T√πy ch·ªçn m·∫´u d·ªØ li·ªáu")
        sample_size = st.number_input("Ch·ªçn c·ª° m·∫´u ƒë·ªÉ ph√¢n c·ª•m", min_value=1000, max_value=70000, value=5000, step=1000)
        X_sample, y_sample = sample_data(X, y, sample_size)
        st.write(f"K√≠ch th∆∞·ªõc d·ªØ li·ªáu sau khi l·∫•y m·∫´u: {X_sample.shape}")

        model_name = st.text_input("Nh·∫≠p t√™n m√¥ h√¨nh:")
        if not model_name:
            model_name= "Default_Model"
        method = st.selectbox("Ch·ªçn ph∆∞∆°ng ph√°p gi·∫£m chi·ªÅu", ["PCA", "t-SNE"], key="method_tab2")

        if method == "PCA":
            n_components = st.slider("S·ªë l∆∞·ª£ng th√†nh ph·∫ßn PCA", 2, 50, 2, key="n_components_tab2")
        elif method == "t-SNE":
            n_components = st.slider("S·ªë l∆∞·ª£ng th√†nh ph·∫ßn t-SNE", 2, 10, 2, key="n_components_tsne")

        if st.button("Gi·∫£m chi·ªÅu", key="reduce_button_tab2"):
            if not st.session_state.run_in_progress:  
                st.session_state.run_in_progress = True
                with st.spinner("ƒêang th·ª±c hi·ªán gi·∫£m chi·ªÅu..."):
                    progress_bar = st.progress(0)
                    
                    if mlflow.active_run():
                        mlflow.end_run()
                    
                    progress_bar.progress(10)
                    start_time = time.time()
                    mlflow.set_experiment("MNIST_Dimensionality_Reduction")
                    
                    try:
                        with mlflow.start_run(run_name=model_name) as run:
                            st.session_state.last_run_id = run.info.run_id
                            if method == "PCA":
                                X_reduced, explained_variance = apply_pca(X_sample, n_components, progress_bar)
                                mlflow.log_param("method", "PCA")
                                mlflow.log_param("n_components", n_components)
                                mlflow.log_param("sample_size", sample_size)
                                mlflow.log_param("model_name", model_name)
                                mlflow.log_metric("explained_variance", explained_variance)
                                if n_components in [2, 3]:
                                    fig = plot_scatter(X_reduced, y_sample, f"PCA - {n_components} Components")
                                    progress_bar.progress(80)
                                    if fig is not None:
                                        st.plotly_chart(fig, use_container_width=True)
                                    st.write(f"T·ª∑ l·ªá ph∆∞∆°ng sai gi·∫£i th√≠ch: {explained_variance:.4f}")
                                else:
                                    progress_bar.progress(80)
                                    st.write(f"K·∫øt qu·∫£ PCA c√≥ {n_components} chi·ªÅu, kh√¥ng th·ªÉ visual h√≥a tr·ª±c ti·∫øp ·ªü 2D ho·∫∑c 3D. T·ª∑ l·ªá ph∆∞∆°ng sai gi·∫£i th√≠ch: {explained_variance:.4f}")

                            elif method == "t-SNE":
                                X_reduced = apply_tsne(X_sample, n_components, progress_bar)
                                mlflow.log_param("method", "t-SNE")
                                mlflow.log_param("n_components", n_components)
                                mlflow.log_param("sample_size", sample_size)
                                mlflow.log_param("model_name", model_name)
                                if n_components in [2, 3]:
                                    fig = plot_scatter(X_reduced, y_sample, f"t-SNE - {n_components} Components")
                                    progress_bar.progress(80)
                                    if fig is not None:
                                        st.plotly_chart(fig, use_container_width=True)
                                else:
                                    progress_bar.progress(80)
                                    st.write(f"K·∫øt qu·∫£ t-SNE c√≥ {n_components} chi·ªÅu, kh√¥ng th·ªÉ visual h√≥a tr·ª±c ti·∫øp ·ªü 2D ho·∫∑c 3D.")
                            
                            execution_time = time.time() - start_time
                            mlflow.log_metric("execution_time", execution_time)
                            progress_bar.progress(100)
                    except Exception as e:
                        if mlflow.active_run():
                            mlflow.end_run()
                    
                    # ƒê·∫£m b·∫£o ch·∫°y ƒë∆∞·ª£c k·∫øt th√∫c
                    if mlflow.active_run():
                        mlflow.end_run()
                
                time.sleep(1)
                # st.success(f"ƒê√£ ho√†n th√†nh gi·∫£m chi·ªÅu v√† l∆∞u v√†o th√≠ nghi·ªám 'MNIST_Dimensionality_Reduction' v·ªõi t√™n m√¥ h√¨nh '{model_name}'!")
                st.session_state.run_in_progress = False

    with tab3:
        st.subheader("MLflow Tracking")

        if mlflow.active_run():
            mlflow.end_run()

        experiments = mlflow.search_experiments()
        experiment_dict = {exp.name: exp.experiment_id for exp in experiments}
        selected_exp_id = experiment_dict.get("MNIST_Dimensionality_Reduction")

        if not selected_exp_id:
            st.write("Ch∆∞a c√≥ th√≠ nghi·ªám 'MNIST_Dimensionality_Reduction'. Vui l√≤ng gi·∫£m chi·ªÅu d·ªØ li·ªáu tr∆∞·ªõc.")
        else:
            search_query = st.text_input("T√¨m ki·∫øm theo t√™n m√¥ h√¨nh", "", key="search_tab3")
            runs = mlflow.search_runs(experiment_ids=[selected_exp_id])

            if not runs.empty:
                runs['experiment_name'] = "MNIST_Dimensionality_Reduction"
                if search_query:
                    runs = runs[runs['params.model_name'].str.contains(search_query, case=False, na=False)]
                
                available_columns = ['params.model_name', 'start_time', 'params.method', 
                                    'params.n_components', 'params.sample_size', 'metrics.explained_variance']
                display_columns = [col for col in available_columns if col in runs.columns]
                display_df = runs[display_columns].rename(columns={'params.model_name': 'Model Name'})
                st.dataframe(display_df)

                model_names = runs['params.model_name'].unique().tolist()
                selected_model_name = st.selectbox("Ch·ªçn m·ªôt m√¥ h√¨nh ƒë·ªÉ xem chi ti·∫øt", model_names, key="select_model_tab3")
                
                if selected_model_name:
                    selected_run = runs[runs['params.model_name'] == selected_model_name].iloc[0]
                    st.write(f"##### Chi ti·∫øt c·ªßa Model Name: {selected_model_name}")
                    
                    st.write("**Th√¥ng tin chung:**")
                    general_info = {
                        'Model Name': selected_run.get('params.model_name', 'N/A'),
                        'Start Time': selected_run.get('start_time', 'N/A')
                        # 'Execution Time (s)': selected_run.get('metrics.execution_time', 'N/A'),  # Kh√¥ng nh·∫≠n th·ª©c v√† c·ªë ƒë·ªãnh
                    }
                    for key, value in general_info.items():
                        if pd.notna(value):
                            st.write(f"{key}: {value}")

                    st.write("**Th√¥ng tin li√™n quan ƒë·∫øn ph∆∞∆°ng ph√°p:**")
                    method = selected_run.get('params.method', 'N/A')
                    if method == "PCA":
                        method_info = {
                            'Ph∆∞∆°ng ph√°p': method,
                            'S·ªë l∆∞·ª£ng th√†nh ph·∫ßn (n_components)': selected_run.get('params.n_components', 'N/A'),
                            'T·ª∑ l·ªá ph∆∞∆°ng sai gi·∫£i th√≠ch': selected_run.get('metrics.explained_variance', 'N/A'),
                            'K√≠ch th∆∞·ªõc m·∫´u': selected_run.get('params.sample_size', 'N/A'),  # Fixed spacing
                        }
                    elif method == "t-SNE":
                        method_info = {
                            'Ph∆∞∆°ng ph√°p': method,
                            'S·ªë l∆∞·ª£ng th√†nh ph·∫ßn (n_components)': selected_run.get('params.n_components', 'N/A'),
                            'K√≠ch th∆∞·ªõc m·∫´u': selected_run.get('params.sample_size', 'N/A'),  # Fixed spacing
                        }
                    else:
                        method_info = {'Ph∆∞∆°ng ph√°p': 'Kh√¥ng x√°c ƒë·ªãnh'}

                    for key, value in method_info.items():
                        if pd.notna(value):
                            st.write(f"{key}: {value}")
            else:
                st.write("Ch∆∞a c√≥ run n√†o trong th√≠ nghi·ªám 'MNIST_Dimensionality_Reduction'.")

if __name__ == "__main__":
    main()
