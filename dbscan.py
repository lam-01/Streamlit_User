import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient
from sklearn.cluster import KMeans, DBSCAN
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score, calinski_harabasz_score
from openml import datasets
import datetime
import os
import plotly.express as px
import plotly.graph_objects as go
from PIL import Image
import io
from sklearn.datasets import fetch_openml

# Set up MLflow
def setup_mlflow():
    # ƒê·∫∑t URI theo d√µi MLFlow th√†nh th∆∞ m·ª•c c·ª•c b·ªô
    mlflow_tracking_uri = "./mlruns"
    # mlflow.set_experiment("Clustering Algorithms")
    if not os.path.exists(mlflow_tracking_uri):
        os.makedirs(mlflow_tracking_uri)
    mlflow.set_tracking_uri(mlflow_tracking_uri)
    return MlflowClient()
    # Modify your setup_mlflow function to ensure it sets the experiment


# T·∫£i b·ªô d·ªØ li·ªáu MNIST t·ª´ OpenML
@st.cache_data
def load_mnist_data():
    mnist = fetch_openml('mnist_784', version=1, parser='auto')
    X = mnist.data.astype('float32').values  # Chuy·ªÉn ƒë·ªïi th√†nh m·∫£ng NumPy
    y = mnist.target.astype('int')
    return X, y
# Preprocess data
@st.cache_data
def preprocess_data(X, sample_size=5000):
    # L·∫•y m·∫´u ƒë·ªÉ th·ª±c hi·ªán x·ª≠ l√Ω nhanh h∆°n cho b·∫£n demo
    np.random.seed(42)
    indices = np.random.choice(X.shape[0], sample_size, replace=False)
    X_sample = X[indices]
    
    # L∆∞u tr·ªØ c√°c gi√° tr·ªã ban ƒë·∫ßu c·ªßa m·∫´u
    X_original = X_sample.copy()
    
    # Chu·∫©n h√≥a d·ªØ li·ªáu
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_sample)
    
    # √Åp d·ª•ng PCA ƒë·ªÉ gi·∫£m chi·ªÅu d·ªØ li·ªáu xu·ªëng 2 chi·ªÅu
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X_scaled)  # Hu·∫•n luy·ªán PCA v√† bi·∫øn ƒë·ªïi d·ªØ li·ªáu
    
    return X_sample, X_scaled, X_pca, indices, X_original, pca 
# Th·ª±c hi·ªán ph√¢n c·ª•m K-Means
def run_kmeans(X_scaled, n_clusters=10):
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    kmeans.fit(X_scaled)
    return kmeans

# Th·ª±c hi·ªán ph√¢n c·ª•m DBSCAN
def run_dbscan(X_scaled, eps=0.5, min_samples=5):
    dbscan = DBSCAN(eps=eps, min_samples=min_samples)
    dbscan.fit(X_scaled)
    return dbscan
# H√†m log m√¥ h√¨nh v√†o MLFlow
def log_model(model, model_name, params, metrics, cluster_images, experiment_name):
    mlflow.set_experiment(experiment_name)
    
    with mlflow.start_run(run_name=model_name) as run:
        # Log model name
        mlflow.log_param("model_name", model_name)
        
        # Log parameters
        for param_name, param_value in params.items():
            mlflow.log_param(param_name, param_value)
        
        # Log metrics
        for metric_name, metric_value in metrics.items():
            mlflow.log_metric(metric_name, metric_value)
        
        # Log the model
        mlflow.sklearn.log_model(model, "model")
        
        # Log sample images
        for cluster_id, images in cluster_images.items():
            if images is not None and len(images) > 0:
                for i, img_data in enumerate(images[:5]):  # Ch·ªâ ƒëƒÉng 5 ·∫£nh m·ªói c·ª•m
                    fig, ax = plt.subplots(figsize=(3, 3))
                    ax.imshow(img_data.reshape(28, 28), cmap='gray')
                    plt.axis('off')
                    buf = io.BytesIO()
                    plt.savefig(buf, format='png')
                    buf.seek(0)
                    mlflow.log_image(Image.open(buf), f"cluster_{cluster_id}_sample_{i}.png")
                    plt.close(fig)
                
        return run.info.run_id

# Tr·ª±c quan h√≥a k·∫øt qu·∫£ ph√¢n c·ª•m
def visualize_clusters(X_pca, labels, model_type, centroids=None):
    fig = px.scatter(
        x=X_pca[:, 0], 
        y=X_pca[:, 1], 
        color=[str(label) for label in labels],
        title=f"{model_type} Clustering Results (PCA Visualization)",
        labels={"x": "PCA Component 1", "y": "PCA Component 2"},
        color_discrete_sequence=px.colors.qualitative.G10
    )
    
   # Th√™m Centroids n·∫øu c√≥ (K-Means)
    if centroids is not None and model_type == 'K-means':
        pca = PCA(n_components=2)
        pca.fit(X_pca)  # Ph√π h·ª£p v·ªõi d·ªØ li·ªáu PCA hi·ªán c√≥
        centroids_pca = pca.transform(centroids)  # Bi·∫øn ƒë·ªïi Centroids
        
        fig.add_trace(
            go.Scatter(
                x=centroids_pca[:, 0],
                y=centroids_pca[:, 1],
                mode='markers',
                marker=dict(
                    symbol='x',
                    color='black',
                    size=10,
                    line=dict(width=2)
                ),
                name='Centroids'
            )
        )
    
    return fig

# Nh·∫≠n c√°c v√≠ d·ª• v·ªÅ ch·ªØ s·ªë b·∫±ng c·ª•m
def get_digit_examples_by_cluster(X_original, cluster_labels):
    examples_by_cluster = {}
    unique_labels = np.unique(cluster_labels)
    
    for label in unique_labels:
       # B·ªè qua ƒëi·ªÉm nhi·ªÖu (nh√£n -1 trong DBSCAN)
        if label == -1:
            continue
            
        # Nh·∫≠n c√°c ch·ªâ s·ªë c·ªßa c√°c m·∫´u trong c·ª•m n√†y
        cluster_indices = np.where(cluster_labels == label)[0]
        
        # Nh·∫≠n d·ªØ li·ªáu m·∫´u cho c√°c ch·ªâ s·ªë n√†y tr·ª±c ti·∫øp
        cluster_samples = X_original[cluster_indices]
        
        examples_by_cluster[label] = cluster_samples
        
    return examples_by_cluster

# Danh s√°ch th√≠ nghi·ªám
def list_experiments(client):
    return client.search_experiments()

# Li·ªát k√™ t·∫•t c·∫£ c√°c l·∫ßn ch·∫°y cho m·ªôt th·ª≠ nghi·ªám
def list_runs(client, experiment_id):
    return client.search_runs(experiment_id)

# T√¨m ki·∫øm c√°c m√¥ h√¨nh theo t√™n
def search_models(client, query, experiment_id):
    runs = client.search_runs(
        experiment_id,
        filter_string=f"params.model_name LIKE '%{query}%'"
    )
    return runs

# Nh·∫≠n chi ti·∫øt m√¥ h√¨nh
def get_model_details(client, run_id):
    run = client.get_run(run_id)
    return run

# ·ª®ng d·ª•ng Streamlit ch√≠nh
def main():
    st.title("MNIST Clustering ")
    
    # Setup MLflow client
    client = setup_mlflow()
    
    # Sidebar for app navigation
    tab1, tab2, tab3 = st.tabs(["T·ªïng quan ", "Ph√¢n c·ª•m ", "MLFlow"])

    with tab1:
        # Hi·ªÉn th·ªã c√°c ch·ªØ s·ªë MNIST m·∫´u
        try:
            X, y = load_mnist_data()
            st.subheader("üîπC√°c ch·ªØ s·ªë Mnist m·∫´u")
            
            # Ki·ªÉm tra d·ªØ li·ªáu
            if len(X) == 0 or len(y) == 0:
                st.error("D·ªØ li·ªáu MNIST tr·ªëng. Vui l√≤ng ki·ªÉm tra l·∫°i h√†m t·∫£i d·ªØ li·ªáu.")
            else:
                # Hi·ªÉn th·ªã m·ªôt l∆∞·ªõi c√°c ch·ªØ s·ªë v√≠ d·ª•
                cols = st.columns(5)
                for i, col in enumerate(cols):
                    idx = np.random.randint(0, len(X))
                    with col:
                        fig, ax = plt.subplots(figsize=(3, 3))
                        ax.imshow(X[idx].reshape(28, 28), cmap='gray')
                        ax.set_title(f"Ch·ªØ s·ªë : {y[idx]}")
                        ax.axis('off')
                        st.pyplot(fig)
                        plt.close(fig)
        except Exception as e:
            st.error(f"Error loading MNIST data: {e}")
            st.error(f"Chi ti·∫øt l·ªói: {str(e)}")
        
        st.subheader("üîπThu·∫≠t to√°n ph√¢n c·ª•m")
        st.subheader("1. K-means")
        st.image("1.png")
        st.write("##### C√°c b∆∞·ªõc th·ª±c hi·ªán :")
        st.image("2.png")
        st.write("")
        st.subheader("2. DBSCAN")
        st.image("3.png")
        st.image("4.png")
        st.write("##### C√°c b∆∞·ªõc th·ª±c hi·ªán :")
        st.image("5.png")
    with tab2:
        st.header("Run Clustering Algorithms")
        
        try:
            X, y = load_mnist_data()
            st.success(f"B·ªô d·ªØ li·ªáu MNIST ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng v·ªõi {X.shape[0]} m·∫´u.")
            
            # Sample size selection
            sample_size = st.slider("Ch·ªçn c·ª° m·∫´u ƒë·ªÉ ph√¢n c·ª•m", 
                                min_value=1000, 
                                max_value=10000, 
                                value=5000, 
                                step=1000)
            
            # D·ªØ li·ªáu ti·ªÅn x·ª≠ l√Ω
            X_sample, X_scaled, X_pca, indices, X_original, pca = preprocess_data(X, sample_size)
            st.success(f"S·ªë l∆∞·ª£ng m·∫´u: {sample_size} m·∫´u.")
            
            # S·ª≠ d·ª•ng gi√° tr·ªã t·ª´ st.text_input ƒë·ªÉ ƒë·∫∑t model_name
            model_name = st.text_input("Nh·∫≠p t√™n m√¥ h√¨nh ƒë·ªÉ l∆∞u v√†o MLflow:")  # T√™n ch√≠nh cho experiment
            if not model_name:  # N·∫øu ng∆∞·ªùi d√πng kh√¥ng nh·∫≠p g√¨, ƒë·∫∑t m·∫∑c ƒë·ªãnh
                model_name = "Default_Model"
            mlflow.set_experiment(model_name)  # S·ª≠ d·ª•ng model_name l√†m t√™n experiment
            st.write(f"T√™n m√¥ h√¨nh hi·ªán t·∫°i: {model_name}")
            
            # T·∫°o selectbox ƒë·ªÉ ch·ªçn thu·∫≠t to√°n
            selected_tab = st.selectbox("Ch·ªçn thu·∫≠t to√°n ph√¢n c·ª•m", ["K-means", "DBSCAN"])

            if selected_tab == "K-means":
                st.subheader("K-means Clustering")
                
                # S·ªë c·ª•m
                n_clusters = st.slider("S·ªë c·ª•m (k)", min_value=5, max_value=20, value=10)
                
                # Run K-means button
                if st.button("Run K-means"):
                    with st.spinner("Ch·∫°y ph√¢n c·ª•m K-Means ..."):
                        # Run K-means
                        kmeans_model = run_kmeans(X_scaled, n_clusters)
                        kmeans_labels = kmeans_model.labels_
                        
                        # Calculate metrics
                        if len(np.unique(kmeans_labels)) > 1:  # C·∫ßn √≠t nh·∫•t 2 c·ª•m cho s·ªë li·ªáu
                            silhouette = silhouette_score(X_scaled, kmeans_labels)
                            calinski = calinski_harabasz_score(X_scaled, kmeans_labels)
                        else:
                            silhouette = 0
                            calinski = 0
                        
                        # Chuy·ªÉn ƒë·ªïi c√°c trung t√¢m c·ª•m th√†nh kh√¥ng gian PCA
                        cluster_centers_pca = pca.transform(kmeans_model.cluster_centers_)
                        
                        # Tr·ª±c quan h√≥a k·∫øt qu·∫£
                        fig = visualize_clusters(X_pca, kmeans_labels, "K-means", cluster_centers_pca)
                        st.plotly_chart(fig)
                        # Hi·ªÉn th·ªã s·ªë li·ªáu
                        st.subheader("C√°c s·ªë li·ªáu ph√¢n c·ª•m")
                        st.write(f"Silhouette Score: {silhouette:.4f}")
                        st.write(f"Calinski-Harabasz Score: {calinski:.4f}")
                        
                        # Nh·∫≠n c√°c v√≠ d·ª• v·ªÅ ch·ªØ s·ªë b·∫±ng c·ª•m
                        digit_examples = get_digit_examples_by_cluster(X_original, kmeans_labels)
                        
                        # Th√¥ng s·ªë v√† s·ªë li·ªáu ƒë·ªÉ l∆∞u v√†o MLflow
                        params = {
                            "algorithm": "KMeans",
                            "n_clusters": n_clusters,
                            "sample_size": sample_size
                        }
                        metrics = {
                            "silhouette_score": silhouette,
                            "calinski_harabasz_score": calinski
                        }
                        
                        # T·ª± ƒë·ªông l∆∞u m√¥ h√¨nh v√†o MLflow
                        run_id = log_model(kmeans_model, f"KMeans_k{n_clusters}", params, metrics, digit_examples, model_name)
                        st.success(f"M√¥ h√¨nh K-means ƒë∆∞·ª£c l∆∞u v√†o MLflow v·ªõi run ID: {run_id}")
                        
                        # Hi·ªÉn th·ªã c√°c ch·ªØ s·ªë m·∫´u t·ª´ m·ªói c·ª•m
                        st.subheader("C√°c ch·ªØ s·ªë m·∫´u t·ª´ m·ªói c·ª•m")
                        for cluster_idx in range(n_clusters): 
                            if cluster_idx in digit_examples:
                                st.write(f"Cluster {cluster_idx}")
                                cols = st.columns(5)
                                for i, col in enumerate(cols):
                                    if i < len(digit_examples[cluster_idx]):
                                        with col:
                                            fig, ax = plt.subplots(figsize=(2, 2))
                                            ax.imshow(digit_examples[cluster_idx][i].reshape(28, 28), cmap='gray')
                                            ax.axis('off')
                                            st.pyplot(fig)
                                            plt.close(fig)

            elif selected_tab == "DBSCAN":
                st.subheader("Ph√¢n c·ª•m DBSCAN")
                
                # DBSCAN parameters
                eps = st.slider("Epsilon", min_value=0.1, max_value=10.0, value=5.0, step=0.1)
                min_samples = st.slider("Min Samples", min_value=2, max_value=50, value=10)
                
                # Run DBSCAN button
                if st.button("Run DBSCAN"):
                    with st.spinner("Ch·∫°y ph√¢n c·ª•m DBSCAN ..."):
                        # Run DBSCAN
                        dbscan_model = run_dbscan(X_scaled, eps, min_samples)
                        dbscan_labels = dbscan_model.labels_
                        
                        # T√≠nh to√°n s·ªë li·ªáu n·∫øu c√≥ nhi·ªÅu h∆°n m·ªôt c·ª•m
                        n_clusters = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)
                        if n_clusters > 1: # C·∫ßn √≠t nh·∫•t 2 c·ª•m cho s·ªë li·ªáu
                            silhouette = silhouette_score(X_scaled, dbscan_labels)
                            calinski = calinski_harabasz_score(X_scaled, dbscan_labels)
                        else:
                            silhouette = 0
                            calinski = 0
                        
                        # Tr·ª±c quan h√≥a k·∫øt qu·∫£
                        fig = visualize_clusters(X_pca, dbscan_labels, "DBSCAN")
                        st.plotly_chart(fig)
                        
                        # Hi·ªÉn th·ªã s·ªë li·ªáu v√† s·ªë li·ªáu th·ªëng k√™
                        st.subheader("K·∫øt qu·∫£ ph√¢n c·ª•m")
                        st.write(f"S·ªë l∆∞·ª£ng c·ª•m ƒë∆∞·ª£c t√¨m th·∫•y: {n_clusters}")
                        noise_points = np.sum(dbscan_labels == -1)
                        st.write(f"S·ªë ƒëi·ªÉm nhi·ªÖu: {noise_points} ({noise_points / len(dbscan_labels) * 100:.2f}%)")
                        
                        st.subheader("C√°c s·ªë li·ªáu ph√¢n c·ª•m")
                        st.write(f"Silhouette Score: {silhouette:.4f}")
                        st.write(f"Calinski-Harabasz Score: {calinski:.4f}")
                        
                        # Nh·∫≠n c√°c v√≠ d·ª• v·ªÅ ch·ªØ s·ªë b·∫±ng c·ª•m
                        digit_examples = get_digit_examples_by_cluster(X_original, dbscan_labels)
                        
                        # Th√¥ng s·ªë v√† s·ªë li·ªáu ƒë·ªÉ l∆∞u v√†o MLflow
                        params = {
                            "algorithm": "DBSCAN",
                            "eps": eps,
                            "min_samples": min_samples,
                            "sample_size": sample_size
                        }
                        metrics = {
                            "silhouette_score": silhouette,
                            "calinski_harabasz_score": calinski,
                            "n_clusters": n_clusters,
                            "noise_percentage": noise_points / len(dbscan_labels) * 100
                        }
                        
                        # T·ª± ƒë·ªông l∆∞u m√¥ h√¨nh v√†o MLflow
                        run_id = log_model(dbscan_model, f"DBSCAN_eps{eps}_minSamples{min_samples}", params, metrics, digit_examples, model_name)
                        st.success(f"M√¥ h√¨nh DBSCAN ƒë∆∞·ª£c l∆∞u v√†o MLflow v·ªõi ID ch·∫°y: {run_id}")
                        
                        # Hi·ªÉn th·ªã c√°c ch·ªØ s·ªë m·∫´u t·ª´ m·ªói c·ª•m
                        st.subheader("C√°c ch·ªØ s·ªë m·∫´u t·ª´ m·ªói c·ª•m")
                        unique_labels = sorted(set(dbscan_labels))
                        if -1 in unique_labels: # X√≥a c·ª•m nhi·ªÖu ƒë·ªÉ tr·ª±c quan h√≥a
                            unique_labels.remove(-1)
                            
                        for cluster_idx in unique_labels:  # Hi·ªÉn th·ªã 3 c·ª•m ƒë·∫ßu ti√™n
                            if cluster_idx in digit_examples:
                                st.write(f"C·ª•m {cluster_idx}")
                                cols = st.columns(5)
                                for i, col in enumerate(cols):
                                    if i < len(digit_examples[cluster_idx]):
                                        with col:
                                            fig, ax = plt.subplots(figsize=(2, 2))
                                            ax.imshow(digit_examples[cluster_idx][i].reshape(28, 28), cmap='gray')
                                            ax.axis('off')
                                            st.pyplot(fig)
                                            plt.close(fig)
                        
                        # Hi·ªÉn th·ªã ƒëi·ªÉm nhi·ªÖu n·∫øu ch√∫ng t·ªìn t·∫°i
                        if -1 in dbscan_labels:
                            noise_indices = np.where(dbscan_labels == -1)[0]
                            if len(noise_indices) > 0:
                                st.write("ƒêi·ªÉm nhi·ªÖu m·∫´u")
                                cols = st.columns(5)
                                for i, col in enumerate(cols):
                                    if i < min(5, len(noise_indices)):
                                        idx = noise_indices[i]
                                        with col:
                                            fig, ax = plt.subplots(figsize=(2, 2))
                                            ax.imshow(X_original[idx].reshape(28, 28), cmap='gray')
                                            ax.axis('off')
                                            st.pyplot(fig)
                                            plt.close(fig)
        
        except Exception as e:
            st.error(f"Error: {e}")
            st.error(f"Error details: {str(e)}")
    with tab3:
        st.header("MLflow Tracking")
        
        # Setup MLflow client
        client = setup_mlflow()
        
        # Nh·∫≠n danh s√°ch c√°c th√≠ nghi·ªám
        experiments = list_experiments(client)
        
        if not experiments:
            st.warning("Kh√¥ng t√¨m th·∫•y th√≠ nghi·ªám n√†o trong MLflow. Vui l√≤ng ch·∫°y m·ªôt s·ªë thu·∫≠t to√°n ph√¢n c·ª•m tr∆∞·ªõc!")
        else:
            # Dropdown ƒë·ªÉ ch·ªçn experiment
            experiment_names = [exp.name for exp in experiments]
            selected_exp_name = st.selectbox("Ch·ªçn m·ªôt th√≠ nghi·ªám", experiment_names)
            
            # L·∫•y th√¥ng tin th√≠ nghi·ªám ƒë√£ ch·ªçn
            selected_exp = next((exp for exp in experiments if exp.name == selected_exp_name), None)
            
            if selected_exp:
                # L·∫•y danh s√°ch c√°c run trong experiment
                runs = list_runs(client, selected_exp.experiment_id)
                
                if not runs:
                    st.warning("Kh√¥ng t√¨m th·∫•y run n√†o trong th√≠ nghi·ªám n√†y!")
                else:
                    st.subheader("Danh s√°ch c√°c Run")
                    
                    # Ch·ª©c nƒÉng t√¨m ki·∫øm
                    search_query = st.text_input("T√¨m ki·∫øm theo t√™n m√¥ h√¨nh", "")
                    
                    # T·∫°o danh s√°ch th√¥ng tin run
                    run_data = []
                    for run in runs:
                        model_name = run.data.params.get("model_name", "Unknown")
                        algorithm = run.data.params.get("algorithm", "Unknown")
                        
                        # L·∫•y tham s·ªë ch√≠nh theo thu·∫≠t to√°n
                        if algorithm == "KMeans":
                            main_param = f"n_clusters={run.data.params.get('n_clusters', 'N/A')}"
                        elif algorithm == "DBSCAN":
                            main_param = f"eps={run.data.params.get('eps', 'N/A')}, min_samples={run.data.params.get('min_samples', 'N/A')}"
                        else:
                            main_param = "N/A"
                        
                        # L·∫•y metrics
                        silhouette = run.data.metrics.get("silhouette_score", "N/A")
                        calinski = run.data.metrics.get("calinski_harabasz_score", "N/A")
                        
                        run_data.append({
                            "Model Name": model_name,
                            "Algorithm": algorithm,
                            "Main Parameters": main_param,
                            "Silhouette Score": silhouette if silhouette != "N/A" else "N/A",
                            "Calinski-Harabasz Score": calinski if calinski != "N/A" else "N/A",
                            "Run ID": run.info.run_id,
                            "Start Time": run.info.start_time
                        })
                    
                    # Chuy·ªÉn th√†nh DataFrame ƒë·ªÉ d·ªÖ hi·ªÉn th·ªã
                    run_df = pd.DataFrame(run_data)
                    run_df["Start Time"] = pd.to_datetime(run_df["Start Time"]).dt.strftime('%Y-%m-%d %H:%M:%S')
                    
                    # L·ªçc theo t√¨m ki·∫øm
                    if search_query:
                        filtered_df = run_df[run_df["Model Name"].str.contains(search_query, case=False, na=False)]
                    else:
                        filtered_df = run_df
                    
                    # Hi·ªÉn th·ªã danh s√°ch run
                    st.dataframe(
                        filtered_df.drop("Run ID", axis=1),  # ·∫®n Run ID trong b·∫£ng hi·ªÉn th·ªã
                        use_container_width=True
                    )
                    
                    # Hi·ªÉn th·ªã chi ti·∫øt run khi ch·ªçn
                    selected_model = st.selectbox(
                        "Ch·ªçn m·ªôt m√¥ h√¨nh ƒë·ªÉ xem chi ti·∫øt",
                        options=filtered_df["Model Name"].tolist()
                    )
                    
                    if selected_model:
                        selected_run_id = filtered_df[filtered_df["Model Name"] == selected_model]["Run ID"].iloc[0]
                        run_details = get_model_details(client, selected_run_id)
                        
                        # Hi·ªÉn th·ªã parameters
                        st.write("**Parameters:**")
                        params_df = pd.DataFrame(
                            list(run_details.data.params.items()),
                            columns=["Parameter", "Value"]
                        )
                        st.dataframe(params_df)
                        
                        # Hi·ªÉn th·ªã metrics
                        st.write("**Metrics:**")
                        metrics_df = pd.DataFrame(
                            list(run_details.data.metrics.items()),
                            columns=["Metric", "Value"]
                        )
                        st.dataframe(metrics_df)
                        
                        # T·∫£i v√† hi·ªÉn th·ªã th√¥ng tin m√¥ h√¨nh
                        try:
                            model_uri = f"runs:/{selected_run_id}/model"
                            model = mlflow.sklearn.load_model(model_uri)
                            
                            if run_details.data.params.get("algorithm") == "KMeans":
                                st.write("**Cluster Centers Shape:**", model.cluster_centers_.shape)
                                st.write("**Iterations:**", model.n_iter_)
                                
                                # Hi·ªÉn th·ªã cluster centers (tr·ª±c quan h√≥a)
                                st.subheader("H√¨nh ·∫£nh tr·ª±c quan h√≥a")
                                cols = st.columns(5)
                                for i, col in enumerate(cols):
                                    if i < min(5, model.cluster_centers_.shape[0]):
                                        with col:
                                            fig, ax = plt.subplots(figsize=(5, 5),dpi=100)
                                            ax.imshow(model.cluster_centers_[i].reshape(28, 28), cmap='gray',interpolation='nearest')
                                            ax.set_title(f"Cluster {i}")
                                            ax.axis('off')
                                            st.pyplot(fig)
                                            plt.close(fig)
                            
                            elif run_details.data.params.get("algorithm") == "DBSCAN":
                                st.write("**Core Samples:**", len(model.core_sample_indices_))
                        
                        except Exception as e:
                            st.error(f"Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh: {e}")

if __name__ == "__main__":
    main()
