import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans, DBSCAN
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score, calinski_harabasz_score
import mlflow
import mlflow.sklearn
from sklearn.datasets import fetch_openml
import time
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Ti√™u ƒë·ªÅ ·ª©ng d·ª•ng
st.title("Ph√¢n c·ª•m d·ªØ li·ªáu MNIST v·ªõi K-means v√† DBSCAN")
st.write("·ª®ng d·ª•ng n√†y th·ª±c hi·ªán ph√¢n c·ª•m tr√™n t·∫≠p d·ªØ li·ªáu ch·ªØ s·ªë vi·∫øt tay MNIST")

# T·∫°o c√°c tab
tab1, tab2, tab3 = st.tabs(["T·ªïng quan l√Ω thuy·∫øt", "Ph√¢n c·ª•m ", "MLFlow"])

# Tab 1:  Ti·ªÅn x·ª≠ l√Ω
with tab1:
    st.write("##### L√≠ thuy·∫øt")


# Tab 2: Ph√¢n c·ª•m v√† ƒê√°nh gi√°
with tab2:
    st.write("##### T√πy ch·ªçn s·ªë l∆∞·ª£ng d·ªØ li·ªáu ")
    
    # T√πy ch·ªçn s·ªë l∆∞·ª£ng d·ªØ li·ªáu
    sample_size = st.slider("S·ªë l∆∞·ª£ng m·∫´u", 1000, 70000, 7000, key="sample_size_tab1")
    
    # T·∫£i d·ªØ li·ªáu MNIST
    @st.cache_data
    def load_mnist(sample_size):
        logger.info(f"ƒêang t·∫£i d·ªØ li·ªáu MNIST v·ªõi k√≠ch th∆∞·ªõc m·∫´u {sample_size}")
        
        # T·∫£i d·ªØ li·ªáu t·ª´ OpenML
        mnist = fetch_openml('mnist_784', version=1, parser='auto')
        X = mnist.data.astype('float32')
        y = mnist.target.astype('int')
        
        # L·∫•y m·∫´u ng·∫´u nhi√™n
        if sample_size < X.shape[0]:
            indices = np.random.choice(X.shape[0], sample_size, replace=False)
            X_sampled = X.iloc[indices] if hasattr(X, 'iloc') else X[indices]
            y_sampled = y.iloc[indices] if hasattr(y, 'iloc') else y[indices]
        else:
            X_sampled = X
            y_sampled = y
        
        logger.info(f"ƒê√£ t·∫£i xong d·ªØ li·ªáu MNIST: {X_sampled.shape}")
        st.text(f"S·ªë l∆∞·ª£ng m·∫´u : {X_sampled.shape[0]} m·∫´u v·ªõi {X_sampled.shape[1]} chi·ªÅu")
        
        return X_sampled, y_sampled
    
    # T·∫£i d·ªØ li·ªáu
    X, y = load_mnist(sample_size)
    
    # Hi·ªÉn th·ªã m·ªôt s·ªë ·∫£nh t·ª´ t·∫≠p d·ªØ li·ªáu
    def display_random_images(X, n_samples=10):
        st.write("##### Hi·ªÉn th·ªã m·ªôt s·ªë ·∫£nh t·ª´ t·∫≠p d·ªØ li·ªáu")
        
        # T·∫°o l∆∞·ªõi ƒë·ªÉ hi·ªÉn th·ªã ·∫£nh
        fig, axes = plt.subplots(1, n_samples, figsize=(15, 2))
        
        # Ch·ªçn ng·∫´u nhi√™n c√°c ch·ªâ s·ªë
        indices = np.random.choice(X.shape[0], n_samples, replace=False)
        
        # Hi·ªÉn th·ªã m·ªói ·∫£nh
        for i, idx in enumerate(indices):
            img = X.iloc[idx].values.reshape(28, 28)
            axes[i].imshow(img, cmap='gray')
            axes[i].axis('off')
        
        st.pyplot(fig)
    
    # Hi·ªÉn th·ªã ·∫£nh
    display_random_images(X)
    st.write("##### Ph√¢n c·ª•m v√† ƒê√°nh gi√°")
    
    # T√πy ch·ªçn thu·∫≠t to√°n
    algorithm = st.selectbox("Thu·∫≠t to√°n ph√¢n c·ª•m", ["K-means", "DBSCAN"], key="algorithm_tab2")
    
    if algorithm == "K-means":
        n_clusters = st.slider("S·ªë l∆∞·ª£ng c·ª•m (k)", 2, 20, 10, key="n_clusters_tab2")
        max_iter = st.slider("S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa", 100, 1000, 300, key="max_iter_tab2")
    elif algorithm == "DBSCAN":
        eps = st.slider("Epsilon (b√°n k√≠nh v√πng l√¢n c·∫≠n)", 0.1, 20.0, 5.0, key="eps_tab2")
        min_samples = st.slider("S·ªë l∆∞·ª£ng m·∫´u t·ªëi thi·ªÉu", 2, 100, 5, key="min_samples_tab2")
    
    # N√∫t "Ph√¢n c·ª•m"
    if st.button("Ph√¢n c·ª•m"):
        if algorithm == "K-means":
            # Th·ª±c hi·ªán K-means
            def run_kmeans(X, n_clusters, max_iter):
                logger.info(f"Th·ª±c hi·ªán K-means v·ªõi {n_clusters} c·ª•m")
                st.text(f"S·ªë c·ª•m : {n_clusters} c·ª•m")
                
                start_time = time.time()
                
                # Kh·ªüi t·∫°o v√† th·ª±c hi·ªán K-means
                kmeans = KMeans(n_clusters=n_clusters, max_iter=max_iter, random_state=42, n_init=10)
                clusters = kmeans.fit_predict(X)
                
                elapsed_time = time.time() - start_time
                logger.info(f"K-means ho√†n th√†nh trong {elapsed_time:.2f} gi√¢y")
                
                return clusters, kmeans
            
            clusters, model = run_kmeans(X, n_clusters, max_iter)
        
        elif algorithm == "DBSCAN":
            # Th·ª±c hi·ªán DBSCAN
            def run_dbscan(X, eps, min_samples):
                logger.info(f"Th·ª±c hi·ªán DBSCAN v·ªõi eps={eps}, min_samples={min_samples}")
                st.text(f"eps={eps}, min_samples={min_samples}")
                
                start_time = time.time()
                
                # Kh·ªüi t·∫°o v√† th·ª±c hi·ªán DBSCAN
                dbscan = DBSCAN(eps=eps, min_samples=min_samples)
                clusters = dbscan.fit_predict(X)
                
                elapsed_time = time.time() - start_time
                
                # X√°c ƒë·ªãnh s·ªë l∆∞·ª£ng c·ª•m (kh√¥ng t√≠nh ƒëi·ªÉm nhi·ªÖu -1)
                n_clusters = len(set(clusters)) - (1 if -1 in clusters else 0)
                n_noise = list(clusters).count(-1)
                
                logger.info(f"DBSCAN ho√†n th√†nh trong {elapsed_time:.2f} gi√¢y. T√¨m th·∫•y {n_clusters} c·ª•m v√† {n_noise} ƒëi·ªÉm nhi·ªÖu")
                st.text(f"T√¨m th·∫•y {n_clusters} c·ª•m v√† {n_noise} ƒëi·ªÉm nhi·ªÖu")
                
                return clusters, dbscan
            
            clusters, model = run_dbscan(X, eps, min_samples)
        
        # ƒê√°nh gi√° k·∫øt qu·∫£ ph√¢n c·ª•m
        def evaluate_clustering(X, clusters):
            results = {}
            
            # Ki·ªÉm tra n·∫øu c√≥ ƒëi·ªÉm nhi·ªÖu
            if -1 in clusters:
                st.warning("DBSCAN t√¨m th·∫•y ƒëi·ªÉm nhi·ªÖu. Lo·∫°i b·ªè ƒëi·ªÉm nhi·ªÖu ƒë·ªÉ t√≠nh to√°n ch·ªâ s·ªë ƒë√°nh gi√°.")
                
                # Lo·∫°i b·ªè ƒëi·ªÉm nhi·ªÖu
                valid_indices = clusters != -1
                X_valid = X[valid_indices]
                clusters_valid = clusters[valid_indices]
                
                # Ki·ªÉm tra s·ªë l∆∞·ª£ng c·ª•m h·ª£p l·ªá
                unique_clusters = set(clusters_valid)
                if len(unique_clusters) > 1:
                    # Silhouette Score
                    results["Silhouette Score"] = silhouette_score(X_valid, clusters_valid)
                    
                    # Calinski-Harabasz Index
                    results["Calinski-Harabasz Index"] = calinski_harabasz_score(X_valid, clusters_valid)
                else:
                    st.warning("Kh√¥ng th·ªÉ t√≠nh ch·ªâ s·ªë ƒë√°nh gi√° do ch·ªâ c√≥ m·ªôt c·ª•m sau khi lo·∫°i b·ªè ƒëi·ªÉm nhi·ªÖu.")
            else:
                # N·∫øu kh√¥ng c√≥ ƒëi·ªÉm nhi·ªÖu, t√≠nh to√°n ch·ªâ s·ªë b√¨nh th∆∞·ªùng
                unique_clusters = set(clusters)
                if len(unique_clusters) > 1:
                    # Silhouette Score
                    results["Silhouette Score"] = silhouette_score(X, clusters)
                    
                    # Calinski-Harabasz Index
                    results["Calinski-Harabasz Index"] = calinski_harabasz_score(X, clusters)
                else:
                    st.warning("Kh√¥ng th·ªÉ t√≠nh ch·ªâ s·ªë ƒë√°nh gi√° do ch·ªâ c√≥ m·ªôt c·ª•m.")
            
            return results
        
        # T√≠nh to√°n k·∫øt qu·∫£ ƒë√°nh gi√°
        evaluation_results = evaluate_clustering(X, clusters)
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£ ƒë√°nh gi√°
        st.markdown("##### K·∫øt qu·∫£ ƒë√°nh gi√° ph√¢n c·ª•m")
        if evaluation_results and isinstance(evaluation_results, dict):
            for metric, value in evaluation_results.items():
                st.write(f"{metric}: {value:.4f}")
        else:
            st.warning("Kh√¥ng c√≥ k·∫øt qu·∫£ ƒë√°nh gi√° n√†o ƒë∆∞·ª£c t√≠nh to√°n.")
        # H√†m tr·ª±c quan h√≥a k·∫øt qu·∫£ ph√¢n c·ª•m
        def visualize_clusters(X, clusters, y_true=None, algorithm_name=""):
            st.write(f"##### K·∫øt qu·∫£ ph√¢n c·ª•m {algorithm_name}")
            
            # S·ª≠ d·ª•ng PCA ƒë·ªÉ gi·∫£m chi·ªÅu d·ªØ li·ªáu
            if X.shape[1] > 2:
                st.text("S·ª≠ d·ª•ng PCA ƒë·ªÉ hi·ªÉn th·ªã trong kh√¥ng gian 2D")
                pca = PCA(n_components=2)
                X_2d = pca.fit_transform(X)
            else:
                X_2d = X
            
            # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì ph√¢n c·ª•m
            fig, ax = plt.subplots(1, 2, figsize=(16, 6))
            
            # V·∫Ω ph√¢n c·ª•m theo nh√≥m
            scatter = ax[0].scatter(X_2d[:, 0], X_2d[:, 1], c=clusters, cmap='viridis', alpha=0.5)
            ax[0].set_title(f'Ph√¢n c·ª•m {algorithm_name}')
            
            # Th√™m legend n·∫øu DBSCAN (ƒë·ªÉ hi·ªÉn th·ªã ƒëi·ªÉm nhi·ªÖu)
            if algorithm_name == "DBSCAN" and -1 in clusters:
                unique_clusters = np.unique(clusters)
                if len(unique_clusters) <= 20:  # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng nh√£n hi·ªÉn th·ªã
                    legend_labels = [f'C·ª•m {i}' for i in unique_clusters]
                    legend_labels[0] = 'Nhi·ªÖu' if unique_clusters[0] == -1 else legend_labels[0]
                    ax[0].legend(handles=scatter.legend_elements()[0], labels=legend_labels, loc="upper right")
            
            # V·∫Ω ph√¢n c·ª•m theo s·ªë th·∫≠t (n·∫øu c√≥)
            if y_true is not None:
                ax[1].scatter(X_2d[:, 0], X_2d[:, 1], c=y_true, cmap='tab10', alpha=0.5)
                ax[1].set_title('Ph√¢n lo·∫°i th·ª±c t·∫ø (digit)')
            else:
                ax[1].axis('off')
            
            st.pyplot(fig)

        # H√†m hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt v·ªÅ t·ª´ng c·ª•m d∆∞·ªõi d·∫°ng b·∫£ng
        def display_cluster_info(X, clusters):
            st.subheader("Th√¥ng tin chi ti·∫øt v·ªÅ t·ª´ng c·ª•m")
            
            # L·∫•y c√°c c·ª•m duy nh·∫•t
            unique_clusters = np.unique(clusters)
            
            # T·∫°o m·ªôt danh s√°ch ƒë·ªÉ l∆∞u th√¥ng tin t·ª´ng c·ª•m
            cluster_info = []
            
            for cluster_id in unique_clusters:
                cluster_name = f"C·ª•m {cluster_id}" if cluster_id != -1 else "ƒêi·ªÉm nhi·ªÖu (c·ª•m -1)"
                
                # L·∫•y c√°c ch·ªâ s·ªë c·ªßa c√°c ƒëi·ªÉm trong c·ª•m n√†y
                indices = np.where(clusters == cluster_id)[0]
                
                # T√≠nh s·ªë l∆∞·ª£ng ƒëi·ªÉm d·ªØ li·ªáu trong c·ª•m
                n_samples = len(indices)
                
                # Th√™m th√¥ng tin v√†o danh s√°ch
                cluster_info.append({
                    "T√™n c·ª•m": cluster_name,
                    "S·ªë l∆∞·ª£ng ƒëi·ªÉm d·ªØ li·ªáu": n_samples
                })
            
            # T·∫°o DataFrame t·ª´ danh s√°ch th√¥ng tin
            cluster_df = pd.DataFrame(cluster_info)
            
            # Hi·ªÉn th·ªã b·∫£ng th√¥ng tin
            st.dataframe(cluster_df)

        # H√†m hi·ªÉn th·ªã m·ªôt s·ªë ·∫£nh t·ª´ m·ªói c·ª•m
        def display_cluster_examples(X, clusters, n_clusters=10, n_samples=5):
            st.subheader("Hi·ªÉn th·ªã m·ªôt s·ªë ·∫£nh t·ª´ m·ªói c·ª•m")
            
            # T√πy ch·ªçn s·ªë l∆∞·ª£ng c·ª•m hi·ªÉn th·ªã
            n_clusters = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng c·ª•m hi·ªÉn th·ªã", 1, 20, 10, key="n_clusters_display")
            
            # T√πy ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh hi·ªÉn th·ªã t·ª´ m·ªói c·ª•m
            n_samples = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh hi·ªÉn th·ªã t·ª´ m·ªói c·ª•m", 1, 10, 5, key="n_samples_display")
            
            # L·∫•y c√°c c·ª•m duy nh·∫•t
            unique_clusters = np.unique(clusters)
            n_unique = min(len(unique_clusters), n_clusters)
            
            # Ch·ªâ hi·ªÉn th·ªã n_clusters ƒë·∫ßu ti√™n
            display_clusters = unique_clusters[:n_clusters]
            
            # ƒê·ªëi v·ªõi m·ªói c·ª•m, hi·ªÉn th·ªã m·ªôt s·ªë ·∫£nh m·∫´u
            for cluster_id in display_clusters:
                cluster_name = f"C·ª•m {cluster_id}" if cluster_id != -1 else "ƒêi·ªÉm nhi·ªÖu (c·ª•m -1)"
                st.write(f"### {cluster_name}")
                
                # L·∫•y c√°c ch·ªâ s·ªë c·ªßa c√°c ƒëi·ªÉm trong c·ª•m n√†y
                indices = np.where(clusters == cluster_id)[0]
                
                # N·∫øu kh√¥ng c√≥ ƒë·ªß m·∫´u trong c·ª•m, hi·ªÉn th·ªã t·∫•t c·∫£
                n_to_display = min(len(indices), n_samples)
                
                if n_to_display > 0:
                    # Ch·ªçn ng·∫´u nhi√™n c√°c m·∫´u ƒë·ªÉ hi·ªÉn th·ªã
                    display_indices = np.random.choice(indices, n_to_display, replace=False)
                    
                    # T·∫°o l∆∞·ªõi ƒë·ªÉ hi·ªÉn th·ªã ·∫£nh
                    fig, axes = plt.subplots(1, n_to_display, figsize=(15, 2))
                    
                    # Tr∆∞·ªùng h·ª£p ch·ªâ c√≥ 1 ·∫£nh
                    if n_to_display == 1:
                        img = X[display_indices[0]].reshape(28, 28)
                        axes.imshow(img, cmap='gray')
                        axes.axis('off')
                    else:
                        # Hi·ªÉn th·ªã m·ªói ·∫£nh
                        for i, idx in enumerate(display_indices):
                            img = X.iloc[idx].values.reshape(28, 28)
                            axes[i].imshow(img, cmap='gray')
                            axes[i].axis('off')
                    
                    st.pyplot(fig)
                else:
                    st.write("Kh√¥ng c√≥ m·∫´u n√†o trong c·ª•m n√†y")

        # G·ªçi c√°c h√†m ƒë·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£
        visualize_clusters(X, clusters, y, algorithm)
        display_cluster_info(X, clusters)
        display_cluster_examples(X, clusters)

        st.write("##### L∆∞u k·∫øt qu·∫£ ph√¢n c·ª•m v√†o MLFlow")
        user_name = st.text_input("Nh·∫≠p t√™n c·ªßa b·∫°n ƒë·ªÉ l∆∞u k·∫øt qu·∫£ ph√¢n c·ª•m", key="user_name_tab2")
        
        if user_name:
            if st.button("L∆∞u k·∫øt qu·∫£ ph√¢n c·ª•m v√†o MLFlow"):
                if 'model' in locals() and 'clusters' in locals():
                    with mlflow.start_run(run_name=f"Clustering_{user_name}"):
                        # Log ph∆∞∆°ng ph√°p ph√¢n c·ª•m
                        mlflow.log_param("Algorithm", algorithm)
                        
                        # Log th√¥ng tin c·ª• th·ªÉ v·ªÅ ph∆∞∆°ng ph√°p ph√¢n c·ª•m
                        if algorithm == "K-means":
                            mlflow.log_param("n_clusters", n_clusters)
                            mlflow.log_param("max_iter", max_iter)
                        elif algorithm == "DBSCAN":
                            mlflow.log_param("eps", eps)
                            mlflow.log_param("min_samples", min_samples)
                            mlflow.log_param("n_clusters", len(set(clusters)) - (1 if -1 in clusters else 0))
                            mlflow.log_param("n_noise", list(clusters).count(-1))
                        
                        # Log ch·ªâ s·ªë ƒë√°nh gi√°
                        if evaluation_results:
                            for metric, value in evaluation_results.items():
                                mlflow.log_metric(metric, value)
                        
                        # Log m√¥ h√¨nh
                        mlflow.sklearn.log_model(model, "model")
                        
                        st.success(f"K·∫øt qu·∫£ ph√¢n c·ª•m ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o MLFlow v·ªõi t√™n {user_name}.")
                else:
                    st.warning("Vui l√≤ng th·ª±c hi·ªán ph√¢n c·ª•m tr∆∞·ªõc khi l∆∞u k·∫øt qu·∫£.")
            

with tab3:
    st.header("üìä MLflow Tracking")

    # # K·∫øt n·ªëi ƒë·∫øn MLflow
    # mlflow.set_tracking_uri("http://127.0.0.1:5000")  # ƒê·∫£m b·∫£o MLflow server ƒëang ch·∫°y

    # T√¨m ki·∫øm m√¥ h√¨nh theo t√™n
    search_name = st.text_input("üîç Nh·∫≠p t√™n m√¥ h√¨nh ƒë·ªÉ t√¨m ki·∫øm:", "")

    # L·∫•y danh s√°ch c√°c phi√™n l√†m vi·ªác t·ª´ MLflow
    if search_name:
        runs = mlflow.search_runs(filter_string=f"tags.mlflow.runName LIKE '%{search_name}%'", order_by=["start_time desc"])
    else:
        runs = mlflow.search_runs(order_by=["start_time desc"])

    if not runs.empty:
        # Hi·ªÉn th·ªã danh s√°ch c√°c m√¥ h√¨nh
        st.write("### üìú Danh s√°ch m√¥ h√¨nh ƒë√£ l∆∞u:")
        st.dataframe(runs[["tags.mlflow.runName", "run_id"]])

        # Ch·ªçn m·ªôt m√¥ h√¨nh ƒë·ªÉ xem chi ti·∫øt
        selected_run_id = st.selectbox("üìù Ch·ªçn m·ªôt m√¥ h√¨nh ƒë·ªÉ xem chi ti·∫øt:", runs["run_id"].tolist())

        if selected_run_id:
            # L·∫•y th√¥ng tin chi ti·∫øt v·ªÅ run ƒë∆∞·ª£c ch·ªçn
            run_details = mlflow.get_run(selected_run_id)
            st.write(f"### üîç Chi ti·∫øt m√¥ h√¨nh: `{run_details.data.tags.get('mlflow.runName', 'Kh√¥ng c√≥ t√™n')}`")
            st.write("**üü¢ Tr·∫°ng th√°i:**", run_details.info.status)
            st.write("**‚è≥ Th·ªùi gian b·∫Øt ƒë·∫ßu:**", run_details.info.start_time)
            st.write("**üèÅ Th·ªùi gian k·∫øt th√∫c:**", run_details.info.end_time)

            # Hi·ªÉn th·ªã tham s·ªë
            st.write("üìå **Tham s·ªë:**")
            for key, value in run_details.data.params.items():
                st.write(f"- **{key}**: {value}")

            # Hi·ªÉn th·ªã metric
            st.write("üìä **Metric:**")
            for key, value in run_details.data.metrics.items():
                st.write(f"- **{key}**: {value}")

            # Hi·ªÉn th·ªã artifacts (n·∫øu c√≥)
            st.write("üìÇ **Artifacts:**")
            if run_details.info.artifact_uri:
                st.write(f"- **Artifact URI**: {run_details.info.artifact_uri}")
                # T·∫£i m√¥ h√¨nh t·ª´ artifact
                if st.button("T·∫£i m√¥ h√¨nh", key=f"load_{selected_run_id}"):
                    model = mlflow.sklearn.load_model(f"runs:/{selected_run_id}/model")
                    st.success(f"ƒê√£ t·∫£i m√¥ h√¨nh {run_details.data.tags.get('mlflow.runName', 'Kh√¥ng c√≥ t√™n')} th√†nh c√¥ng!")
                    st.write(f"Th√¥ng tin m√¥ h√¨nh: {model}")
            else:
                st.write("- Kh√¥ng c√≥ artifacts n√†o.")

    else:
        st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh n√†o.")
