import streamlit as st
import mlflow
import mlflow.sklearn
import numpy as np
import cv2
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.metrics import accuracy_score
from streamlit_drawable_canvas import st_canvas
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.patches import Circle, Rectangle
from sklearn.neural_network import MLPClassifier
import time

# Kh·ªüi t·∫°o session state
if 'model' not in st.session_state:
    st.session_state.model = None
if 'data_split' not in st.session_state:
    st.session_state.data_split = None
if 'params' not in st.session_state:
    st.session_state.params = None
if 'cv_folds' not in st.session_state:
    st.session_state.cv_folds = 3  # M·∫∑c ƒë·ªãnh 3 fold
if 'custom_model_name' not in st.session_state:
    st.session_state.custom_model_name = ""
if 'trained_models' not in st.session_state:
    st.session_state.trained_models = {}
if 'training_metrics' not in st.session_state:
    st.session_state.training_metrics = {}

# üìå T·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu MNIST t·ª´ OpenML
@st.cache_data
def load_data(n_samples=None):
    mnist = fetch_openml("mnist_784", version=1, as_frame=False, parser='liac-arff')
    X, y = mnist.data[:n_samples], mnist.target[:n_samples].astype(int)
    X = X / 255.0
    return X, y

# üìå Chia d·ªØ li·ªáu th√†nh train, validation, v√† test
@st.cache_data
def split_data(X, y, train_size=0.7, val_size=0.15, test_size=0.15, random_state=42):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X_train, y_train, test_size=val_size / (train_size + val_size), random_state=random_state
    )
    return X_train, X_val, X_test, y_train, y_val, y_test

# üìå Visualize m·∫°ng n∆°-ron v·ªõi k·∫øt qu·∫£ d·ª± ƒëo√°n
def visualize_neural_network_prediction(model, input_image, predicted_label):
    hidden_layer_sizes = model.hidden_layer_sizes
    if isinstance(hidden_layer_sizes, int):
        hidden_layer_sizes = [hidden_layer_sizes]
    elif isinstance(hidden_layer_sizes, tuple):
        hidden_layer_sizes = list(hidden_layer_sizes)

    input_layer_size = 784
    output_layer_size = 10
    layer_sizes = [input_layer_size] + hidden_layer_sizes + [output_layer_size]
    num_layers = len(layer_sizes)

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), gridspec_kw={'width_ratios': [1, 3]})

    ax1.imshow(input_image.reshape(28, 28), cmap='gray')
    ax1.set_title("Input Image")
    ax1.axis('off')

    pos = {}
    layer_names = ['Input', 'Hidden 1', 'Hidden 2', 'Output'] if len(hidden_layer_sizes) == 2 else ['Input'] + [f'Hidden {i+1}' for i in range(len(hidden_layer_sizes))] + ['Output']

    for layer_idx, layer_size in enumerate(layer_sizes):
        for neuron_idx in range(layer_size):
            if layer_size > 20 and layer_idx == 0:
                if neuron_idx < 10 or neuron_idx >= layer_size - 10:
                    pos[(layer_idx, neuron_idx)] = (layer_idx, neuron_idx / layer_size)
                elif neuron_idx == 10:
                    pos[('dots', layer_idx)] = (layer_idx, 0.5)
            else:
                pos[(layer_idx, neuron_idx)] = (layer_idx, neuron_idx / (layer_size - 1) if layer_size > 1 else 0.5)

    for layer_idx, layer_size in enumerate(layer_sizes):
        for neuron_idx in range(layer_size):
            if layer_size > 20 and layer_idx == 0 and neuron_idx >= 10 and neuron_idx < layer_size - 10:
                continue
            
            x, y = pos[(layer_idx, neuron_idx)]
            circle = Circle((x, y), 0.05, color='white', ec='black')
            ax2.add_patch(circle)
            
            if layer_idx == num_layers - 1:
                ax2.text(x + 0.2, y, f"{neuron_idx}", fontsize=12, color='white')
            
            if layer_idx == num_layers - 1 and neuron_idx == predicted_label:
                square = Rectangle((x - 0.07, y - 0.07), 0.14, 0.14, fill=False, edgecolor='yellow', linewidth=2)
                ax2.add_patch(square)

    if ('dots', 0) in pos:
        x, y = pos[('dots', 0)]
        ax2.text(x, y, "...", fontsize=12, color='white', ha='center', va='center')

    for layer_idx in range(len(layer_sizes) - 1):
        current_layer_size = layer_sizes[layer_idx]
        next_layer_size = layer_sizes[layer_idx + 1]

        if layer_idx == 0 and current_layer_size > 20:
            neuron_indices_1 = list(range(5)) + list(range(current_layer_size - 5, current_layer_size))
        else:
            neuron_indices_1 = range(current_layer_size)

        if layer_idx == len(layer_sizes) - 2:
            neuron_indices_2 = [predicted_label]
        else:
            if next_layer_size > 10:
                neuron_indices_2 = list(range(5)) + list(range(next_layer_size - 5, next_layer_size))
            else:
                neuron_indices_2 = range(next_layer_size)

        for idx1, neuron1 in enumerate(neuron_indices_1):
            for idx2, neuron2 in enumerate(neuron_indices_2):
                x1, y1 = pos[(layer_idx, neuron1)]
                x2, y2 = pos[(layer_idx + 1, neuron2)]
                color = plt.cm.coolwarm(idx2 / max(len(neuron_indices_2), 1))
                ax2.plot([x1, x2], [y1, y2], color=color, alpha=0.5, linewidth=1)

    ax2.set_xlim(-0.5, num_layers - 0.5)
    ax2.set_ylim(-0.1, 1.1)
    ax2.set_xticks(range(num_layers))
    ax2.set_xticklabels(layer_names)
    ax2.set_yticks([])
    ax2.set_title(f"Neural Network Prediction: {predicted_label}")
    ax2.set_facecolor('black')

    return fig

# üìå Hu·∫•n luy·ªán m√¥ h√¨nh 
def train_model(custom_model_name, params, X_train, X_val, X_test, y_train, y_val, y_test, cv_folds):
    progress_bar = st.progress(0)
    status_text = st.empty()
    metrics_container = st.empty()
    metrics_plot = st.empty()
    
    # Kh·ªüi t·∫°o c√°c m·∫£ng ƒë·ªÉ l∆∞u tr·ªØ gi√° tr·ªã metrics qua c√°c epoch
    epochs = params["epochs"]
    train_acc_history = []
    val_acc_history = []
    
    hidden_layer_sizes = tuple([params["neurons_per_layer"]] * params["num_hidden_layers"])
    model = MLPClassifier(
        hidden_layer_sizes=hidden_layer_sizes,
        max_iter=1,
        activation=params["activation"],
        learning_rate_init=params["learning_rate"],
        solver='adam',
        alpha=0.0001,
        random_state=42,
        warm_start=True,
        batch_size=min(256, len(X_train))  # T·ªëi ∆∞u h√≥a v·ªõi batch_size
    )
    
    # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ ki·∫øn tr√∫c m·∫°ng
    layers_info = f"üß† Ki·∫øn tr√∫c m·∫°ng: Input(784) ‚Üí "
    for i in range(params["num_hidden_layers"]):
        layers_info += f"Hidden{i+1}({params['neurons_per_layer']}) ‚Üí "
    layers_info += "Output(10)"
    st.info(layers_info)
    
    train_start_time = time.time()
    
    try:
        with mlflow.start_run(run_name=custom_model_name):
            for epoch in range(epochs):
                epoch_start_time = time.time()
                
                # Hu·∫•n luy·ªán m√¥ h√¨nh
                model.fit(X_train, y_train)
                
                # Ch·ªâ t√≠nh ƒë·ªô ch√≠nh x√°c ·ªü m·ªôt s·ªë epoch nh·∫•t ƒë·ªãnh ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô
                if epoch % max(1, epochs // 10) == 0 or epoch == epochs - 1:
                    y_train_pred = model.predict(X_train)
                    y_val_pred = model.predict(X_val)
                    
                    train_accuracy = accuracy_score(y_train, y_train_pred)
                    val_accuracy = accuracy_score(y_val, y_val_pred)
                    
                    train_acc_history.append(train_accuracy)
                    val_acc_history.append(val_accuracy)
                
                # Hi·ªÉn th·ªã ti·∫øn tr√¨nh
                progress = (epoch + 1) / epochs
                progress_bar.progress(progress)
                
                # T√≠nh th·ªùi gian trung b√¨nh m·ªói epoch
                epoch_time = time.time() - epoch_start_time
                elapsed_time = time.time() - train_start_time
                eta = (epochs - (epoch + 1)) * (elapsed_time / (epoch + 1))  # D·ª± ƒëo√°n ETA ch√≠nh x√°c h∆°n
                
                # Thanh ti·∫øn tr√¨nh chi ti·∫øt v·ªõi HTML
                status_html = f"""
                <div style="display: flex; justify-content: space-between; padding: 10px; background-color: #f0f2f6; border-radius: 5px; margin-bottom: 10px;">
                    <div>
                        <span style="font-weight: bold;">‚è≥ Epoch {epoch + 1}/{epochs}</span> 
                        <span style="margin-left: 15px;">‚è±Ô∏è {epoch_time:.2f}s/epoch</span>
                    </div>
                    <div>
                        <span style="margin-right: 15px;">üïí ƒê√£ tr√¥i qua: {elapsed_time:.2f}s</span>
                        <span>‚åõ ETA: {eta:.2f}s</span>
                    </div>
                </div>
                """
                status_text.markdown(status_html, unsafe_allow_html=True)
                
                # Hi·ªÉn th·ªã metrics n·∫øu c√≥
                if train_acc_history and epoch % max(1, epochs // 10) == 0:
                    metrics_html = f"""
                    <div style="display: flex; justify-content: space-between; padding: 10px; background-color: #e6f3ff; border-radius: 5px;">
                        <div style="text-align: center; flex: 1;">
                            <div style="font-size: 24px; font-weight: bold;">{train_acc_history[-1]:.4f}</div>
                            <div>Train Accuracy</div>
                        </div>
                        <div style="text-align: center; flex: 1;">
                            <div style="font-size: 24px; font-weight: bold;">{val_acc_history[-1]:.4f}</div>
                            <div>Validation Accuracy</div>
                        </div>
                    </div>
                    """
                    metrics_container.markdown(metrics_html, unsafe_allow_html=True)
                
                # V·∫Ω bi·ªÉu ƒë·ªì ti·∫øn tr√¨nh
                if train_acc_history and epoch > 0 and epoch % max(1, epochs // 10) == 0:
                    fig, ax = plt.subplots(figsize=(10, 4))
                    epochs_range = list(range(1, len(train_acc_history) + 1))
                    ax.plot(epochs_range, train_acc_history, 'b-', label='Train Accuracy')
                    ax.plot(epochs_range, val_acc_history, 'r-', label='Validation Accuracy')
                    ax.set_xlabel('Epoch')
                    ax.set_ylabel('Accuracy')
                    ax.set_title('Training Progress')
                    ax.legend()
                    ax.grid(True)
                    metrics_plot.pyplot(fig)
                    plt.close(fig)
                
                # L∆∞u metrics cu·ªëi c√πng
                if epoch == epochs - 1:
                    y_train_pred = model.predict(X_train)
                    y_val_pred = model.predict(X_val)
                    train_accuracy = accuracy_score(y_train, y_train_pred)
                    val_accuracy = accuracy_score(y_val, y_val_pred)
                    st.session_state.training_metrics[custom_model_name] = {
                        'train_accuracy_history': train_acc_history,
                        'val_accuracy_history': val_acc_history,
                        'final_train_accuracy': train_accuracy,
                        'final_val_accuracy': val_accuracy
                    }
                
                # L∆∞u metrics v√†o MLflow
                if epoch % max(1, epochs // 10) == 0 or epoch == epochs - 1:
                    mlflow.log_metric("train_accuracy_epoch_" + str(epoch + 1), train_accuracy)
                    mlflow.log_metric("val_accuracy_epoch_" + str(epoch + 1), val_accuracy)
                
            # ƒê√°nh gi√° tr√™n t·∫≠p test
            y_test_pred = model.predict(X_test)
            test_accuracy = accuracy_score(y_test, y_test_pred)
            
            # Cross-Validation
            cv_status = st.empty()
            cv_status.info("‚è≥ ƒêang th·ª±c hi·ªán Cross-Validation...")
            cv_model = MLPClassifier(
                hidden_layer_sizes=hidden_layer_sizes,
                max_iter=params["epochs"],
                activation=params["activation"],
                learning_rate_init=params["learning_rate"],
                solver='adam',
                alpha=0.0001,
                random_state=42,
                batch_size=min(256, len(X_train))
            )
            cv = KFold(n_splits=cv_folds, shuffle=True, random_state=42)
            cv_scores = cross_val_score(cv_model, X_train, y_train, cv=cv, n_jobs=-1)
            cv_mean_accuracy = np.mean(cv_scores)
            cv_status.success(f"‚úÖ Cross-Validation ho√†n t·∫•t: {cv_mean_accuracy:.4f}")
            
            # Log v√†o MLflow
            mlflow.log_param("model_name", "Neural Network")
            mlflow.log_params(params)
            mlflow.log_param("cv_folds", cv_folds)
            mlflow.log_metric("train_accuracy", train_accuracy)
            mlflow.log_metric("val_accuracy", val_accuracy)
            mlflow.log_metric("test_accuracy", test_accuracy)
            mlflow.log_metric("cv_mean_accuracy", cv_mean_accuracy)
            mlflow.log_metric("training_time", time.time() - train_start_time)
            mlflow.sklearn.log_model(model, "Neural Network")
            
            # Hi·ªÉn th·ªã th√¥ng tin t·ªïng quan
            training_time = time.time() - train_start_time
            st.success(f"‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t trong {training_time:.2f} gi√¢y!")
            
    except Exception as e:
        st.error(f"‚ùå L·ªói trong qu√° tr√¨nh hu·∫•n luy·ªán: {str(e)}")
        return None, None, None, None, None

    return model, train_accuracy, val_accuracy, test_accuracy, cv_mean_accuracy

# üìå X·ª≠ l√Ω ·∫£nh t·∫£i l√™n
def preprocess_uploaded_image(image):
    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    image = cv2.resize(image, (28, 28))
    image = image / 255.0
    return image.reshape(1, -1)

# üìå X·ª≠ l√Ω ·∫£nh t·ª´ v·∫Ω tay tr√™n canvas
def preprocess_canvas_image(canvas):
    image = np.array(canvas)
    image = cv2.cvtColor(image, cv2.COLOR_RGBA2GRAY)
    image = cv2.bitwise_not(image)
    image = cv2.resize(image, (28, 28))
    image = image / 255.0
    return image.reshape(1, -1)

def show_sample_images(X, y):
    st.write("**üñºÔ∏è M·ªôt v√†i m·∫´u d·ªØ li·ªáu t·ª´ MNIST**")
    fig, axes = plt.subplots(1, 10, figsize=(15, 3))
    for digit in range(10):
        idx = np.where(y == digit)[0][0]
        ax = axes[digit]
        ax.imshow(X[idx].reshape(28, 28), cmap='gray')
        ax.set_title(f"{digit}")
        ax.axis('off')
    st.pyplot(fig)

# üìå Hi·ªÉn th·ªã k·∫øt qu·∫£ hu·∫•n luy·ªán
def display_training_results(model_name, train_accuracy, val_accuracy, test_accuracy, cv_mean_accuracy):
    result_container = st.container()
    with result_container:
        st.write("### üìä K·∫øt qu·∫£ hu·∫•n luy·ªán")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric(label="Train Accuracy", value=f"{train_accuracy:.4f}")
        with col2:
            st.metric(label="Validation Accuracy", value=f"{val_accuracy:.4f}")
        with col3:
            st.metric(label="Test Accuracy", value=f"{test_accuracy:.4f}")
        with col4:
            st.metric(label="CV Accuracy", value=f"{cv_mean_accuracy:.4f}")
        
        # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì ti·∫øn tr√¨nh n·∫øu c√≥
        if model_name in st.session_state.training_metrics:
            train_history = st.session_state.training_metrics[model_name]['train_accuracy_history']
            val_history = st.session_state.training_metrics[model_name]['val_accuracy_history']
            
            fig, ax = plt.subplots(figsize=(10, 4))
            epochs_range = list(range(1, len(train_history) + 1))
            ax.plot(epochs_range, train_history, 'b-', label='Train Accuracy')
            ax.plot(epochs_range, val_history, 'r-', label='Validation Accuracy')
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Accuracy')
            ax.set_title('Training Progress')
            ax.legend()
            ax.grid(True)
            st.pyplot(fig)

# üìå Giao di·ªán Streamlit
def create_streamlit_app():
    st.title("üî¢ Ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay")
    
    tab1, tab2, tab3, tab4 = st.tabs(["üìì L√≠ thuy·∫øt", "üìã Hu·∫•n luy·ªán", "üîÆ D·ª± ƒëo√°n", "‚ö° MLflow"])
    
    with tab1:
        st.write("##### Neural Network")
        st.write("""Neural Network l√† m·ªôt ph∆∞∆°ng th·ª©c ph·ªï bi·∫øn trong lƒ©nh v·ª±c tr√≠ tu·ªá nh√¢n t·∫°o, ƒë∆∞·ª£c d√πng ƒë·ªÉ ƒëi·ªÅu khi·ªÉn m√°y t√≠nh d·ª± ƒëo√°n, nh·∫≠n d·∫°ng v√† x·ª≠ l√Ω d·ªØ li·ªáu nh∆∞ m·ªôt b·ªô n√£o c·ªßa con ng∆∞·ªùi. 
        B√™n c·∫°nh ƒë√≥, quy tr√¨nh n√†y c√≤n ƒë∆∞·ª£c bi·∫øt ƒë·∫øn v·ªõi thu·∫≠t ng·ªØ quen thu·ªôc l√† "deep learning", nghƒ©a l√† vi·ªác v·∫≠n d·ª•ng c√°c n∆°-ron ho·∫∑c c√°c n√∫t t·∫°o s·ª± li√™n k·∫øt v·ªõi nhau trong c√πng m·ªôt c·∫•u tr√∫c ph√¢n l·ªõp.""")
        st.write("##### 1. ƒê·∫∑c ƒëi·ªÉm c·ªßa Neural Network")
        st.write("""- M·∫°ng l∆∞·ªõi n∆°-ron nh√¢n t·∫°o ho·∫°t ƒë·ªông nh∆∞ n∆°-ron trong n√£o b·ªô con ng∆∞·ªùi. Trong ƒë√≥, m·ªói n∆°-ron l√† m·ªôt h√†m to√°n h·ªçc, c√≥ ch·ª©c nƒÉng thu th·∫≠p v√† ph√¢n lo·∫°i d·ªØ li·ªáu, th√¥ng tin theo c·∫•u tr√∫c chi ti·∫øt. 
        \n- Neural Network t∆∞∆°ng ƒë·ªìng v·ªõi nh·ªØng ph∆∞∆°ng ph√°p th·ªëng k√™ theo ƒë·ªì th·ªã ƒë∆∞·ªùng cong ho·∫∑c ph√¢n t√≠ch h·ªìi quy. ƒê·ªÉ gi·∫£i th√≠ch ƒë∆°n gi·∫£n nh·∫•t, b·∫°n h√£y h√¨nh dung Neural Network bao h√†m c√°c n√∫t m·∫°ng li√™n k·∫øt v·ªõi nhau. 
        \n- M·ªói n√∫t l√† m·ªôt t·∫≠p h·ª£p tri gi√°c, c·∫•u t·∫°o t∆∞∆°ng t·ª± h√†m h·ªìi quy ƒëa tuy·∫øn t√≠nh, ƒë∆∞·ª£c s·∫Øp x·∫øp li√™n k·∫øt v·ªõi nhau. C√°c l·ªõp n√†y s·∫Ω thu th·∫≠p th√¥ng tin, sau ƒë√≥ ph√¢n lo·∫°i v√† ph√°t t√≠n hi·ªáu ƒë·∫ßu ra t∆∞∆°ng ·ª©ng.
        """)
        st.write("##### 2. C·∫•u tr√∫c m·∫°ng Neural Network")
        st.write("""- Input Layer (t·∫ßng ƒë·∫ßu v√†o): N·∫±m b√™n tr√°i c·ªßa h·ªá th·ªëng, bao g·ªìm d·ªØ li·ªáu th√¥ng tin ƒë·∫ßu v√†o. 
        \n- Output Layer (t·∫ßng ƒë·∫ßu ra): N·∫±m b√™n ph·∫£i c·ªßa h·ªá th·ªëng, bao g·ªìm d·ªØ li·ªáu th√¥ng tin ƒë·∫ßu ra. 
        \n- Hidden Layer (t·∫ßng ·∫©n): N·∫±m ·ªü gi·ªØa t·∫ßng ƒë·∫ßu v√†o v√† ƒë·∫ßu ra, th·ªÉ hi·ªán qu√° tr√¨nh suy lu·∫≠n v√† x·ª≠ l√Ω th√¥ng tin c·ªßa h·ªá th·ªëng.    
        """)
        st.image("neural_networks.png", caption="C·∫•u tr√∫c m·∫°ng Neural Network", width=500)
        st.write("V√≠ d·ª• minh h·ªça v·ªõi b·ªô d·ªØ li·ªáu mnist : ")
        st.image("mau.png", caption="Ngu·ªìn : https://www.researchgate.net/", width=700)
        st.write("##### 3. C√°c tham s·ªë quan tr·ªçng")
        st.write("""**a. S·ªë l·ªõp ·∫©n (num_hidden_layers)**:
        \n- ƒê√¢y l√† s·ªë l∆∞·ª£ng t·∫ßng ·∫©n trong m·∫°ng n∆°-ron. Nhi·ªÅu t·∫ßng ·∫©n h∆°n c√≥ th·ªÉ gi√∫p m√¥ h√¨nh h·ªçc ƒë∆∞·ª£c c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p h∆°n, nh∆∞ng c≈©ng l√†m tƒÉng ƒë·ªô ph·ª©c t·∫°p t√≠nh to√°n.
        \n**b. S·ªë neuron m·ªói l·ªõp (neurons_per_layer)**:
        \n- ƒê√¢y l√† s·ªë l∆∞·ª£ng n∆°-ron trong m·ªói t·∫ßng ·∫©n. S·ªë l∆∞·ª£ng n∆°-ron ·∫£nh h∆∞·ªüng ƒë·∫øn kh·∫£ nƒÉng h·ªçc c√°c ƒë·∫∑c tr∆∞ng t·ª´ d·ªØ li·ªáu.
        \n**c. Epochs**:
        \n- ƒê√¢y l√† s·ªë l·∫ßn to√†n b·ªô d·ªØ li·ªáu hu·∫•n luy·ªán ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ c·∫≠p nh·∫≠t tr·ªçng s·ªë c·ªßa m√¥ h√¨nh.""")
        st.latex(r"w = w - \eta \cdot \nabla L(w)")
        st.markdown(r"""
        Trong ƒë√≥:
            $$w$$ l√† tr·ªçng s·ªë.
            $$\eta$$ l√† t·ªëc ƒë·ªô h·ªçc (learning rate).
            $$\nabla L(w)$$ l√† gradient c·ªßa h√†m m·∫•t m√°t (loss function) theo tr·ªçng s·ªë.
        """)
        st.write("""**d. H√†m k√≠ch ho·∫°t (activation)**: 
        \n- H√†m k√≠ch ho·∫°t l√† m·ªôt h√†m to√°n h·ªçc ƒë∆∞·ª£c √°p d·ª•ng cho ƒë·∫ßu ra c·ªßa m·ªói n∆°-ron trong t·∫ßng ·∫©n. N√≥ gi√∫p m√¥ h√¨nh h·ªçc ƒë∆∞·ª£c c√°c m·ªëi quan h·ªá phi tuy·∫øn gi·ªØa c√°c ƒë·∫∑c tr∆∞ng. C√°c h√†m k√≠ch ho·∫°t ph·ªï bi·∫øn bao g·ªìm:""")
        st.write("**ReLU (Rectified Linear Unit)**: H√†m n√†y tr·∫£ v·ªÅ gi√° tr·ªã ƒë·∫ßu v√†o n·∫øu n√≥ l·ªõn h∆°n 0, ng∆∞·ª£c l·∫°i tr·∫£ v·ªÅ 0. ReLU gi√∫p gi·∫£m thi·ªÉu v·∫•n ƒë·ªÅ vanishing gradient.")
        st.latex("f(x) = \max(0, x)")
        st.write("**Tanh**: H√†m n√†y tr·∫£ v·ªÅ gi√° tr·ªã trong kho·∫£ng t·ª´ -1 ƒë·∫øn 1, gi√∫p c·∫£i thi·ªán t·ªëc ƒë·ªô h·ªôi t·ª• so v·ªõi h√†m sigmoid.")
        st.latex(r" f(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} ")
        st.write("**Logistic (Sigmoid)**: H√†m n√†y tr·∫£ v·ªÅ gi√° tr·ªã trong kho·∫£ng t·ª´ 0 ƒë·∫øn 1, th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng cho c√°c b√†i to√°n ph√¢n lo·∫°i nh·ªã ph√¢n.")
        st.latex(r"f(x) = \frac{1}{1 + e^{-x}}")

    with tab2:
        max_samples = 70000
        n_samples = st.number_input(
            "S·ªë l∆∞·ª£ng m·∫´u ƒë·ªÉ hu·∫•n luy·ªán", min_value=1000, max_value=max_samples, value=9000, step=1000,
        )
        
        X, y = load_data(n_samples=n_samples)
        st.write(f"**S·ªë l∆∞·ª£ng m·∫´u ƒë∆∞·ª£c ch·ªçn ƒë·ªÉ hu·∫•n luy·ªán: {X.shape[0]}**")
        show_sample_images(X, y)
        st.write("**üìä T·ª∑ l·ªá d·ªØ li·ªáu**")
                test_size = st.slider("T·ª∑ l·ªá Test (%)", min_value=5, max_value=30, value=15, step=5)
                val_size = st.slider("T·ª∑ l·ªá Validation (%)", min_value=5, max_value=30, value=15, step=5)
                
                train_size = 100 - test_size
                val_ratio = val_size / train_size
                
                if val_ratio >= 1.0:
                    st.error("T·ª∑ l·ªá Validation qu√° l·ªõn so v·ªõi Train! Vui l√≤ng ƒëi·ªÅu ch·ªânh l·∫°i.")
                else:
                    X_temp, X_test, y_temp, y_test = train_test_split(
                        X, y, test_size=test_size/100, random_state=42
                    )
                    val_ratio_adjusted = val_size / (train_size)
                    X_train, X_val, y_train, y_val = train_test_split(
                        X_temp, y_temp, test_size=val_ratio_adjusted, random_state=42
                    )
                    
                    st.session_state.data_split = (X_train, X_val, X_test, y_train, y_val, y_test)
                    
                    data_ratios = pd.DataFrame({
                        "T·∫≠p d·ªØ li·ªáu": ["Train", "Validation", "Test"],
                        "T·ª∑ l·ªá (%)": [train_size - val_size, val_size, test_size],
                        "S·ªë l∆∞·ª£ng m·∫´u": [len(X_train), len(X_val), len(X_test)]
                    })
                    st.table(data_ratios)
    
        st.write("**üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh Neural Network**")
        st.session_state.custom_model_name = st.text_input("Nh·∫≠p t√™n m√¥ h√¨nh ƒë·ªÉ l∆∞u v√†o MLflow:", st.session_state.custom_model_name)
        params = {}
        
        
        params["num_hidden_layers"] = st.slider("S·ªë l·ªõp ·∫©n", 1, 5, 2)
        params["neurons_per_layer"] = st.slider("S·ªë neuron m·ªói l·ªõp", 20, 256, 128)
        params["epochs"] = st.slider("Epochs", 5, 50, 5, step=5)
        params["activation"] = st.selectbox("H√†m k√≠ch ho·∫°t", ["relu", "tanh", "logistic"])
        params["learning_rate"] = st.slider("T·ªëc ƒë·ªô h·ªçc (learning rate)", 0.0001, 0.1, 0.001, step=0.0001, format="%.4f")
        st.session_state.cv_folds = st.slider("S·ªë l∆∞·ª£ng fold cho Cross-Validation", 2, 10, 5)
        
        st.write(f"T·ªëc ƒë·ªô h·ªçc ƒë√£ ch·ªçn: {params['learning_rate']:.4f}")
        
        if st.button("üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh"):
            if not st.session_state.custom_model_name:
                st.error("Vui l√≤ng nh·∫≠p t√™n m√¥ h√¨nh tr∆∞·ªõc khi hu·∫•n luy·ªán!")
            else:
                with st.spinner("üîÑ ƒêang kh·ªüi t·∫°o hu·∫•n luy·ªán..."):
                    st.session_state.params = params
                    X_train, X_val, X_test, y_train, y_val, y_test = st.session_state.data_split
                    result = train_model(
                        st.session_state.custom_model_name, params, X_train, X_val, X_test, 
                        y_train, y_val, y_test, st.session_state.cv_folds
                    )
                    if result[0] is not None:
                        model, train_accuracy, val_accuracy, test_accuracy, cv_mean_accuracy = result
                        st.session_state.model = model
                        st.session_state.trained_models[st.session_state.custom_model_name] = model
                        display_training_results(
                            st.session_state.custom_model_name, train_accuracy, val_accuracy, 
                            test_accuracy, cv_mean_accuracy
                        )
                    else:
                        st.error("Hu·∫•n luy·ªán th·∫•t b·∫°i. Vui l√≤ng ki·ªÉm tra l·ªói ·ªü tr√™n.")

    with tab3:
        if 'trained_models' not in st.session_state or not st.session_state.trained_models:
            st.warning("‚ö†Ô∏è Vui l√≤ng hu·∫•n luy·ªán √≠t nh·∫•t m·ªôt m√¥ h√¨nh tr∆∞·ªõc khi d·ª± ƒëo√°n!")
        else:
            model_names = list(st.session_state.trained_models.keys())
            selected_model_name = st.selectbox("üìù Ch·ªçn m√¥ h√¨nh ƒë·ªÉ d·ª± ƒëo√°n:", model_names)
            selected_model = st.session_state.trained_models[selected_model_name]

            option = st.radio("üñºÔ∏è Ch·ªçn ph∆∞∆°ng th·ª©c nh·∫≠p:", ["üìÇ T·∫£i ·∫£nh l√™n", "‚úèÔ∏è V·∫Ω s·ªë"])
            show_visualization = st.checkbox("Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì m·∫°ng n∆°-ron", value=True)

            if option == "üìÇ T·∫£i ·∫£nh l√™n":
                uploaded_file = st.file_uploader("üì§ T·∫£i ·∫£nh s·ªë vi·∫øt tay (PNG, JPG)", type=["png", "jpg", "jpeg"])
                if uploaded_file is not None:
                    image = cv2.imdecode(np.frombuffer(uploaded_file.read(), np.uint8), cv2.IMREAD_COLOR)
                    processed_image = preprocess_uploaded_image(image)
                    st.image(image, caption="üì∑ ·∫¢nh t·∫£i l√™n", use_column_width=True)
                    if st.button("üîÆ D·ª± ƒëo√°n"):
                        prediction = selected_model.predict(processed_image)[0]
                        probabilities = selected_model.predict_proba(processed_image)[0]
                        st.write(f"üéØ **D·ª± ƒëo√°n: {prediction}**")
                        st.write(f"üî¢ **ƒê·ªô tin c·∫≠y: {probabilities[prediction] * 100:.2f}%**")
                        if show_visualization:
                            st.write("##### üìâ Bi·ªÉu di·ªÖn m·∫°ng Neural Network v·ªõi k·∫øt qu·∫£ d·ª± ƒëo√°n")
                            fig = visualize_neural_network_prediction(selected_model, processed_image, prediction)
                            st.pyplot(fig)

            elif option == "‚úèÔ∏è V·∫Ω s·ªë":
                canvas_result = st_canvas(
                    fill_color="white", stroke_width=15, stroke_color="black",
                    background_color="white", width=280, height=280, drawing_mode="freedraw", key="canvas"
                )
                if st.button("üîÆ D·ª± ƒëo√°n"):
                    if canvas_result.image_data is not None:
                        processed_canvas = preprocess_canvas_image(canvas_result.image_data)
                        prediction = selected_model.predict(processed_canvas)[0]
                        probabilities = selected_model.predict_proba(processed_canvas)[0]
                        st.write(f"üéØ **D·ª± ƒëo√°n: {prediction}**")
                        st.write(f"üî¢ **ƒê·ªô tin c·∫≠y: {probabilities[prediction] * 100:.2f}%**")
                        if show_visualization:
                            st.write("##### üìâ Bi·ªÉu di·ªÖn m·∫°ng Neural Network v·ªõi k·∫øt qu·∫£ d·ª± ƒëo√°n")
                            fig = visualize_neural_network_prediction(selected_model, processed_canvas, prediction)
                            st.pyplot(fig)

    with tab4:
        st.write("##### üìä MLflow Tracking")
        st.write("Xem chi ti·∫øt c√°c k·∫øt qu·∫£ ƒë√£ l∆∞u trong MLflow.")
        
        runs = mlflow.search_runs(order_by=["start_time desc"])
        if not runs.empty:
            if "tags.mlflow.runName" in runs.columns:
                runs["model_custom_name"] = runs["tags.mlflow.runName"]
            else:
                runs["model_custom_name"] = "Unnamed Model"
            model_names = runs["model_custom_name"].dropna().unique().tolist()
        
            search_model_name = st.text_input("üîç Nh·∫≠p t√™n m√¥ h√¨nh ƒë·ªÉ t√¨m ki·∫øm:", "")
            if search_model_name:
                filtered_runs = runs[runs["model_custom_name"].str.contains(search_model_name, case=False, na=False)]
            else:
                filtered_runs = runs
        
            if not filtered_runs.empty:
                st.write("##### üìú Danh s√°ch m√¥ h√¨nh ƒë√£ l∆∞u:")
                available_columns = [
                    col for col in [
                        "model_custom_name", "params.model_name", "start_time",
                        "metrics.train_accuracy", "metrics.val_accuracy", "metrics.test_accuracy",
                        "metrics.cv_mean_accuracy"
                    ] if col in filtered_runs.columns
                ]
                display_df = filtered_runs[available_columns]
                display_df = display_df.rename(columns={
                    "model_custom_name": "Custom Model Name",
                    "params.model_name": "Model Type"
                })
                st.dataframe(display_df)
        
                selected_model_name = st.selectbox("üìù Ch·ªçn m·ªôt m√¥ h√¨nh ƒë·ªÉ xem chi ti·∫øt:", model_names)
                if selected_model_name:
                    selected_run = filtered_runs[filtered_runs["model_custom_name"] == selected_model_name].iloc[0]
                    selected_run_id = selected_run["run_id"]
                    
                    run_details = mlflow.get_run(selected_run_id)
                    custom_name = run_details.data.tags.get('mlflow.runName', 'Kh√¥ng c√≥ t√™n')
                    model_type = run_details.data.params.get('model_name', 'Kh√¥ng x√°c ƒë·ªãnh')
                    st.write(f"##### üîç Chi ti·∫øt m√¥ h√¨nh: `{custom_name}`")
                    st.write(f"**üìå Lo·∫°i m√¥ h√¨nh hu·∫•n luy·ªán:** {model_type}")
        
                    st.write("üìå **Tham s·ªë:**")
                    for key, value in run_details.data.params.items():
                        if key != 'model_name':
                            st.write(f"- **{key}**: {value}")
        
                    st.write("üìä **Metric:**")
                    for key, value in run_details.data.metrics.items():
                        st.write(f"- **{key}**: {value}")
            else:
                st.write("‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh n√†o kh·ªõp v·ªõi t√¨m ki·∫øm.")
        else:
            st.write("‚ö†Ô∏è Kh√¥ng c√≥ phi√™n l√†m vi·ªác n√†o ƒë∆∞·ª£c ghi l·∫°i.")

if __name__ == "__main__":
    create_streamlit_app()
