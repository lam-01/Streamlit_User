import streamlit as st
import mlflow
import mlflow.sklearn
import numpy as np
import cv2
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score
from streamlit_drawable_canvas import st_canvas
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.patches import Circle, Polygon, Rectangle
from sklearn.neural_network import MLPClassifier
import time

# Initialize session state to store the model and training data
if 'model' not in st.session_state:
    st.session_state.model = None
if 'data_split' not in st.session_state:
    st.session_state.data_split = None
if 'params' not in st.session_state:
    st.session_state.params = None
if 'cv_folds' not in st.session_state:
    st.session_state.cv_folds = 5
if 'custom_model_name' not in st.session_state:
    st.session_state.custom_model_name = ""

# Load and preprocess MNIST data from OpenML
@st.cache_data
def load_data(n_samples=None):
    mnist = fetch_openml("mnist_784", version=1, as_frame=False)  # Fetch MNIST dataset
    X, y = mnist.data, mnist.target.astype(int)  # Separate features and labels
    X = X / 255.0  # Normalize pixel values to [0, 1]
    if n_samples is not None and n_samples < len(X):
        indices = np.random.choice(len(X), n_samples, replace=False)  # Randomly select samples
        X = X[indices]
        y = y[indices]
    return X, y

# Split data into training, validation, and test sets
@st.cache_data
def split_data(X, y, train_size=0.7, val_size=0.15, test_size=0.15, random_state=42):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state  # Split into test set
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X_train, y_train, test_size=val_size / (train_size + val_size), random_state=random_state  # Split into validation set
    )
    return X_train, X_val, X_test, y_train, y_val, y_test

# Visualize the neural network with prediction results
def visualize_neural_network_prediction(model, input_image, predicted_label):
    hidden_layer_sizes = model.hidden_layer_sizes  # Get the sizes of hidden layers
    if isinstance(hidden_layer_sizes, int):
        hidden_layer_sizes = [hidden_layer_sizes]  # Convert to list if it's a single integer
    elif isinstance(hidden_layer_sizes, tuple):
        hidden_layer_sizes = list(hidden_layer_sizes)  # Convert tuple to list

    input_layer_size = 784  # Input layer size for MNIST
    output_layer_size = 10  # Output layer size (digits 0-9)
    layer_sizes = [input_layer_size] + hidden_layer_sizes + [output_layer_size]  # Define layer sizes
    num_layers = len(layer_sizes)  # Total number of layers

    # Create subplots for visualization
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), gridspec_kw={'width_ratios': [1, 3]})

    ax1.imshow(input_image.reshape(28, 28), cmap='gray')  # Display input image
    ax1.set_title("Input Image")
    ax1.axis('off')  # Hide axes

    pos = {}  # Position dictionary for neurons
    layer_names = ['Input', 'Hidden 1', 'Hidden 2', 'Output'] if len(hidden_layer_sizes) == 2 else ['Input'] + [f'Hidden {i+1}' for i in range(len(hidden_layer_sizes))] + ['Output']

    # Calculate positions for neurons in each layer
    for layer_idx, layer_size in enumerate(layer_sizes):
        for neuron_idx in range(layer_size):
            if layer_size > 20 and layer_idx == 0:
                if neuron_idx < 10 or neuron_idx >= layer_size - 10:
                    pos[(layer_idx, neuron_idx)] = (layer_idx, neuron_idx / layer_size)  # Position for first and last 10 neurons
                elif neuron_idx == 10:
                    pos[('dots', layer_idx)] = (layer_idx, 0.5)  # Position for dots
            else:
                pos[(layer_idx, neuron_idx)] = (layer_idx, neuron_idx / (layer_size - 1) if layer_size > 1 else 0.5)  # Position for other neurons

    # Draw neurons and connections
    for layer_idx, layer_size in enumerate(layer_sizes):
        for neuron_idx in range(layer_size):
            if layer_size > 20 and layer_idx == 0 and neuron_idx >= 10 and neuron_idx < layer_size - 10:
                continue  # Skip drawing for hidden neurons if too many

            x, y = pos[(layer_idx, neuron_idx)]  # Get position
            circle = Circle((x, y), 0.05, color='white', ec='black')  # Create neuron circle
            ax2.add_patch(circle)  # Add circle to plot

            if layer_idx == num_layers - 1:
                ax2.text(x + 0.2, y, f"{neuron_idx}", fontsize=12, color='white')  # Label output neurons

            if layer_idx == num_layers - 1 and neuron_idx == predicted_label:
                square = Rectangle((x - 0.07, y - 0.07), 0.14, 0.14, fill=False, edgecolor='yellow', linewidth=2)  # Highlight predicted label
                ax2.add_patch(square)

    if ('dots', 0) in pos:
        x, y = pos[('dots', 0)]
        ax2.text(x, y, "...", fontsize=12, color='white', ha='center', va='center')  # Indicate skipped neurons

    # Draw connections between layers
    for layer_idx in range(len(layer_sizes) - 1):
        current_layer_size = layer_sizes[layer_idx]
        next_layer_size = layer_sizes[layer_idx + 1]

        if layer_idx == 0 and current_layer_size > 20:
            neuron_indices_1 = list(range(5)) + list(range(current_layer_size - 5, current_layer_size))  # First and last 5 neurons
        else:
            neuron_indices_1 = range(current_layer_size)  # All neurons

        if layer_idx == len(layer_sizes) - 2:
            neuron_indices_2 = [predicted_label]  # Only predicted label for output layer
        else:
            if next_layer_size > 10:
                neuron_indices_2 = list(range(5)) + list(range(next_layer_size - 5, next_layer_size))  # First and last 5 neurons
            else:
                neuron_indices_2 = range(next_layer_size)  # All neurons

        for idx1, neuron1 in enumerate(neuron_indices_1):
            for idx2, neuron2 in enumerate(neuron_indices_2):
                x1, y1 = pos[(layer_idx, neuron1)]  # Get position of neuron in current layer
                x2, y2 = pos[(layer_idx + 1, neuron2)]  # Get position of neuron in next layer
                color = plt.cm.coolwarm(idx2 / max(len(neuron_indices_2), 1))  # Color for connection
                ax2.plot([x1, x2], [y1, y2], color=color, alpha=0.5, linewidth=1)  # Draw connection

    ax2.set_xlim(-0.5, num_layers - 0.5)  # Set x limits
    ax2.set_ylim(-0.1, 1.1)  # Set y limits
    ax2.set_xticks(range(num_layers))  # Set x ticks
    ax2.set_xticklabels(layer_names)  # Set x tick labels
    ax2.set_yticks([])  # Hide y ticks
    ax2.set_title(f"Neural Network Prediction: {predicted_label}")  # Title for prediction
    ax2.set_facecolor('black')  # Background color

    return fig  # Return the figure for display

# Train the model with a progress bar and cross-validation
def train_model(custom_model_name, params, X_train, X_val, X_test, y_train, y_val, y_test, cv_folds):
    progress_bar = st.progress(0)  # Initialize progress bar
    status_text = st.empty()  # Placeholder for status text

    hidden_layer_sizes = tuple([params["neurons_per_layer"]] * params["num_hidden_layers"])  # Define hidden layer sizes

    model = MLPClassifier(
        hidden_layer_sizes=hidden_layer_sizes,
        max_iter=params["epochs"],
        activation=params["activation"],
        learning_rate_init=params["learning_rate"],
        solver='sgd',
        random_state=42,
        warm_start=True  # Allow warm start for incremental training
    )

    try:
        with mlflow.start_run(run_name=custom_model_name):  # Start MLflow run
            for i in range(params["epochs"]):
                model.max_iter = i + 1  # Incrementally increase max iterations
                model.fit(X_train, y_train)  # Train the model
                progress = (i + 1) / params["epochs"]  # Calculate progress
                progress_bar.progress(progress)  # Update progress bar
                status_text.text(f"Äang huáº¥n luyá»‡n: {int(progress * 100)}%")  # Update status text
                time.sleep(0.1)  # Simulate training time

            # Make predictions on training, validation, and test sets
            y_train_pred = model.predict(X_train)
            y_test_pred = model.predict(X_test)
            y_val_pred = model.predict(X_val)
            train_accuracy = accuracy_score(y_train, y_train_pred)  # Calculate training accuracy
            val_accuracy = accuracy_score(y_val, y_val_pred)  # Calculate validation accuracy
            test_accuracy = accuracy_score(y_test, y_test_pred)  # Calculate test accuracy

            cv_scores = cross_val_score(model, X_train, y_train, cv=cv_folds)  # Perform cross-validation
            cv_mean_accuracy = np.mean(cv_scores)  # Calculate mean cross-validation accuracy

            # Log parameters and metrics to MLflow
            mlflow.log_param("model_name", "Neural Network")
            mlflow.log_params(params)
            mlflow.log_param("cv_folds", cv_folds)
            mlflow.log_metric("train_accuracy", train_accuracy)
            mlflow.log_metric("val_accuracy", val_accuracy)
            mlflow.log_metric("test_accuracy", test_accuracy)
            mlflow.log_metric("cv_mean_accuracy", cv_mean_accuracy)
            mlflow.sklearn.log_model(model, "Neural Network")  # Log the trained model
    except Exception as e:
        st.error(f"Lá»—i trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n: {str(e)}")  # Display error message
        return None, None, None, None, None

    progress_bar.empty()  # Clear progress bar
    status_text.empty()  # Clear status text
    return model, train_accuracy, val_accuracy, test_accuracy, cv_mean_accuracy  # Return results

# Preprocess uploaded image for prediction
def preprocess_uploaded_image(image):
    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale
    image = cv2.resize(image, (28, 28))  # Resize to 28x28
    image = image / 255.0  # Normalize pixel values
    return image.reshape(1, -1)  # Reshape for model input

# Preprocess image drawn on canvas for prediction
def preprocess_canvas_image(canvas):
    image = np.array(canvas)  # Convert canvas to numpy array
    image = cv2.cvtColor(image, cv2.COLOR_RGBA2GRAY)  # Convert to grayscale
    image = cv2.bitwise_not(image)  # Invert colors
    image = cv2.resize(image, (28, 28))  # Resize to 28x28
    image = image / 255.0  # Normalize pixel values
    return image.reshape(1, -1)  # Reshape for model input

# Display sample images from the MNIST dataset
def show_sample_images(X, y):
    st.write("**ğŸ–¼ï¸ Má»™t vÃ i máº«u dá»¯ liá»‡u tá»« MNIST**")
    fig, axes = plt.subplots(1, 10, figsize=(15, 3))  # Create subplots for 10 samples
    for digit in range(10):
        idx = np.where(y == digit)[0][0]  # Get index of first occurrence of each digit
        ax = axes[digit]
        ax.imshow(X[idx].reshape(28, 28), cmap='gray')  # Display sample image
        ax.set_title(f"{digit}")  # Set title to the digit
        ax.axis('off')  # Hide axes
    st.pyplot(fig)  # Show the figure

# Streamlit app interface
def create_streamlit_app():
    st.title("ğŸ”¢ PhÃ¢n loáº¡i chá»¯ sá»‘ viáº¿t tay")  # Title of the app
    
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ““ LÃ­ thuyáº¿t", "ğŸ“‹ Huáº¥n luyá»‡n", "ğŸ”® Dá»± Ä‘oÃ¡n", "âš¡ MLflow"])  # Create tabs
    
    with tab1:
        st.write("##### Neural Network")
        st.write("""Neural Network lÃ  má»™t phÆ°Æ¡ng thá»©c phá»• biáº¿n trong lÄ©nh vá»±c trÃ­ tuá»‡ nhÃ¢n táº¡o, Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ Ä‘iá»u khiá»ƒn mÃ¡y tÃ­nh dá»± Ä‘oÃ¡n, nháº­n dáº¡ng vÃ  xá»­ lÃ½ dá»¯ liá»‡u nhÆ° má»™t bá»™ nÃ£o cá»§a con ngÆ°á»i. 
        BÃªn cáº¡nh Ä‘Ã³, quy trÃ¬nh nÃ y cÃ²n Ä‘Æ°á»£c biáº¿t Ä‘áº¿n vá»›i thuáº­t ngá»¯ quen thuá»™c lÃ  â€œdeep learningâ€, nghÄ©a lÃ  viá»‡c váº­n dá»¥ng cÃ¡c nÆ¡-ron hoáº·c cÃ¡c nÃºt táº¡o sá»± liÃªn káº¿t vá»›i nhau trong cÃ¹ng má»™t cáº¥u trÃºc phÃ¢n lá»›p.""")
        st.write("##### 1. Äáº·c Ä‘iá»ƒm cá»§a Neural Network")
        st.write("""- Máº¡ng lÆ°á»›i nÆ¡-ron nhÃ¢n táº¡o hoáº¡t Ä‘á»™ng nhÆ° nÆ¡-ron trong nÃ£o bá»™ con ngÆ°á»i. Trong Ä‘Ã³, má»—i nÆ¡-ron lÃ  má»™t hÃ m toÃ¡n há»c, cÃ³ chá»©c nÄƒng thu tháº­p vÃ  phÃ¢n loáº¡i dá»¯ liá»‡u, thÃ´ng tin theo cáº¥u trÃºc chi tiáº¿t. 
        \n- Neural Network tÆ°Æ¡ng Ä‘á»“ng vá»›i nhá»¯ng phÆ°Æ¡ng phÃ¡p thá»‘ng kÃª theo Ä‘á»“ thá»‹ Ä‘Æ°á»ng cong hoáº·c phÃ¢n tÃ­ch há»“i quy. Äá»ƒ giáº£i thÃ­ch Ä‘Æ¡n giáº£n nháº¥t, báº¡n hÃ£y hÃ¬nh dung Neural Network bao hÃ m cÃ¡c nÃºt máº¡ng liÃªn káº¿t vá»›i nhau. 
        \n- Má»—i nÃºt lÃ  má»™t táº­p há»£p tri giÃ¡c, cáº¥u táº¡o tÆ°Æ¡ng tá»± hÃ m há»“i quy Ä‘a tuyáº¿n tÃ­nh, Ä‘Æ°á»£c sáº¯p xáº¿p liÃªn káº¿t vá»›i nhau. CÃ¡c lá»›p nÃ y sáº½ thu tháº­p thÃ´ng tin, sau Ä‘Ã³ phÃ¢n loáº¡i vÃ  phÃ¡t tÃ­n hiá»‡u Ä‘áº§u ra tÆ°Æ¡ng á»©ng.
        """)
        st.write("##### 2. Cáº¥u trÃºc máº¡ng Neural Network")
        st.write("""- Input Layer (táº§ng Ä‘áº§u vÃ o): Náº±m bÃªn trÃ¡i cá»§a há»‡ thá»‘ng, bao gá»“m dá»¯ liá»‡u thÃ´ng tin Ä‘áº§u vÃ o. 
        \n- Output Layer (táº§ng Ä‘áº§u ra): Náº±m bÃªn pháº£i cá»§a há»‡ thá»‘ng, bao gá»“m dá»¯ liá»‡u thÃ´ng tin Ä‘áº§u ra. 
        \n- Hidden Layer (táº§ng áº©n): Náº±m á»Ÿ giá»¯a táº§ng Ä‘áº§u vÃ o vÃ  Ä‘áº§u ra, thá»ƒ hiá»‡n quÃ¡ trÃ¬nh suy luáº­n vÃ  xá»­ lÃ½ thÃ´ng tin cá»§a há»‡ thá»‘ng.    
        """)
        st.image("neural_networks.png", caption="Cáº¥u trÃºc máº¡ng Neural Network", width=500)  # Display neural network structure image
        st.write("VÃ­ dá»¥ minh há»a vá»›i bá»™ dá»¯ liá»‡u mnist : ")
        st.image("mau.png", caption="Nguá»“n : https://www.researchgate.net/", width=700)  # Display example image
        st.write("##### 3. CÃ¡c tham sá»‘ quan trá»ng")
        st.write("""**a. Sá»‘ lá»›p áº©n (num_hidden_layers)**:
        \n- ÄÃ¢y lÃ  sá»‘ lÆ°á»£ng táº§ng áº©n trong máº¡ng nÆ¡-ron. Nhiá»u táº§ng áº©n hÆ¡n cÃ³ thá»ƒ giÃºp mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cÃ¡c Ä‘áº·c trÆ°ng phá»©c táº¡p hÆ¡n, nhÆ°ng cÅ©ng lÃ m tÄƒng Ä‘á»™ phá»©c táº¡p tÃ­nh toÃ¡n.
        \n**b. Sá»‘ neuron má»—i lá»›p (neurons_per_layer)**:
        \n- ÄÃ¢y lÃ  sá»‘ lÆ°á»£ng nÆ¡-ron trong má»—i táº§ng áº©n. Sá»‘ lÆ°á»£ng nÆ¡-ron áº£nh hÆ°á»Ÿng Ä‘áº¿n kháº£ nÄƒng há»c cÃ¡c Ä‘áº·c trÆ°ng tá»« dá»¯ liá»‡u.
        \n**c. Epochs**:
        \n- ÄÃ¢y lÃ  sá»‘ láº§n toÃ n bá»™ dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ cáº­p nháº­t trá»ng sá»‘ cá»§a mÃ´ hÃ¬nh.""")
        st.latex(r"w = w - \eta \cdot \nabla L(w)")  # Display weight update formula
        st.markdown(r"""
        Trong Ä‘Ã³:
            $$w$$ lÃ  trá»ng sá»‘.
            $$\eta$$ lÃ  tá»‘c Ä‘á»™ há»c (learning rate).
            $$\nabla L(w)$$ lÃ  gradient cá»§a hÃ m máº¥t mÃ¡t (loss function) theo trá»ng sá»‘.
        """)
        st.write("""**d. HÃ m kÃ­ch hoáº¡t (activation)**: 
        \n- HÃ m kÃ­ch hoáº¡t lÃ  má»™t hÃ m toÃ¡n há»c Ä‘Æ°á»£c Ã¡p dá»¥ng cho Ä‘áº§u ra cá»§a má»—i nÆ¡-ron trong táº§ng áº©n. NÃ³ giÃºp mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cÃ¡c má»‘i quan há»‡ phi tuyáº¿n giá»¯a cÃ¡c Ä‘áº·c trÆ°ng. CÃ¡c hÃ m kÃ­ch hoáº¡t phá»• biáº¿n bao gá»“m:""")
        st.write("**ReLU (Rectified Linear Unit)**: HÃ m nÃ y tráº£ vá» giÃ¡ trá»‹ Ä‘áº§u vÃ o náº¿u nÃ³ lá»›n hÆ¡n 0, ngÆ°á»£c láº¡i tráº£ vá» 0. ReLU giÃºp giáº£m thiá»ƒu váº¥n Ä‘á» vanishing gradient.")
        st.latex("f(x) = \max(0, x)")  # Display ReLU formula
        st.write("**Tanh**: HÃ m nÃ y tráº£ vá» giÃ¡ trá»‹ trong khoáº£ng tá»« -1 Ä‘áº¿n 1, giÃºp cáº£i thiá»‡n tá»‘c Ä‘á»™ há»™i tá»¥ so vá»›i hÃ m sigmoid.")
        st.latex(r" f(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} ")  # Display Tanh formula
        st.write("**Logistic (Sigmoid)**: HÃ m nÃ y tráº£ vá» giÃ¡ trá»‹ trong khoáº£ng tá»« 0 Ä‘áº¿n 1, thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i nhá»‹ phÃ¢n.")
        st.latex(r"f(x) = \frac{1}{1 + e^{-x}}")  # Display Sigmoid formula

    with tab2:
        max_samples = 70000  # Maximum number of samples
        n_samples = st.number_input(
            "Sá»‘ lÆ°á»£ng máº«u Ä‘á»ƒ huáº¥n luyá»‡n", min_value=1000, max_value=max_samples, value=9000, step=1000,
        )
        
        X, y = load_data(n_samples=n_samples)  # Load data with specified number of samples
        st.write(f"**Sá»‘ lÆ°á»£ng máº«u Ä‘Æ°á»£c chá»n Ä‘á»ƒ huáº¥n luyá»‡n: {X.shape[0]}**")  # Display number of samples
        show_sample_images(X, y)  # Show sample images
        
        st.write("**ğŸ“Š Tá»· lá»‡ dá»¯ liá»‡u**")
        test_size = st.slider("Tá»· lá»‡ Test (%)", min_value=5, max_value=30, value=15, step=5)  # Slider for test size
        val_size = st.slider("Tá»· lá»‡ Validation (%)", min_value=5, max_value=30, value=15, step=5)  # Slider for validation size
        
        train_size = 100 - test_size  # Calculate training size
        val_ratio = val_size / train_size  # Calculate validation ratio
        
        if val_ratio >= 1.0:
            st.error("Tá»· lá»‡ Validation quÃ¡ lá»›n so vá»›i Train! Vui lÃ²ng Ä‘iá»u chá»‰nh láº¡i.")  # Error message for validation ratio
        else:
            X_temp, X_test, y_temp, y_test = train_test_split(
                X, y, test_size=test_size/100, random_state=42  # Split data into test set
            )
            val_ratio_adjusted = val_size / (train_size)  # Adjust validation ratio
            X_train, X_val, y_train, y_val = train_test_split(
                X_temp, y_temp, test_size=val_ratio_adjusted, random_state=42  # Split data into training and validation sets
            )
            
            st.session_state.data_split = (X_train, X_val, X_test, y_train, y_val, y_test)  # Store data split in session state
            
            data_ratios = pd.DataFrame({
                "Táº­p dá»¯ liá»‡u": ["Train", "Validation", "Test"],
                "Tá»· lá»‡ (%)": [train_size - val_size, val_size, test_size],
                "Sá»‘ lÆ°á»£ng máº«u": [len(X_train), len(X_val), len(X_test)]
            })
            st.table(data_ratios)  # Display data ratios in a table
    
        st.write("**ğŸš€ Huáº¥n luyá»‡n mÃ´ hÃ¬nh Neural Network**")
        st.session_state.custom_model_name = st.text_input("Nháº­p tÃªn mÃ´ hÃ¬nh Ä‘á»ƒ lÆ°u vÃ o MLflow:", st.session_state.custom_model_name)  # Input for model name
        params = {}  # Initialize parameters
        
        params["num_hidden_layers"] = st.slider("Sá»‘ lá»›p áº©n", 1, 5, 2)  # Slider for number of hidden layers
        params["neurons_per_layer"] = st.slider("Sá»‘ neuron má»—i lá»›p", 50, 200, 100)  # Slider for number of neurons per layer
        params["epochs"] = st.slider("Epochs", 5, 50, 10)  # Slider for number of epochs
        params["activation"] = st.selectbox("HÃ m kÃ­ch hoáº¡t", ["relu", "tanh", "logistic"])  # Dropdown for activation function
        params["learning_rate"] = st.slider("Tá»‘c Ä‘á»™ há»c (learning rate)", 0.0001, 0.1,0.001)  # Slider for learning rate
        st.session_state.cv_folds = st.slider("Sá»‘ lÆ°á»£ng fold cho Cross-Validation", 2, 10, 5)  # Slider for cross-validation folds
        
        # Display selected learning rate for verification
        st.write(f"Tá»‘c Ä‘á»™ há»c Ä‘Ã£ chá»n: {params['learning_rate']:.4f}")
    
        if st.button("ğŸš€ Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):  # Button to start training
            with st.spinner("ğŸ”„ Äang khá»Ÿi táº¡o huáº¥n luyá»‡n..."):  # Spinner while training
                st.session_state.params = params  # Store parameters in session state
                X_train, X_val, X_test, y_train, y_val, y_test = st.session_state.data_split  # Retrieve data split
                result = train_model(
                    st.session_state.custom_model_name, params, X_train, X_val, X_test, y_train, y_val, y_test, st.session_state.cv_folds
                )
                if result[0] is not None:
                    model, train_accuracy, val_accuracy, test_accuracy, cv_mean_accuracy = result  # Unpack results
                    st.session_state.model = model  # Store trained model in session state
                    st.success(f"âœ… Huáº¥n luyá»‡n xong!")  # Success message
                    st.write(f"ğŸ¯ **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p train: {train_accuracy:.4f}**")  # Display training accuracy
                    st.write(f"ğŸ¯ **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p validation: {val_accuracy:.4f}**")  # Display validation accuracy
                    st.write(f"ğŸ¯ **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test: {test_accuracy:.4f}**")  # Display test accuracy
                    st.write(f"ğŸ¯ **Äá»™ chÃ­nh xÃ¡c trung bÃ¬nh Cross-Validation: {cv_mean_accuracy:.4f}**")  # Display cross-validation accuracy
                else:
                    st.error("Huáº¥n luyá»‡n tháº¥t báº¡i. Vui lÃ²ng kiá»ƒm tra lá»—i á»Ÿ trÃªn.")  # Error message for training failure

    with tab3:
        if st.session_state.model is None:
            st.warning("âš ï¸ Vui lÃ²ng huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c khi dá»± Ä‘oÃ¡n!")  # Warning if model is not trained
        else:
            option = st.radio("ğŸ–¼ï¸ Chá»n phÆ°Æ¡ng thá»©c nháº­p:", ["ğŸ“‚ Táº£i áº£nh lÃªn", "âœï¸ Váº½ sá»‘"])  # Radio button for input method
            show_visualization = st.checkbox("Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ máº¡ng nÆ¡-ron", value=True)  # Checkbox for visualization

            if option == "ğŸ“‚ Táº£i áº£nh lÃªn":  # If upload option is selected
                uploaded_file = st.file_uploader("ğŸ“¤ Táº£i áº£nh sá»‘ viáº¿t tay (PNG, JPG)", type=["png", "jpg", "jpeg"])  # File uploader for images
                if uploaded_file is not None:
                    image = cv2.imdecode(np.frombuffer(uploaded_file.read(), np.uint8), cv2.IMREAD_COLOR)  # Decode uploaded image
                    processed_image = preprocess_uploaded_image(image)  # Preprocess image for prediction
                    st.image(image, caption="ğŸ“· áº¢nh táº£i lÃªn", use_column_width=True)  # Display uploaded image
                    if st.button("ğŸ”® Dá»± Ä‘oÃ¡n"):  # Button to make prediction
                        model = st.session_state.model  # Retrieve trained model
                        prediction = model.predict(processed_image)[0]  # Make prediction
                        probabilities = model.predict_proba(processed_image)[0]  # Get prediction probabilities
                        st.write(f"ğŸ¯ **Dá»± Ä‘oÃ¡n: {prediction}**")  # Display prediction
                        st.write(f"ğŸ”¢ **Äá»™ tin cáº­y: {probabilities[prediction] * 100:.2f}%**")  # Display confidence
                        if show_visualization:
                            st.write("##### ğŸ“‰ Biá»ƒu diá»…n máº¡ng Neural Network vá»›i káº¿t quáº£ dá»± Ä‘oÃ¡n")  # Visualization header
                            fig = visualize_neural_network_prediction(model, processed_image, prediction)  # Visualize prediction
                            st.pyplot(fig)  # Show visualization

            elif option == "âœï¸ Váº½ sá»‘":  # If draw option is selected
                canvas_result = st_canvas(
                    fill_color="white", stroke_width=15, stroke_color="black",
                    background_color="white", width=280, height=280, drawing_mode="freedraw", key="canvas"  # Canvas for drawing
                )
                if st.button("ğŸ”® Dá»± Ä‘oÃ¡n"):  # Button to make prediction
                    if canvas_result.image_data is not None:
                        processed_canvas = preprocess_canvas_image(canvas_result.image_data)  # Preprocess drawn image
                        model = st.session_state.model  # Retrieve trained model
                        prediction = model.predict(processed_canvas)[0]  # Make prediction
                        probabilities = model.predict_proba(processed_canvas)[0]  # Get prediction probabilities
                        st.write(f"ğŸ¯ **Dá»± Ä‘oÃ¡n: {prediction}**")  # Display prediction
                        st.write(f"ğŸ”¢ **Äá»™ tin cáº­y: {probabilities[prediction] * 100:.2f}%**")  # Display confidence
                        if show_visualization:
                            st.write("##### ğŸ“‰ Biá»ƒu diá»…n máº¡ng Neural Network vá»›i káº¿t quáº£ dá»± Ä‘oÃ¡n")  # Visualization header
                            fig = visualize_neural_network_prediction(model, processed_canvas, prediction)  # Visualize prediction
                            st.pyplot(fig)  # Show visualization

    with tab4:
        st.write("##### ğŸ“Š MLflow Tracking")  # MLflow tracking header
        st.write("Xem chi tiáº¿t cÃ¡c káº¿t quáº£ Ä‘Ã£ lÆ°u trong MLflow.")  # Description for MLflow tracking
        
        runs = mlflow.search_runs(order_by=["start_time desc"])  # Search for runs in MLflow
        if not runs.empty:
            if "tags.mlflow.runName" in runs.columns:
                runs["model_custom_name"] = runs["tags.mlflow.runName"]  # Get custom model names
            else:
                runs["model_custom_name"] = "Unnamed Model"  # Default name if not available
            model_names = runs["model_custom_name"].dropna().unique().tolist()  # Get unique model names
        
            search_model_name = st.text_input("ğŸ” Nháº­p tÃªn mÃ´ hÃ¬nh Ä‘á»ƒ tÃ¬m kiáº¿m:", "")  # Input for model search
            if search_model_name:
                filtered_runs = runs[runs["model_custom_name"].str.contains(search_model_name, case=False, na=False)]  # Filter runs by model name
            else:
                filtered_runs = runs  # No filtering if no input
        
            if not filtered_runs.empty:
                st.write("##### ğŸ“œ Danh sÃ¡ch mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u:")  # Display saved models header
                available_columns = [
                    col for col in [
                        "model_custom_name", "params.model_name", "start_time",
                        "metrics.train_accuracy", "metrics.val_accuracy", "metrics.test_accuracy",
                        "metrics.cv_mean_accuracy"
                    ] if col in filtered_runs.columns
                ]
                display_df = filtered_runs[available_columns]  # Create dataframe for display
                display_df = display_df.rename(columns={
                    "model_custom_name": "Custom Model Name",
                    "params.model_name": "Model Type"
                })
                st.dataframe(display_df)  # Show dataframe in Streamlit
        
                selected_model_name = st.selectbox("ğŸ“ Chá»n má»™t mÃ´ hÃ¬nh Ä‘á»ƒ xem chi tiáº¿t:", model_names)  # Dropdown for selecting model
                if selected_model_name:
                    selected_run = filtered_runs[filtered_runs["model_custom_name"] == selected_model_name].iloc[0]  # Get selected run
                    selected_run_id = selected_run["run_id"]  # Get run ID
                    
                    run_details = mlflow.get_run(selected_run_id)  # Get details of the run
                    custom_name = run_details.data.tags.get('mlflow.runName', 'KhÃ´ng cÃ³ tÃªn')  # Get custom name
                    model_type = run_details.data.params.get('model_name', 'KhÃ´ng xÃ¡c Ä‘á»‹nh')  # Get model type
                    st.write(f"##### ğŸ” Chi tiáº¿t mÃ´ hÃ¬nh: `{custom_name}`")  # Display model details header
                    st.write(f"**ğŸ“Œ Loáº¡i mÃ´ hÃ¬nh huáº¥n luyá»‡n:** {model_type}")  # Display model type
        
                    st.write("ğŸ“Œ **Tham sá»‘:**")  # Parameters header
                    for key, value in run_details.data.params.items():
                        if key != 'model_name':
                            st.write(f"- **{key}**: {value}")  # Display parameters
        
                    st.write("ğŸ“Š **Metric:**")  # Metrics header
                    for key, value in run_details.data.metrics.items():
                        st.write(f"- **{key}**: {value}")  # Display metrics
            else:
                st.write("âŒ KhÃ´ng tÃ¬m tháº¥y mÃ´ hÃ¬nh nÃ o khá»›p vá»›i tÃ¬m kiáº¿m.")  # No models found message
        else:
            st.write("âš ï¸ KhÃ´ng cÃ³ phiÃªn lÃ m viá»‡c nÃ o Ä‘Æ°á»£c ghi láº¡i.")  # No runs recorded message

if __name__ == "__main__":
    create_streamlit_app()  # Run the Streamlit app
