import streamlit as st
import mlflow
import mlflow.sklearn
import numpy as np
import cv2
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score
from streamlit_drawable_canvas import st_canvas
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.neural_network import MLPClassifier
import time

# üìå T·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu MNIST t·ª´ OpenML
@st.cache_data
def load_data(n_samples=None):
    mnist = fetch_openml("mnist_784", version=1, as_frame=False)
    X, y = mnist.data, mnist.target.astype(int)  # Chuy·ªÉn nh√£n v·ªÅ ki·ªÉu s·ªë nguy√™n
    X = X / 255.0  # Chu·∫©n h√≥a v·ªÅ [0,1]
    if n_samples is not None and n_samples < len(X):
        indices = np.random.choice(len(X), n_samples, replace=False)
        X = X[indices]
        y = y[indices]
    return X, y

# üìå Chia d·ªØ li·ªáu th√†nh train, validation, v√† test
@st.cache_data
def split_data(X, y, train_size=0.7, val_size=0.15, test_size=0.15, random_state=42):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X_train, y_train, test_size=val_size / (train_size + val_size), random_state=random_state
    )
    return X_train, X_val, X_test, y_train, y_val, y_test

# üìå Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi thanh ti·∫øn tr√¨nh v√† cross-validation
def train_model(custom_model_name, params, X_train, X_val, X_test, y_train, y_val, y_test, cv_folds):
    progress_bar = st.progress(0)
    status_text = st.empty()

    model = MLPClassifier(
        hidden_layer_sizes=(params["hidden_layer_size"],),
        max_iter=params["max_iter"],
        activation=params["activation"],
        solver=params["solver"],
        random_state=42,
        warm_start=True  # Cho ph√©p hu·∫•n luy·ªán ti·∫øp t·ª•c ƒë·ªÉ m√¥ ph·ªèng ti·∫øn tr√¨nh
    )

    # Hu·∫•n luy·ªán m√¥ h√¨nh
    with mlflow.start_run(run_name=custom_model_name):
        # M√¥ ph·ªèng ti·∫øn tr√¨nh hu·∫•n luy·ªán cho Neural Network
        for i in range(params["max_iter"]):
            model.max_iter = i + 1  # TƒÉng s·ªë l·∫ßn l·∫∑p t·ª´ng b∆∞·ªõc
            model.fit(X_train, y_train)  # Hu·∫•n luy·ªán t·ª´ng epoch
            progress = (i + 1) / params["max_iter"]
            progress_bar.progress(progress)
            status_text.text(f"ƒêang hu·∫•n luy·ªán: {int(progress * 100)}%")
            time.sleep(0.1)  # Gi·∫£ l·∫≠p th·ªùi gian hu·∫•n luy·ªán ƒë·ªÉ th·∫•y ti·∫øn tr√¨nh

        # D·ª± ƒëo√°n v√† t√≠nh to√°n ƒë·ªô ch√≠nh x√°c
        y_train_pred = model.predict(X_train)
        y_test_pred = model.predict(X_test)
        y_val_pred = model.predict(X_val)
        train_accuracy = accuracy_score(y_train, y_train_pred)
        val_accuracy = accuracy_score(y_val, y_val_pred)
        test_accuracy = accuracy_score(y_test, y_test_pred)

        # Th·ª±c hi·ªán cross-validation
        cv_scores = cross_val_score(model, X_train, y_train, cv=cv_folds)
        cv_mean_accuracy = np.mean(cv_scores)
        cv_std_accuracy = np.std(cv_scores)

        # Ghi log tham s·ªë v√† metric v√†o MLflow
        mlflow.log_param("model_name", "Neural Network")
        mlflow.log_params(params)  # Ghi to√†n b·ªô tham s·ªë
        mlflow.log_param("cv_folds", cv_folds)  # Ghi s·ªë l∆∞·ª£ng fold
        mlflow.log_metric("train_accuracy", train_accuracy)
        mlflow.log_metric("val_accuracy", val_accuracy)
        mlflow.log_metric("test_accuracy", test_accuracy)
        mlflow.log_metric("cv_mean_accuracy", cv_mean_accuracy)
        mlflow.log_metric("cv_std_accuracy", cv_std_accuracy)
        mlflow.sklearn.log_model(model, "Neural Network")
    
    # X√≥a thanh ti·∫øn tr√¨nh v√† tr·∫°ng th√°i sau khi ho√†n th√†nh
    status_text.text("Ho√†n th√†nh hu·∫•n luy·ªán!")
    return model, train_accuracy, val_accuracy, test_accuracy, cv_mean_accuracy, cv_std_accuracy

# üìå X·ª≠ l√Ω ·∫£nh t·∫£i l√™n
def preprocess_uploaded_image(image):
    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    image = cv2.resize(image, (28, 28))
    image = image / 255.0
    return image.reshape(1, -1)

# üìå X·ª≠ l√Ω ·∫£nh t·ª´ v·∫Ω tay tr√™n canvas
def preprocess_canvas_image(canvas):
    image = np.array(canvas)
    image = cv2.cvtColor(image, cv2.COLOR_RGBA2GRAY)
    image = cv2.bitwise_not(image)
    image = cv2.resize(image, (28, 28))
    image = image / 255.0
    return image.reshape(1, -1)

def show_sample_images(X, y):
    st.write("**üñºÔ∏è M·ªôt v√†i m·∫´u d·ªØ li·ªáu t·ª´ MNIST**")
    fig, axes = plt.subplots(1, 10, figsize=(15, 3))
    for digit in range(10):
        idx = np.where(y == digit)[0][0]
        ax = axes[digit]
        ax.imshow(X[idx].reshape(28, 28), cmap='gray')
        ax.set_title(f"{digit}")
        ax.axis('off')
    st.pyplot(fig)

# üìå Giao di·ªán Streamlit
def create_streamlit_app():
    st.title("üî¢ Ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay")
    
    tab1, tab2, tab3, tab4 = st.tabs(["üìì L√≠ thuy·∫øt", "üìã Hu·∫•n luy·ªán", "üîÆ D·ª± ƒëo√°n", "‚ö° MLflow"])
    
    with tab1:
        st.write("##### Neural Network")
        st.write("""Neural Network l√† m·ªôt ph∆∞∆°ng th·ª©c ph·ªï bi·∫øn trong lƒ©nh v·ª±c tr√≠ tu·ªá nh√¢n t·∫°o, ƒë∆∞·ª£c d√πng ƒë·ªÉ ƒëi·ªÅu khi·ªÉn m√°y t√≠nh d·ª± ƒëo√°n, nh·∫≠n d·∫°ng v√† x·ª≠ l√Ω d·ªØ li·ªáu nh∆∞ m·ªôt b·ªô n√£o c·ªßa con ng∆∞·ªùi. 
        B√™n c·∫°nh ƒë√≥, quy tr√¨nh n√†y c√≤n ƒë∆∞·ª£c bi·∫øt ƒë·∫øn v·ªõi thu·∫≠t ng·ªØ quen thu·ªôc l√† ‚Äúdeep learning‚Äù, nghƒ©a l√† vi·ªác v·∫≠n d·ª•ng c√°c n∆°-ron ho·∫∑c c√°c n√∫t t·∫°o s·ª± li√™n k·∫øt v·ªõi nhau trong c√πng m·ªôt c·∫•u tr√∫c ph√¢n l·ªõp.""")
        st.write("##### 1. ƒê·∫∑c ƒëi·ªÉm c·ªßa Neural Network")
        st.write("""- M·∫°ng l∆∞·ªõi n∆°-ron nh√¢n t·∫°o ho·∫°t ƒë·ªông nh∆∞ n∆°-ron trong n√£o b·ªô con ng∆∞·ªùi. Trong ƒë√≥, m·ªói n∆°-ron l√† m·ªôt h√†m to√°n h·ªçc, c√≥ ch·ª©c nƒÉng thu th·∫≠p v√† ph√¢n lo·∫°i d·ªØ li·ªáu, th√¥ng tin theo c·∫•u tr√∫c chi ti·∫øt. 
        \n- Neural Network t∆∞∆°ng ƒë·ªìng v·ªõi nh·ªØng ph∆∞∆°ng ph√°p th·ªëng k√™ theo ƒë·ªì th·ªã ƒë∆∞·ªùng cong ho·∫∑c ph√¢n t√≠ch h·ªìi quy. ƒê·ªÉ gi·∫£i th√≠ch ƒë∆°n gi·∫£n nh·∫•t, b·∫°n h√£y h√¨nh dung Neural Network bao h√†m c√°c n√∫t m·∫°ng li√™n k·∫øt v·ªõi nhau. 
        \n- M·ªói n√∫t l√† m·ªôt t·∫≠p h·ª£p tri gi√°c, c·∫•u t·∫°o t∆∞∆°ng t·ª± h√†m h·ªìi quy ƒëa tuy·∫øn t√≠nh, ƒë∆∞·ª£c s·∫Øp x·∫øp li√™n k·∫øt v·ªõi nhau. C√°c l·ªõp n√†y s·∫Ω thu th·∫≠p th√¥ng tin, sau ƒë√≥ ph√¢n lo·∫°i v√† ph√°t t√≠n hi·ªáu ƒë·∫ßu ra t∆∞∆°ng ·ª©ng.
        """)
        st.write("##### 2. C·∫•u tr√∫c m·∫°ng Neural Network")
        st.write("""- Input Layer (t·∫ßng ƒë·∫ßu v√†o): N·∫±m b√™n tr√°i c·ªßa h·ªá th·ªëng, bao g·ªìm d·ªØ li·ªáu th√¥ng tin ƒë·∫ßu v√†o. 
        \n- Output Layer (t·∫ßng ƒë·∫ßu ra): N·∫±m b√™n ph·∫£i c·ªßa h·ªá th·ªëng, bao g·ªìm d·ªØ li·ªáu th√¥ng tin ƒë·∫ßu ra. 
        \n- Hidden Layer (t·∫ßng ·∫©n): N·∫±m ·ªü gi·ªØa t·∫ßng ƒë·∫ßu v√†o v√† ƒë·∫ßu ra, th·ªÉ hi·ªán qu√° tr√¨nh suy lu·∫≠n v√† x·ª≠ l√Ω th√¥ng tin c·ªßa h·ªá th·ªëng.    
        """)
        st.image("neural_networks.png", caption="C·∫•u tr√∫c m·∫°ng Neural Network", width=500)
        st.write("V√≠ d·ª• minh h·ªça v·ªõi b·ªô d·ªØ li·ªáu mnist : ")
        st.image("mau.png", caption="Ngu·ªìn : https://www.researchgate.net/", width=700)
        st.write("##### 3. C√°c tham s·ªë quan tr·ªçng")
        st.write("""**a. K√≠ch th∆∞·ªõc t·∫ßng ·∫©n (hidden_layer_size)**:
        \n- ƒê√¢y l√† s·ªë l∆∞·ª£ng n∆°-ron trong t·∫ßng ·∫©n c·ªßa m·∫°ng n∆°-ron. T·∫ßng ·∫©n l√† n∆°i m√† c√°c ph√©p to√°n phi tuy·∫øn ƒë∆∞·ª£c th·ª±c hi·ªán, gi√∫p m√¥ h√¨nh h·ªçc ƒë∆∞·ª£c c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p t·ª´ d·ªØ li·ªáu. K√≠ch th∆∞·ªõc c·ªßa t·∫ßng ·∫©n c√≥ th·ªÉ ·∫£nh h∆∞·ªüng l·ªõn ƒë·∫øn kh·∫£ nƒÉng h·ªçc c·ªßa m√¥ h√¨nh.
        \n**b. S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa (max_iter)**:
        \n- ƒê√¢y l√† s·ªë l·∫ßn m√† thu·∫≠t to√°n t·ªëi ∆∞u s·∫Ω c·∫≠p nh·∫≠t tr·ªçng s·ªë c·ªßa m√¥ h√¨nh trong qu√° tr√¨nh hu·∫•n luy·ªán.""")
        st.latex(r"w = w - \eta \cdot \nabla L(w)")
        st.markdown(r"""
        Trong ƒë√≥:
            $$w$$ l√† tr·ªçng s·ªë.
            $$\eta$$ l√† t·ªëc ƒë·ªô h·ªçc (learning rate).
            $$\nabla L(w)$$ l√† gradient c·ªßa h√†m m·∫•t m√°t (loss function) theo tr·ªçng s·ªë.
        """)
        st.write("""**c. H√†m k√≠ch ho·∫°t (activation)**: 
        \n- H√†m k√≠ch ho·∫°t l√† m·ªôt h√†m to√°n h·ªçc ƒë∆∞·ª£c √°p d·ª•ng cho ƒë·∫ßu ra c·ªßa m·ªói n∆°-ron trong t·∫ßng ·∫©n. N√≥ gi√∫p m√¥ h√¨nh h·ªçc ƒë∆∞·ª£c c√°c m·ªëi quan h·ªá phi tuy·∫øn gi·ªØa c√°c ƒë·∫∑c tr∆∞ng. C√°c h√†m k√≠ch ho·∫°t ph·ªï bi·∫øn bao g·ªìm:""")
        st.write("**ReLU (Rectified Linear Unit)**: H√†m n√†y tr·∫£ v·ªÅ gi√° tr·ªã ƒë·∫ßu v√†o n·∫øu n√≥ l·ªõn h∆°n 0, ng∆∞·ª£c l·∫°i tr·∫£ v·ªÅ 0. ReLU gi√∫p gi·∫£m thi·ªÉu v·∫•n ƒë·ªÅ vanishing gradient.")
        st.latex("f(x) = \max(0, x)")
        st.write("**Tanh**: H√†m n√†y tr·∫£ v·ªÅ gi√° tr·ªã trong kho·∫£ng t·ª´ -1 ƒë·∫øn 1, gi√∫p c·∫£i thi·ªán t·ªëc ƒë·ªô h·ªôi t·ª• so v·ªõi h√†m sigmoid.")
        st.latex(r" f(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} ")
        st.write("**Logistic (Sigmoid)**: H√†m n√†y tr·∫£ v·ªÅ gi√° tr·ªã trong kho·∫£ng t·ª´ 0 ƒë·∫øn 1, th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng cho c√°c b√†i to√°n ph√¢n lo·∫°i nh·ªã ph√¢n.")
        st.latex(r"f(x) = \frac{1}{1 + e^{-x}}")
        st.write("""**d. B·ªô gi·∫£i t·ªëi ∆∞u (solver)**:
        \n- B·ªô gi·∫£i t·ªëi ∆∞u l√† thu·∫≠t to√°n ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ c·∫≠p nh·∫≠t tr·ªçng s·ªë c·ªßa m√¥ h√¨nh trong qu√° tr√¨nh hu·∫•n luy·ªán. C√°c b·ªô gi·∫£i ph·ªï bi·∫øn bao g·ªìm:""")
        st.write("**Adam**: M·ªôt trong nh·ªØng b·ªô gi·∫£i t·ªëi ∆∞u ph·ªï bi·∫øn nh·∫•t, k·∫øt h·ª£p c√°c ∆∞u ƒëi·ªÉm c·ªßa hai b·ªô gi·∫£i kh√°c l√† AdaGrad v√† RMSProp. Adam t·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh t·ªëc ƒë·ªô h·ªçc cho t·ª´ng tr·ªçng s·ªë.")
        st.write("B∆∞·ªõc 1: T√≠nh to√°n gradient")
        st.latex(r"g_t = \nabla L(w_t)") 
        st.write("B∆∞·ªõc 2: C·∫≠p nh·∫≠t c√°c ∆∞·ªõc l∆∞·ª£ng trung b√¨nh")
        st.latex(r"m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t ] [ v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2 ")
        st.write("B∆∞·ªõc 3: ƒêi·ªÅu ch·ªânh bias")
        st.latex(r"\hat{m}_t = \frac{m_t}{1 - \beta_1^t} ] [ \hat{v}_t = \frac{v_t}{1 - \beta_2^t} ")
        st.write("B∆∞·ªõc 4: C·∫≠p nh·∫≠t tr·ªçng s·ªë")
        st.latex(r"w_{t+1} = w_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t ")
        st.write("**SGD (Stochastic Gradient Descent)**: M·ªôt ph∆∞∆°ng ph√°p ƒë∆°n gi·∫£n v√† hi·ªáu qu·∫£, c·∫≠p nh·∫≠t tr·ªçng s·ªë d·ª±a tr√™n m·ªôt m·∫´u ng·∫´u nhi√™n t·ª´ t·∫≠p d·ªØ li·ªáu. SGD c√≥ th·ªÉ h·ªôi t·ª• nhanh h∆°n nh∆∞ng c√≥ th·ªÉ kh√¥ng ·ªïn ƒë·ªãnh.")

    with tab2:
        # Cho ph√©p ch·ªçn s·ªë m·∫´u ƒë·ªÉ hu·∫•n luy·ªán
        max_samples = 70000  # T·ªïng s·ªë m·∫´u trong MNIST
        n_samples = st.slider("S·ªë l∆∞·ª£ng m·∫´u ƒë·ªÉ hu·∫•n luy·ªán", 1000, max_samples, 10000, step=1000, 
                              help=f"Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u t·ª´ 1,000 ƒë·∫øn {max_samples} ƒë·ªÉ hu·∫•n luy·ªán.")
        
        X, y = load_data(n_samples=n_samples)
        st.write(f"**S·ªë l∆∞·ª£ng m·∫´u ƒë∆∞·ª£c ch·ªçn ƒë·ªÉ hu·∫•n luy·ªán: {X.shape[0]}**")
        show_sample_images(X, y)
        
        st.write("**üìä T·ª∑ l·ªá d·ªØ li·ªáu**")
        test_size = st.slider("T·ª∑ l·ªá Test (%)", min_value=5, max_value=30, value=15, step=5)
        val_size = st.slider("T·ª∑ l·ªá Validation (%)", min_value=5, max_value=30, value=15, step=5)
        
        train_size = 100 - test_size
        val_ratio = val_size / train_size
        
        if val_ratio >= 1.0:
            st.error("T·ª∑ l·ªá Validation qu√° l·ªõn so v·ªõi Train! Vui l√≤ng ƒëi·ªÅu ch·ªânh l·∫°i.")
        else:
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size/100, random_state=42)
            X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_ratio, random_state=42)
        
            data_ratios = pd.DataFrame({
                "T·∫≠p d·ªØ li·ªáu": ["Train", "Validation", "Test"],
                "T·ª∑ l·ªá (%)": [train_size - val_size, val_size, test_size],
                "S·ªë l∆∞·ª£ng m·∫´u": [len(X_train), len(X_val), len(X_test)]
            })
            st.table(data_ratios)

        st.write("**üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh Neural Network**")
        custom_model_name = st.text_input("Nh·∫≠p t√™n m√¥ h√¨nh ƒë·ªÉ l∆∞u v√†o MLflow:", "MyModel")
        params = {}
        
        params["hidden_layer_size"] = st.slider("K√≠ch th∆∞·ªõc t·∫ßng ·∫©n", 50, 200, 100, help="S·ªë n∆°-ron trong t·∫ßng ·∫©n.")
        params["max_iter"] = st.slider("S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa", 5, 50, 10, help="S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa ƒë·ªÉ hu·∫•n luy·ªán.")
        params["activation"] = st.selectbox("H√†m k√≠ch ho·∫°t", ["relu", "tanh", "logistic"], help="H√†m k√≠ch ho·∫°t cho c√°c n∆°-ron.")
        params["solver"] = st.selectbox("B·ªô gi·∫£i t·ªëi ∆∞u", ["adam", "sgd"], help="B·ªô gi·∫£i t·ªëi ∆∞u h√≥a tr·ªçng s·ªë.")
        cv_folds = st.slider("S·ªë l∆∞·ª£ng fold cho Cross-Validation", 2, 10, 5, help="S·ªë l∆∞·ª£ng fold ƒë·ªÉ ƒë√°nh gi√° m√¥ h√¨nh b·∫±ng cross-validation.")

        if st.button("üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh"):
            with st.spinner("üîÑ ƒêang kh·ªüi t·∫°o hu·∫•n luy·ªán..."):
                model, train_accuracy, val_accuracy, test_accuracy, cv_mean_accuracy, cv_std_accuracy = train_model(
                    custom_model_name, params, X_train, X_val, X_test, y_train, y_val, y_test, cv_folds
                )
            st.success(f"‚úÖ Hu·∫•n luy·ªán xong!")
            st.write(f"üéØ **ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p train: {train_accuracy:.4f}**")
            st.write(f"üéØ **ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p validation: {val_accuracy:.4f}**")
            st.write(f"üéØ **ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p test: {test_accuracy:.4f}**")
            st.write(f"üéØ **ƒê·ªô ch√≠nh x√°c trung b√¨nh Cross-Validation: {cv_mean_accuracy:.4f} (¬±{cv_std_accuracy:.4f})**")

    with tab3:
        option = st.radio("üñºÔ∏è Ch·ªçn ph∆∞∆°ng th·ª©c nh·∫≠p:", ["üìÇ T·∫£i ·∫£nh l√™n", "‚úèÔ∏è V·∫Ω s·ªë"])
        if option == "üìÇ T·∫£i ·∫£nh l√™n":
            uploaded_file = st.file_uploader("üì§ T·∫£i ·∫£nh s·ªë vi·∫øt tay (PNG, JPG)", type=["png", "jpg", "jpeg"])
            if uploaded_file is not None:
                image = cv2.imdecode(np.frombuffer(uploaded_file.read(), np.uint8), cv2.IMREAD_COLOR)
                processed_image = preprocess_uploaded_image(image)
                st.image(image, caption="üì∑ ·∫¢nh t·∫£i l√™n", use_column_width=True)
                if st.button("üîÆ D·ª± ƒëo√°n"):
                    model, train_accuracy, val_accuracy, test_accuracy, cv_mean_accuracy, cv_std_accuracy = train_model(
                        custom_model_name, params, X_train, X_val, X_test, y_train, y_val, y_test, cv_folds
                    )
                    prediction = model.predict(processed_image)[0]
                    probabilities = model.predict_proba(processed_image)[0]
                    st.write(f"üéØ **D·ª± ƒëo√°n: {prediction}**")
                    st.write(f"üî¢ **ƒê·ªô tin c·∫≠y: {probabilities[prediction] * 100:.2f}%**")
        elif option == "‚úèÔ∏è V·∫Ω s·ªë":
            canvas_result = st_canvas(
                fill_color="white", stroke_width=15, stroke_color="black",
                background_color="white", width=280, height=280, drawing_mode="freedraw", key="canvas"
            )
            if st.button("üîÆ D·ª± ƒëo√°n"):
                if canvas_result.image_data is not None:
                    processed_canvas = preprocess_canvas_image(canvas_result.image_data)
                    model, train_accuracy, val_accuracy, test_accuracy, cv_mean_accuracy, cv_std_accuracy = train_model(
                        custom_model_name, params, X_train, X_val, X_test, y_train, y_val, y_test, cv_folds
                    )
                    prediction = model.predict(processed_canvas)[0]
                    probabilities = model.predict_proba(processed_canvas)[0]
                    st.write(f"üéØ **D·ª± ƒëo√°n: {prediction}**")
                    st.write(f"üî¢ **ƒê·ªô tin c·∫≠y: {probabilities[prediction] * 100:.2f}%**")

    with tab4:
        st.header("üìä MLflow Tracking")
        st.write("Xem chi ti·∫øt c√°c k·∫øt qu·∫£ ƒë√£ l∆∞u trong MLflow.")

        runs = mlflow.search_runs(order_by=["start_time desc"])
        if not runs.empty:
            runs["model_custom_name"] = runs["tags.mlflow.runName"]
            model_names = runs["model_custom_name"].dropna().unique().tolist()

            search_model_name = st.text_input("üîç Nh·∫≠p t√™n m√¥ h√¨nh ƒë·ªÉ t√¨m ki·∫øm:", "")
            if search_model_name:
                filtered_runs = runs[runs["model_custom_name"].str.contains(search_model_name, case=False, na=False)]
            else:
                filtered_runs = runs

            if not filtered_runs.empty:
                st.write("### üìú Danh s√°ch m√¥ h√¨nh ƒë√£ l∆∞u:")
                display_df = filtered_runs[["model_custom_name", "params.model_name", "run_id", "start_time", 
                                           "metrics.train_accuracy", "metrics.val_accuracy", "metrics.test_accuracy",
                                           "metrics.cv_mean_accuracy", "metrics.cv_std_accuracy"]]
                display_df = display_df.rename(columns={
                    "model_custom_name": "Custom Model Name",
                    "params.model_name": "Model Type"
                })
                st.dataframe(display_df)

                selected_run_id = st.selectbox("üìù Ch·ªçn m·ªôt m√¥ h√¨nh ƒë·ªÉ xem chi ti·∫øt:", filtered_runs["run_id"].tolist())
                if selected_run_id:
                    run_details = mlflow.get_run(selected_run_id)
                    custom_name = run_details.data.tags.get('mlflow.runName', 'Kh√¥ng c√≥ t√™n')
                    model_type = run_details.data.params.get('model_name', 'Kh√¥ng x√°c ƒë·ªãnh')
                    st.write(f"### üîç Chi ti·∫øt m√¥ h√¨nh: `{custom_name}`")
                    st.write(f"**üìå Lo·∫°i m√¥ h√¨nh hu·∫•n luy·ªán:** {model_type}")

                    st.write("üìå **Tham s·ªë:**")
                    for key, value in run_details.data.params.items():
                        if key != 'model_name':
                            st.write(f"- **{key}**: {value}")

                    st.write("üìä **Metric:**")
                    for key, value in run_details.data.metrics.items():
                        st.write(f"- **{key}**: {value}")

                    st.write("üìÇ **Artifacts:**")
                    if run_details.info.artifact_uri:
                        st.write(f"- **Artifact URI**: {run_details.info.artifact_uri}")
                    else:
                        st.write("- Kh√¥ng c√≥ artifacts n√†o.")
            else:
                st.write("‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh n√†o.")
        else:
            st.write("‚ö†Ô∏è Kh√¥ng c√≥ phi√™n l√†m vi·ªác n√†o ƒë∆∞·ª£c ghi l·∫°i.")

if __name__ == "__main__":
    create_streamlit_app()
