import streamlit as st
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers
import mlflow
import mlflow.keras
import cv2
from streamlit_drawable_canvas import st_canvas
import matplotlib.pyplot as plt
import time
import pandas as pd
from sklearn.model_selection import train_test_split

# H√†m x√¢y d·ª±ng model NN v·ªõi tham s·ªë t√πy ch·ªânh
def create_model(num_hidden_layers=2, neurons_per_layer=128, activation='relu', learning_rate=0.001):
    model = keras.Sequential()
    model.add(layers.Flatten(input_shape=(28, 28)))
    
    # Th√™m c√°c l·ªõp ·∫©n theo tham s·ªë
    for _ in range(num_hidden_layers):
        model.add(layers.Dense(neurons_per_layer, activation=activation))
        model.add(layers.Dropout(0.2))
    
    model.add(layers.Dense(10, activation='softmax'))
    
    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)
    model.compile(optimizer=optimizer,
                 loss='sparse_categorical_crossentropy',
                 metrics=['accuracy'])
    return model

# T·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu MNIST v·ªõi k√≠ch th∆∞·ªõc m·∫´u t√πy ch·ªânh
@st.cache_data
def load_data(sample_size=10000):
    (x_full, y_full), _ = keras.datasets.mnist.load_data()
    x_full = x_full.astype('float32') / 255
    
    # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng m·∫´u theo sample_size
    if sample_size < len(x_full):
        indices = np.random.permutation(len(x_full))[:sample_size]
        x_full = x_full[indices]
        y_full = y_full[indices]
    
    return x_full, y_full

# Ch·ªçn d·ªØ li·ªáu labeled ban ƒë·∫ßu v·ªõi t·ªâ l·ªá t√πy ch·ªânh
def select_initial_data(x_train, y_train, percentage):
    labeled_idx = []
    for i in range(10):
        class_idx = np.where(y_train == i)[0]
        n_samples = max(1, int(len(class_idx) * percentage))
        selected_idx = np.random.choice(class_idx, n_samples, replace=False)
        labeled_idx.extend(selected_idx)
    
    x_labeled = x_train[labeled_idx]
    y_labeled = y_train[labeled_idx]
    unlabeled_idx = [i for i in range(len(x_train)) if i not in labeled_idx]
    x_unlabeled = x_train[unlabeled_idx]
    
    return x_labeled, y_labeled, x_unlabeled, unlabeled_idx

# Hi·ªÉn th·ªã m·∫´u d·ªØ li·ªáu ƒë∆∞·ª£c g√°n nh√£n gi·∫£
def show_pseudo_labeled_samples(model, samples, predictions, n_samples=10):
    fig, axes = plt.subplots(2, n_samples, figsize=(15, 4))
    
    # Ch·ªçn ng·∫´u nhi√™n n_samples t·ª´ c√°c m·∫´u ƒë∆∞·ª£c g√°n nh√£n gi·∫£
    if len(samples) <= n_samples:
        selected_indices = np.arange(len(samples))
    else:
        selected_indices = np.random.choice(len(samples), n_samples, replace=False)
    
    for i, idx in enumerate(selected_indices):
        # Hi·ªÉn th·ªã ·∫£nh
        axes[0, i].imshow(samples[idx], cmap='gray')
        axes[0, i].axis('off')
        
        # Hi·ªÉn th·ªã d·ª± ƒëo√°n
        pred_idx = np.argmax(predictions[idx])
        confidence = np.max(predictions[idx])
        axes[1, i].axis('off')
        axes[1, i].text(0.5, 0.5, f"{pred_idx}\n{confidence:.2f}", 
                      ha='center', va='center',
                      color='green' if confidence > 0.9 else 'blue')
    
    plt.tight_layout()
    return fig

# Thu·∫≠t to√°n Pseudo Labelling v·ªõi MLflow v√† hi·ªÉn th·ªã k·∫øt qu·∫£ sau m·ªói v√≤ng l·∫∑p
def pseudo_labeling_with_mlflow(x_labeled, y_labeled, x_unlabeled, x_val, y_val, x_test, y_test, 
                               threshold, max_iterations, custom_model_name, model_params):
    results_container = st.empty()
    metrics_container = st.empty()
    samples_container = st.empty()
    
    with mlflow.start_run(run_name=custom_model_name):
        model = create_model(
            num_hidden_layers=model_params['num_hidden_layers'],
            neurons_per_layer=model_params['neurons_per_layer'],
            activation=model_params['activation'],
            learning_rate=model_params['learning_rate']
        )
        
        # Log parameters
        mlflow.log_param("threshold", threshold)
        mlflow.log_param("max_iterations", max_iterations)
        mlflow.log_param("initial_labeled_percentage", percentage * 100)
        for key, value in model_params.items():
            mlflow.log_param(key, value)
        
        x_train_current = x_labeled.copy()
        y_train_current = y_labeled.copy()
        remaining_unlabeled = x_unlabeled.copy()
        
        # Metrics tracking
        metrics_history = {
            'iteration': [],
            'labeled_samples_count': [],
            'train_accuracy': [],
            'val_accuracy': [],
            'test_accuracy': []
        }
        
        # Initial metrics
        metrics_history['iteration'].append(0)
        metrics_history['labeled_samples_count'].append(len(x_labeled))
        metrics_history['train_accuracy'].append(0)
        metrics_history['val_accuracy'].append(0)
        metrics_history['test_accuracy'].append(0)
        
        # Show initial results
        results_container.markdown("### K·∫øt qu·∫£ trong qu√° tr√¨nh hu·∫•n luy·ªán")
        
        for iteration in range(max_iterations):
            # Hu·∫•n luy·ªán model v·ªõi d·ªØ li·ªáu hi·ªán t·∫°i
            history = model.fit(
                x_train_current, y_train_current,
                epochs=model_params['epochs'],
                batch_size=32,
                verbose=0,
                validation_data=(x_val, y_val)
            )
            
            # T√≠nh to√°n ƒë·ªô ch√≠nh x√°c
            train_acc = history.history['accuracy'][-1]
            val_acc = history.history['val_accuracy'][-1]
            test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)
            
            # Log metrics
            mlflow.log_metric("train_accuracy", train_acc, step=iteration)
            mlflow.log_metric("val_accuracy", val_acc, step=iteration)
            mlflow.log_metric("test_accuracy", test_acc, step=iteration)
            
            # D·ª± ƒëo√°n nh√£n cho c√°c m·∫´u unlabeled
            if len(remaining_unlabeled) > 0:
                predictions = model.predict(remaining_unlabeled, verbose=0)
                max_probs = np.max(predictions, axis=1)
                pseudo_labels = np.argmax(predictions, axis=1)
                
                # L·ªçc c√°c m·∫´u v∆∞·ª£t ng∆∞·ª°ng tin c·∫≠y
                confident_idx = np.where(max_probs >= threshold)[0]
                
                # Hi·ªÉn th·ªã m·∫´u ƒë∆∞·ª£c g√°n nh√£n gi·∫£
                if len(confident_idx) > 0:
                    fig = show_pseudo_labeled_samples(
                        model, 
                        remaining_unlabeled[confident_idx], 
                        predictions[confident_idx]
                    )
                    samples_container.pyplot(fig)
                
                # C·∫≠p nh·∫≠t t·∫≠p d·ªØ li·ªáu
                if len(confident_idx) > 0:
                    x_train_current = np.concatenate([x_train_current, remaining_unlabeled[confident_idx]])
                    y_train_current = np.concatenate([y_train_current, pseudo_labels[confident_idx]])
                    remaining_unlabeled = np.delete(remaining_unlabeled, confident_idx, axis=0)
                    mlflow.log_metric("labeled_samples", len(confident_idx), step=iteration)
                else:
                    break  # D·ª´ng n·∫øu kh√¥ng c√≥ m·∫´u n√†o v∆∞·ª£t ng∆∞·ª°ng
            else:
                break  # D·ª´ng n·∫øu kh√¥ng c√≤n m·∫´u unlabeled
            
            # C·∫≠p nh·∫≠t metrics history
            metrics_history['iteration'].append(iteration + 1)
            metrics_history['labeled_samples_count'].append(len(x_train_current))
            metrics_history['train_accuracy'].append(train_acc)
            metrics_history['val_accuracy'].append(val_acc)
            metrics_history['test_accuracy'].append(test_acc)
            
            # Hi·ªÉn th·ªã metrics sau m·ªói l·∫ßn l·∫∑p
            metrics_df = pd.DataFrame(metrics_history)
            metrics_container.dataframe(metrics_df)
            
            # Hi·ªÉn th·ªã th√¥ng b√°o sau m·ªói l·∫ßn l·∫∑p
            results_container.markdown(f"""
            ### Iteration {iteration + 1} k·∫øt th√∫c:
            - S·ªë m·∫´u labeled hi·ªán t·∫°i: {len(x_train_current)}
            - S·ªë m·∫´u unlabeled c√≤n l·∫°i: {len(remaining_unlabeled)}
            - ƒê·ªô ch√≠nh x√°c train: {train_acc:.4f}
            - ƒê·ªô ch√≠nh x√°c validation: {val_acc:.4f}
            - ƒê·ªô ch√≠nh x√°c test: {test_acc:.4f}
            """)
        
        # Log model cu·ªëi c√πng
        mlflow.keras.log_model(model, "final_model")
        
        # ƒê√°nh gi√° cu·ªëi c√πng
        final_test_loss, final_test_accuracy = model.evaluate(x_test, y_test, verbose=0)
        mlflow.log_metric("final_test_accuracy", final_test_accuracy)
        
    return model, final_test_accuracy, metrics_history

# X·ª≠ l√Ω ·∫£nh t·∫£i l√™n
def preprocess_uploaded_image(image):
    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    image = cv2.resize(image, (28, 28))
    image = image / 255.0
    return image.reshape(1, 28, 28)

# X·ª≠ l√Ω ·∫£nh t·ª´ canvas
def preprocess_canvas_image(canvas):
    image = np.array(canvas)
    image = cv2.cvtColor(image, cv2.COLOR_RGBA2GRAY)
    image = cv2.bitwise_not(image)
    image = cv2.resize(image, (28, 28))
    image = image / 255.0
    return image.reshape(1, 28, 28)

# Hi·ªÉn th·ªã m·∫´u d·ªØ li·ªáu
def show_sample_images(X, y):
    st.write("**üñºÔ∏è M·ªôt v√†i m·∫´u d·ªØ li·ªáu t·ª´ MNIST**")
    fig, axes = plt.subplots(1, 10, figsize=(15, 3))
    for digit in range(10):
        idx = np.where(y == digit)[0][0]
        ax = axes[digit]
        ax.imshow(X[idx], cmap='gray')
        ax.set_title(f"{digit}")
        ax.axis('off')
    st.pyplot(fig)

# Giao di·ªán Streamlit
def create_streamlit_app():
    st.title("üî¢ Pseudo Labelling tr√™n MNIST v·ªõi Neural Network")
    
    tab1, tab2, tab3, tab4 = st.tabs(["üìì Gi·ªõi thi·ªáu", "üìã Hu·∫•n luy·ªán", "üîÆ D·ª± ƒëo√°n", "‚ö° MLflow"])
    
    # Tab 1: Gi·ªõi thi·ªáu
    with tab1:
        st.write("##### Pseudo Labelling v·ªõi Neural Network")
        st.write(""" 
        **Pseudo Labelling** l√† m·ªôt k·ªπ thu·∫≠t h·ªçc b√°n gi√°m s√°t (semi-supervised learning) nh·∫±m t·∫≠n d·ª•ng c·∫£ d·ªØ li·ªáu c√≥ nh√£n (labeled data) v√† d·ªØ li·ªáu kh√¥ng nh√£n (unlabeled data) ƒë·ªÉ c·∫£i thi·ªán hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh h·ªçc m√°y, ƒë·∫∑c bi·ªát khi l∆∞·ª£ng d·ªØ li·ªáu c√≥ nh√£n ban ƒë·∫ßu r·∫•t h·∫°n ch·∫ø. Ph∆∞∆°ng ph√°p n√†y d·ª±a tr√™n √Ω t∆∞·ªüng s·ª≠ d·ª•ng m√¥ h√¨nh ƒë·ªÉ d·ª± ƒëo√°n nh√£n cho d·ªØ li·ªáu kh√¥ng nh√£n, sau ƒë√≥ ch·ªçn c√°c d·ª± ƒëo√°n c√≥ ƒë·ªô tin c·∫≠y cao ƒë·ªÉ b·ªï sung v√†o t·∫≠p d·ªØ li·ªáu c√≥ nh√£n, t·ª´ ƒë√≥ hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh.
        \n **C∆° ch·∫ø ho·∫°t ƒë·ªông**
        \n Ph∆∞∆°ng ph√°p Pseudo Labelling v·ªõi Neural Network bao g·ªìm c√°c b∆∞·ªõc ch√≠nh sau:
        
        \n **(1) Chu·∫©n b·ªã d·ªØ li·ªáu ban ƒë·∫ßu**
        \nT·∫≠p d·ªØ li·ªáu c√≥ nh√£n (Labeled Data): M·ªôt t·∫≠p nh·ªè d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c g√°n nh√£n ch√≠nh x√°c, th∆∞·ªùng chi·∫øm t·ªâ l·ªá r·∫•t th·∫•p (v√≠ d·ª•: 1%) so v·ªõi t·ªïng d·ªØ li·ªáu.
        \nT·∫≠p d·ªØ li·ªáu kh√¥ng nh√£n (Unlabeled Data): Ph·∫ßn l·ªõn d·ªØ li·ªáu c√≤n l·∫°i, kh√¥ng c√≥ nh√£n ban ƒë·∫ßu, chi·∫øm t·ªâ l·ªá l·ªõn (v√≠ d·ª•: 99%).
        \nT·∫≠p ki·ªÉm tra (Test Data): M·ªôt t·∫≠p d·ªØ li·ªáu ri√™ng bi·ªát ƒë·ªÉ ƒë√°nh gi√° hi·ªáu su·∫•t cu·ªëi c√πng c·ªßa m√¥ h√¨nh.
        \nV√≠ d·ª•: V·ªõi t·∫≠p MNIST (60,000 ·∫£nh ch·ªØ s·ªë vi·∫øt tay):
        
        \n Chia 80% l√†m t·∫≠p train (48,000 ·∫£nh) v√† 20% l√†m t·∫≠p test (12,000 ·∫£nh).
        \n T·ª´ t·∫≠p train, l·∫•y 1% (~480 ·∫£nh) l√†m t·∫≠p labeled, 99% (~47,520 ·∫£nh) l√†m t·∫≠p unlabeled.
        \n **(2) Hu·∫•n luy·ªán m√¥ h√¨nh ban ƒë·∫ßu**
        \n S·ª≠ d·ª•ng m·ªôt m·∫°ng n∆°-ron (NN) ƒë·ªÉ hu·∫•n luy·ªán tr√™n t·∫≠p labeled ban ƒë·∫ßu.
        \n **(3) D·ª± ƒëo√°n nh√£n cho d·ªØ li·ªáu kh√¥ng nh√£n**
        \n S·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán ƒë·ªÉ d·ª± ƒëo√°n nh√£n cho to√†n b·ªô t·∫≠p unlabeled.
        \n K·∫øt qu·∫£ d·ª± ƒëo√°n l√† m·ªôt ph√¢n ph·ªëi x√°c su·∫•t cho m·ªói m·∫´u d·ªØ li·ªáu (v√≠ d·ª•: [0.05, 0.02, 0.90, ..., 0.01] cho 10 l·ªõp).
        \n **(4) G√°n nh√£n gi·∫£ (Pseudo Label)**
        \n ƒê·∫∑t m·ªôt ng∆∞·ª°ng tin c·∫≠y (threshold), v√≠ d·ª• 0.95, ƒë·ªÉ l·ªçc c√°c d·ª± ƒëo√°n ƒë√°ng tin c·∫≠y.
        \n Quy t·∫Øc:
        \n N·∫øu x√°c su·∫•t t·ªëi ƒëa ‚â• threshold, m·∫´u ƒë√≥ ƒë∆∞·ª£c g√°n nh√£n gi·∫£ d·ª±a tr√™n l·ªõp c√≥ x√°c su·∫•t cao nh·∫•t.
        \n N·∫øu x√°c su·∫•t t·ªëi ƒëa < threshold, m·∫´u ƒë√≥ v·∫´n gi·ªØ tr·∫°ng th√°i kh√¥ng nh√£n.
        \n V√≠ d·ª•: M·ªôt ·∫£nh trong t·∫≠p unlabeled ƒë∆∞·ª£c d·ª± ƒëo√°n v·ªõi x√°c su·∫•t [0.02, 0.01, 0.96, ..., 0.01]. N·∫øu threshold = 0.95, ·∫£nh n√†y ƒë∆∞·ª£c g√°n nh√£n gi·∫£ l√† l·ªõp 2 (v√¨ 0.96 > 0.95).
        \n **(5) M·ªü r·ªông t·∫≠p labeled v√† hu·∫•n luy·ªán l·∫°i**
        \n T·∫≠p labeled m·ªõi = t·∫≠p labeled ban ƒë·∫ßu + c√°c m·∫´u v·ª´a ƒë∆∞·ª£c g√°n nh√£n gi·∫£.
        \n Hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh NN tr√™n t·∫≠p labeled m·ªü r·ªông n√†y.
        \n Qu√° tr√¨nh d·ª± ƒëo√°n (b∆∞·ªõc 3) v√† g√°n nh√£n gi·∫£ (b∆∞·ªõc 4) ƒë∆∞·ª£c l·∫∑p l·∫°i tr√™n ph·∫ßn unlabeled c√≤n l·∫°i.
        \n **(6) L·∫∑p l·∫°i cho ƒë·∫øn khi ƒë·∫°t ƒëi·ªÅu ki·ªán d·ª´ng**
        \n ƒêi·ªÅu ki·ªán d·ª´ng:
        \n To√†n b·ªô t·∫≠p unlabeled ƒë∆∞·ª£c g√°n nh√£n gi·∫£ v√† chuy·ªÉn sang t·∫≠p labeled.
        \n Kh√¥ng c√≤n m·∫´u n√†o trong t·∫≠p unlabeled c√≥ d·ª± ƒëo√°n v∆∞·ª£t ng∆∞·ª°ng tin c·∫≠y.
        \n ƒê·∫°t s·ªë v√≤ng l·∫∑p t·ªëi ƒëa do ng∆∞·ªùi d√πng ƒë·∫∑t (v√≠ d·ª•: 5, 10, ho·∫∑c 20 v√≤ng).
        \n Sau m·ªói v√≤ng l·∫∑p, m√¥ h√¨nh th∆∞·ªùng tr·ªü n√™n ch√≠nh x√°c h∆°n do ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n t·∫≠p labeled l·ªõn h∆°n.
        """)
    
    # Tab 2: Hu·∫•n luy·ªán
    with tab2:
        st.write("##### Chu·∫©n b·ªã d·ªØ li·ªáu")
        
        # Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u
        sample_size = st.number_input("**Ch·ªçn c·ª° m·∫´u ƒë·ªÉ hu·∫•n luy·ªán**", 1000, 70000, 10000, step=1000)
        X, y = load_data(sample_size=sample_size)
        st.write(f"**S·ªë l∆∞·ª£ng m·∫´u c·ªßa b·ªô d·ªØ li·ªáu: {X.shape[0]}**")
        
        show_sample_images(X, y)
        
        st.write("##### Chia t·∫≠p d·ªØ li·ªáu")
        
        # Chia d·ªØ li·ªáu train, validation v√† test
        train_ratio = st.slider("T·ªâ l·ªá d·ªØ li·ªáu train", 0.5, 0.8, 0.6, 0.05,
                                help="Ch·ªçn t·ªâ l·ªá d·ªØ li·ªáu d√πng ƒë·ªÉ hu·∫•n luy·ªán")
        val_ratio = st.slider("T·ªâ l·ªá d·ªØ li·ªáu validation", 0.1, 0.3, 0.2, 0.05,
                             help="Ch·ªçn t·ªâ l·ªá d·ªØ li·ªáu d√πng ƒë·ªÉ validation trong qu√° tr√¨nh hu·∫•n luy·ªán")
        
        # T√≠nh to√°n test_ratio
        test_ratio = 1.0 - train_ratio - val_ratio
        
        # Chia d·ªØ li·ªáu
        X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=test_ratio, random_state=42)
        X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, 
                                                        test_size=val_ratio/(train_ratio+val_ratio), 
                                                        random_state=42)
        
        labeled_percentage = st.slider("T·ªâ l·ªá d·ªØ li·ªáu labeled ban ƒë·∫ßu (%)", 0.1, 10.0, 1.0, 0.1,
                                      help="Ch·ªçn ph·∫ßn trƒÉm d·ªØ li·ªáu c√≥ nh√£n ban ƒë·∫ßu trong t·∫≠p train.")
        
        # Chia d·ªØ li·ªáu labeled v√† unlabeled
        global percentage
        percentage = labeled_percentage / 100
        x_labeled, y_labeled, x_unlabeled, _ = select_initial_data(X_train, y_train, percentage)
        
        # T·∫°o v√† hi·ªÉn th·ªã b·∫£ng d·ªØ li·ªáu
        total_samples = len(X)
        data = {
            "T·∫≠p d·ªØ li·ªáu": ["T·ªïng m·∫´u", "T·∫≠p train", "T·∫≠p validation", "T·∫≠p test", "T·∫≠p labeled ban ƒë·∫ßu", "T·∫≠p unlabeled"],
            "S·ªë m·∫´u": [len(X), len(X_train), len(X_val), len(X_test), len(x_labeled), len(x_unlabeled)],
            "T·ª∑ l·ªá (%)": [
                "100%",
                f"{len(X_train)/total_samples*100:.1f}%",
                f"{len(X_val)/total_samples*100:.1f}%",
                f"{len(X_test)/total_samples*100:.1f}%",
                f"{len(x_labeled)/len(X_train)*100:.1f}% c·ªßa train",
                f"{len(x_unlabeled)/len(X_train)*100:.1f}% c·ªßa train"
            ]
        }
        df = pd.DataFrame(data)
        st.write("**K√≠ch th∆∞·ªõc t·∫≠p d·ªØ li·ªáu sau khi chia:**")
        st.table(df)
        
        st.write("##### Thi·∫øt l·∫≠p tham s·ªë Neural Network")
        # Tham s·ªë Neural Network
        params = {}
        params["num_hidden_layers"] = st.slider("S·ªë l·ªõp ·∫©n", 1, 5, 2)
        params["neurons_per_layer"] = st.slider("S·ªë neuron m·ªói l·ªõp", 50, 200, 100)
        params["epochs"] = st.slider("Epochs", 5, 50, 10)
        params["activation"] = st.selectbox("H√†m k√≠ch ho·∫°t", ["relu", "tanh", "sigmoid"])
        params["learning_rate"] = st.slider("T·ªëc ƒë·ªô h·ªçc (learning rate)", 0.0001, 0.1, 0.001, format="%.4f")
        
        st.write("##### Hu·∫•n luy·ªán m√¥ h√¨nh Pseudo Labelling")
        custom_model_name = st.text_input("Nh·∫≠p t√™n m√¥ h√¨nh:")
        if not custom_model_name:
            custom_model_name = f"PseudoLabel_Model_{int(time.time())}"
        threshold = st.slider("Ng∆∞·ª°ng tin c·∫≠y", 0.5, 0.99, 0.95, 0.01)
        max_iterations = st.slider("S·ªë v√≤ng l·∫∑p t·ªëi ƒëa", 1, 20, 5)
        
        if st.button("üöÄ Ch·∫°y Pseudo Labelling"):
            with st.spinner("üîÑ ƒêang kh·ªüi t·∫°o hu·∫•n luy·ªán..."):
                model, test_accuracy, metrics_history = pseudo_labeling_with_mlflow(
                    x_labeled, y_labeled, x_unlabeled, X_val, y_val, X_test, y_test,
                    threshold, max_iterations, custom_model_name, params
                )
                st.session_state['model'] = model
            
            st.success(f"‚úÖ Hu·∫•n luy·ªán xong! ƒê·ªô ch√≠nh x√°c cu·ªëi c√πng tr√™n test: {test_accuracy:.4f}")
    
    # Tab 3: D·ª± ƒëo√°n
    with tab3:
        st.write("**üîÆ D·ª± ƒëo√°n ch·ªØ s·ªë**")
        if 'model' not in st.session_state:
            st.warning("Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc ·ªü tab Hu·∫•n luy·ªán!")
        else:
            option = st.radio("üñºÔ∏è Ch·ªçn ph∆∞∆°ng th·ª©c nh·∫≠p:", ["üìÇ T·∫£i ·∫£nh l√™n", "‚úèÔ∏è V·∫Ω s·ªë"])
            
            if option == "üìÇ T·∫£i ·∫£nh l√™n":
                uploaded_file = st.file_uploader("üì§ T·∫£i ·∫£nh s·ªë vi·∫øt tay (PNG, JPG)", type=["png", "jpg", "jpeg"])
                if uploaded_file is not None:
                    image = cv2.imdecode(np.frombuffer(uploaded_file.read(), np.uint8), cv2.IMREAD_COLOR)
                    processed_image = preprocess_uploaded_image(image)
                    st.image(image, caption="üì∑ ·∫¢nh t·∫£i l√™n", width=200)
                    
                    if st.button("üîÆ D·ª± ƒëo√°n"):
                        model = st.session_state['model']
                        prediction = model.predict(processed_image)
                        predicted_digit = np.argmax(prediction)
                        confidence = np.max(prediction)
                        st.write(f"üéØ **D·ª± ƒëo√°n: {predicted_digit}**")
                        st.write(f"üî¢ **ƒê·ªô tin c·∫≠y: {confidence * 100:.2f}%**")
            
            elif option == "‚úèÔ∏è V·∫Ω s·ªë":
                canvas_result = st_canvas(
                    fill_color="white", stroke_width=15, stroke_color="black",
                    background_color="white", width=280, height=280, drawing_mode="freedraw", key="canvas"
                )
                if st.button("üîÆ D·ª± ƒëo√°n"):
                    if canvas_result.image_data is not None:
                        processed_canvas = preprocess_canvas_image(canvas_result.image_data)
                        model = st.session_state['model']
                        prediction = model.predict(processed_canvas)
                        predicted_digit = np.argmax(prediction)
                        confidence = np.max(prediction)
                        st.write(f"üéØ **D·ª± ƒëo√°n: {predicted_digit}**")
                        st.write(f"üî¢ **ƒê·ªô tin c·∫≠y: {confidence * 100:.2f}%**")
    
    # Tab 4: MLflow Tracking
    with tab4:
        st.write("##### MLflow Tracking")
        
        runs = mlflow.search_runs(order_by=["start_time desc"])
        if not runs.empty:
            runs["model_custom_name"] = runs["tags.mlflow.runName"]
            
            search_model_name = st.text_input("üîç Nh·∫≠p t√™n m√¥ h√¨nh ƒë·ªÉ t√¨m ki·∫øm:", "")
            if search_model_name:
                filtered_runs = runs[runs["model_custom_name"].str.contains(search_model_name, case=False, na=False)]
            else:
                filtered_runs = runs
            
            if not filtered_runs.empty:
                st.write("##### üìú Danh s√°ch m√¥ h√¨nh ƒë√£ l∆∞u:")
                available_columns = [col for col in [
                    "model_custom_name", "start_time",
                    "metrics.train_accuracy", "metrics.val_accuracy", "metrics.test_accuracy",
                    "metrics.labeled_samples", "metrics.final_test_accuracy"
                ] if col in filtered_runs.columns]
                display_df = filtered_runs[available_columns]
                display_df = display_df.rename(columns={"model_custom_name": "Custom Model Name"})
                st.dataframe(display_df)
                
                selected_model_name = st.selectbox("üìù Ch·ªçn m·ªôt m√¥ h√¨nh ƒë·ªÉ xem chi ti·∫øt:",
                                                  filtered_runs["model_custom_name"].tolist())
                if selected_model_name:
                    selected_run = filtered_runs[filtered_runs["model_custom_name"] == selected_model_name].iloc[0]
                    run_details = mlflow.get_run(selected_run["run_id"])
                    custom_name = run_details.data.tags.get('mlflow.runName', 'Kh√¥ng c√≥ t√™n')
                    st.write(f"##### üîç Chi ti·∫øt m√¥ h√¨nh: `{custom_name}`")
                    
                    st.write("üìå **Tham s·ªë:**")
                    for key, value in run_details.data.params.items():
                        st.write(f"- **{key}**: {value}")
                    
                    st.write("üìä **Metric:**")
                    for key, value in run_details.data.metrics.items():
                        st.write(f"- **{key}**: {value}")
            else:
                st.write("‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh n√†o.")
        else:
            st.write("‚ö†Ô∏è Kh√¥ng c√≥ phi√™n l√†m vi·ªác n√†o ƒë∆∞·ª£c ghi l·∫°i.")

if __name__ == "__main__":
    create_streamlit_app()
