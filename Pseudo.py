import streamlit as st
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers
import mlflow
import mlflow.keras
import cv2
from streamlit_drawable_canvas import st_canvas
import matplotlib.pyplot as plt
import time
import pandas as pd
from sklearn.model_selection import train_test_split, KFold

# HÃ m xÃ¢y dá»±ng model NN vá»›i tham sá»‘ tÃ¹y chá»‰nh
def create_model(num_hidden_layers, neurons_per_layer, activation, learning_rate):
    model = keras.Sequential()
    model.add(layers.Flatten(input_shape=(28, 28)))
    
    # ThÃªm cÃ¡c táº§ng áº©n
    for _ in range(num_hidden_layers):
        model.add(layers.Dense(neurons_per_layer, activation=activation))
        model.add(layers.Dropout(0.2))
    
    model.add(layers.Dense(10, activation='softmax'))
    
    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)
    model.compile(optimizer=optimizer,
                 loss='sparse_categorical_crossentropy',
                 metrics=['accuracy'])
    return model

# Táº£i vÃ  chia dá»¯ liá»‡u vá»›i train/val/test
@st.cache_data
def load_data(train_split=0.7, val_split=0.15):
    (x_full, y_full), _ = keras.datasets.mnist.load_data()
    x_full = x_full.astype('float32') / 255
    
    total_samples = len(x_full)
    train_size = int(total_samples * train_split)
    val_size = int(total_samples * val_split)
    test_size = total_samples - train_size - val_size
    
    indices = np.random.permutation(total_samples)
    train_indices = indices[:train_size]
    val_indices = indices[train_size:train_size + val_size]
    test_indices = indices[train_size + val_size:]
    
    x_train = x_full[train_indices]
    y_train = y_full[train_indices]
    x_val = x_full[val_indices]
    y_val = y_full[val_indices]
    x_test = x_full[test_indices]
    y_test = y_full[test_indices]
    
    return x_train, y_train, x_val, y_val, x_test, y_test

# Chá»n dá»¯ liá»‡u labeled ban Ä‘áº§u
def select_initial_data(x_train, y_train, percentage):
    labeled_idx = []
    for i in range(10):
        class_idx = np.where(y_train == i)[0]
        n_samples = max(1, int(len(class_idx) * percentage))
        selected_idx = np.random.choice(class_idx, n_samples, replace=False)
        labeled_idx.extend(selected_idx)
    
    x_labeled = x_train[labeled_idx]
    y_labeled = y_train[labeled_idx]
    unlabeled_idx = [i for i in range(len(x_train)) if i not in labeled_idx]
    x_unlabeled = x_train[unlabeled_idx]
    
    return x_labeled, y_labeled, x_unlabeled, unlabeled_idx

# Thuáº­t toÃ¡n Pseudo Labelling vá»›i Cross-Validation
def pseudo_labeling_with_mlflow(x_labeled, y_labeled, x_unlabeled, x_val, y_val, x_test, y_test, 
                              params, custom_model_name, show_details=False, cv_folds=5):
    if show_details:
        progress_bar = st.progress(0)
        status_text = st.empty()
        log_container = st.empty()
        log_text = ""
    else:
        log_text = ""
    
    with mlflow.start_run(run_name=custom_model_name):
        # Log parameters
        mlflow.log_params(params)
        
        x_train_current = x_labeled.copy()
        y_train_current = y_labeled.copy()
        remaining_unlabeled = x_unlabeled.copy()
        
        log_text += "âœ… **BÆ°á»›c 0**: Chia táº­p train/val/test hoÃ n táº¥t.\n"
        if show_details:
            log_container.text(log_text)
            progress_bar.progress(0.1)
            status_text.text("Äang khá»Ÿi táº¡o mÃ´ hÃ¬nh... (10%)")
        
        log_text += f"âœ… **BÆ°á»›c 1**: ÄÃ£ chá»n {len(x_labeled)} máº«u lÃ m táº­p labeled ban Ä‘áº§u ({params['initial_labeled_percentage']:.1f}%).\n"
        if show_details:
            log_container.text(log_text)
        
        for iteration in range(params["max_iterations"]):
            # Cross-validation
            kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)
            cv_scores = []
            
            for fold, (train_idx, val_idx) in enumerate(kf.split(x_train_current)):
                x_cv_train = x_train_current[train_idx]
                y_cv_train = y_train_current[train_idx]
                x_cv_val = x_train_current[val_idx]
                y_cv_val = y_train_current[val_idx]
                
                model = create_model(params["num_hidden_layers"], 
                                   params["neurons_per_layer"],
                                   params["activation"],
                                   params["learning_rate"])
                
                model.fit(x_cv_train, y_cv_train,
                         epochs=params["epochs"],
                         batch_size=32,
                         verbose=0)
                
                val_acc = model.evaluate(x_cv_val, y_cv_val, verbose=0)[1]
                cv_scores.append(val_acc)
            
            # Huáº¥n luyá»‡n trÃªn toÃ n bá»™ dá»¯ liá»‡u hiá»‡n táº¡i
            model = create_model(params["num_hidden_layers"], 
                               params["neurons_per_layer"],
                               params["activation"],
                               params["learning_rate"])
            
            history = model.fit(x_train_current, y_train_current,
                              epochs=params["epochs"],
                              batch_size=32,
                              verbose=0,
                              validation_data=(x_val, y_val))
            
            train_acc = history.history['accuracy'][-1]
            val_acc = history.history['val_accuracy'][-1]
            cv_mean_acc = np.mean(cv_scores)
            
            log_text += f"ğŸ”„ **Iteration {iteration+1}**: Huáº¥n luyá»‡n vá»›i {len(x_train_current)} máº«u.\n"
            log_text += f"ğŸ“Š Train acc: {train_acc:.4f}, Val acc: {val_acc:.4f}, CV mean acc: {cv_mean_acc:.4f}\n"
            if show_details:
                log_container.text(log_text)
            
            # Dá»± Ä‘oÃ¡n trÃªn unlabeled
            predictions = model.predict(remaining_unlabeled, verbose=0)
            max_probs = np.max(predictions, axis=1)
            pseudo_labels = np.argmax(predictions, axis=1)
            
            confident_idx = np.where(max_probs >= params["threshold"])[0]
            log_text += f"ğŸ“Œ GÃ¡n nhÃ£n giáº£ cho {len(confident_idx)} máº«u vá»›i ngÆ°á»¡ng {params['threshold']}.\n"
            if show_details:
                log_container.text(log_text)
                progress_bar.progress(0.5 + 0.4 * (iteration + 1) / params["max_iterations"])
                status_text.text(f"Iteration {iteration + 1}: ÄÃ£ gÃ¡n nhÃ£n cho {len(confident_idx)} máº«u ({int(50 + 40 * (iteration + 1) / params['max_iterations'])}%)")
            
            mlflow.log_metric("train_accuracy", train_acc, step=iteration)
            mlflow.log_metric("val_accuracy", val_acc, step=iteration)
            mlflow.log_metric("cv_mean_accuracy", cv_mean_acc, step=iteration)
            mlflow.log_metric("labeled_samples", len(confident_idx), step=iteration)
            
            if len(confident_idx) == 0:
                log_text += "â›” KhÃ´ng cÃ²n máº«u nÃ o vÆ°á»£t ngÆ°á»¡ng. Dá»«ng thuáº­t toÃ¡n.\n"
                break
                
            x_train_current = np.concatenate([x_train_current, remaining_unlabeled[confident_idx]])
            y_train_current = np.concatenate([y_train_current, pseudo_labels[confident_idx]])
            remaining_unlabeled = np.delete(remaining_unlabeled, confident_idx, axis=0)
            
            if len(remaining_unlabeled) == 0:
                log_text += "âœ… ÄÃ£ gÃ¡n nhÃ£n háº¿t dá»¯ liá»‡u unlabeled. Dá»«ng thuáº­t toÃ¡n.\n"
                break
        
        test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)
        mlflow.log_metric("test_accuracy", test_accuracy)
        mlflow.keras.log_model(model, "final_model")
        
        log_text += f"âœ… **ÄÃ¡nh giÃ¡ cuá»‘i**: Äá»™ chÃ­nh xÃ¡c trÃªn test set: {test_accuracy:.4f}\n"
        if show_details:
            log_container.text(log_text)
            progress_bar.progress(1.0)
            status_text.text("HoÃ n táº¥t! (100%)")
        
    return model, test_accuracy, log_text

# Xá»­ lÃ½ áº£nh táº£i lÃªn
def preprocess_uploaded_image(image):
    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    image = cv2.resize(image, (28, 28))
    image = image / 255.0
    return image.reshape(1, 28, 28)

# Xá»­ lÃ½ áº£nh tá»« canvas
def preprocess_canvas_image(canvas):
    image = np.array(canvas)
    image = cv2.cvtColor(image, cv2.COLOR_RGBA2GRAY)
    image = cv2.bitwise_not(image)
    image = cv2.resize(image, (28, 28))
    image = image / 255.0
    return image.reshape(1, 28, 28)

# Hiá»ƒn thá»‹ máº«u dá»¯ liá»‡u
def show_sample_images(X, y):
    st.write("**ğŸ–¼ï¸ Má»™t vÃ i máº«u dá»¯ liá»‡u tá»« MNIST**")
    fig, axes = plt.subplots(1, 10, figsize=(15, 3))
    for digit in range(10):
        idx = np.where(y == digit)[0][0]
        ax = axes[digit]
        ax.imshow(X[idx], cmap='gray')
        ax.set_title(f"{digit}")
        ax.axis('off')
    st.pyplot(fig)

# Giao diá»‡n Streamlit
def create_streamlit_app():
    st.title("ğŸ”¢ Pseudo Labelling trÃªn MNIST vá»›i Neural Network")
    
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ““ Giá»›i thiá»‡u", "ğŸ“‹ Huáº¥n luyá»‡n", "ğŸ”® Dá»± Ä‘oÃ¡n", "âš¡ MLflow"])
    
    with tab1:
        st.write("##### Pseudo Labelling vá»›i Neural Network")
        st.write(""" 
        **Pseudo Labelling** lÃ  má»™t ká»¹ thuáº­t há»c bÃ¡n giÃ¡m sÃ¡t sá»­ dá»¥ng dá»¯ liá»‡u cÃ³ nhÃ£n vÃ  khÃ´ng nhÃ£n Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t mÃ´ hÃ¬nh.
        \n CÃ¡c bÆ°á»›c chÃ­nh:
        1. Chia dá»¯ liá»‡u thÃ nh train/val/test
        2. Láº¥y má»™t pháº§n nhá» dá»¯ liá»‡u cÃ³ nhÃ£n ban Ä‘áº§u
        3. Huáº¥n luyá»‡n NN vÃ  dá»± Ä‘oÃ¡n nhÃ£n cho dá»¯ liá»‡u khÃ´ng nhÃ£n
        4. GÃ¡n nhÃ£n giáº£ cho cÃ¡c máº«u cÃ³ Ä‘á»™ tin cáº­y cao
        5. Láº·p láº¡i vá»›i táº­p dá»¯ liá»‡u má»Ÿ rá»™ng
        """)
    
    with tab2:
        x_train, y_train, x_val, y_val, _, _ = load_data()
        show_sample_images(x_train, y_train)
        
        st.write("##### Chia táº­p dá»¯ liá»‡u")
        train_split = st.slider("Tá»‰ lá»‡ dá»¯ liá»‡u train", 0.5, 0.9, 0.7, 0.05)
        val_split = st.slider("Tá»‰ lá»‡ dá»¯ liá»‡u validation", 0.05, 0.3, 0.15, 0.05)
        test_split = 1 - train_split - val_split
        if test_split < 0:
            st.error("Tá»•ng tá»‰ lá»‡ vÆ°á»£t quÃ¡ 100%! Vui lÃ²ng Ä‘iá»u chá»‰nh láº¡i.")
            return
        
        x_train, y_train, x_val, y_val, x_test, y_test = load_data(train_split, val_split)
        labeled_percentage = st.slider("Tá»‰ lá»‡ dá»¯ liá»‡u labeled ban Ä‘áº§u (%)", 0.1, 10.0, 1.0, 0.1)
        percentage = labeled_percentage / 100
        x_labeled, y_labeled, x_unlabeled, _ = select_initial_data(x_train, y_train, percentage)
        
        data = {
            "Táº­p dá»¯ liá»‡u": ["Táº­p train", "Táº­p validation", "Táº­p test", "Táº­p labeled ban Ä‘áº§u", "Táº­p unlabeled"],
            "Sá»‘ máº«u": [len(x_train), len(x_val), len(x_test), len(x_labeled), len(x_unlabeled)],
            "Tá»· lá»‡ (%)": [
                f"{train_split*100:.1f}%",
                f"{val_split*100:.1f}%",
                f"{test_split*100:.1f}%",
                f"{len(x_labeled)/len(x_train)*100:.1f}% cá»§a train",
                f"{len(x_unlabeled)/len(x_train)*100:.1f}% cá»§a train"
            ]
        }
        df = pd.DataFrame(data)
        st.write("**KÃ­ch thÆ°á»›c táº­p dá»¯ liá»‡u sau khi chia:**")
        st.table(df)
        
        st.write("##### Huáº¥n luyá»‡n mÃ´ hÃ¬nh Pseudo Labelling")
        custom_model_name = st.text_input("Nháº­p tÃªn mÃ´ hÃ¬nh:", "Default_model")
        params = {
            "threshold": st.slider("NgÆ°á»¡ng tin cáº­y", 0.5, 0.99, 0.95, 0.01),
            "max_iterations": st.slider("Sá»‘ vÃ²ng láº·p tá»‘i Ä‘a", 1, 20, 5),
            "num_hidden_layers": st.slider("Sá»‘ lá»›p áº©n", 1, 5, 2),
            "neurons_per_layer": st.slider("Sá»‘ neuron má»—i lá»›p", 50, 200, 100),
            "epochs": st.slider("Epochs", 5, 50, 10),
            "activation": st.selectbox("HÃ m kÃ­ch hoáº¡t", ["relu", "tanh", "sigmoid"]),
            "learning_rate": st.slider("Tá»‘c Ä‘á»™ há»c (learning rate)", 0.0001, 0.1, 0.001),
            "initial_labeled_percentage": labeled_percentage
        }
        st.session_state.cv_folds = st.slider("Sá»‘ lÆ°á»£ng fold cho Cross-Validation", 2, 10, 5)
        
        show_details = st.checkbox("Hiá»ƒn thá»‹ chi tiáº¿t quÃ¡ trÃ¬nh huáº¥n luyá»‡n", value=False)
        
        if st.button("ğŸš€ Cháº¡y Pseudo Labelling"):
            with st.spinner("ğŸ”„ Äang khá»Ÿi táº¡o huáº¥n luyá»‡n..."):
                model, test_accuracy, log_text = pseudo_labeling_with_mlflow(
                    x_labeled, y_labeled, x_unlabeled, x_val, y_val, x_test, y_test,
                    params, custom_model_name, show_details, st.session_state.cv_folds
                )
                st.session_state['model'] = model
            
            st.success(f"âœ… Huáº¥n luyá»‡n xong! Äá»™ chÃ­nh xÃ¡c trÃªn test: {test_accuracy:.4f}")
            if show_details:
                st.text(log_text)
    
    with tab3:
        st.write("**ğŸ”® Dá»± Ä‘oÃ¡n chá»¯ sá»‘**")
        if 'model' not in st.session_state:
            st.warning("Vui lÃ²ng huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c á»Ÿ tab Huáº¥n luyá»‡n!")
        else:
            option = st.radio("ğŸ–¼ï¸ Chá»n phÆ°Æ¡ng thá»©c nháº­p:", ["ğŸ“‚ Táº£i áº£nh lÃªn", "âœï¸ Váº½ sá»‘"])
            
            if option == "ğŸ“‚ Táº£i áº£nh lÃªn":
                uploaded_file = st.file_uploader("ğŸ“¤ Táº£i áº£nh sá»‘ viáº¿t tay (PNG, JPG)", type=["png", "jpg", "jpeg"])
                if uploaded_file is not None:
                    image = cv2.imdecode(np.frombuffer(uploaded_file.read(), np.uint8), cv2.IMREAD_COLOR)
                    processed_image = preprocess_uploaded_image(image)
                    st.image(image, caption="ğŸ“· áº¢nh táº£i lÃªn", width=200)
                    
                    if st.button("ğŸ”® Dá»± Ä‘oÃ¡n"):
                        model = st.session_state['model']
                        prediction = model.predict(processed_image)
                        predicted_digit = np.argmax(prediction)
                        confidence = np.max(prediction)
                        st.write(f"ğŸ¯ **Dá»± Ä‘oÃ¡n: {predicted_digit}**")
                        st.write(f"ğŸ”¢ **Äá»™ tin cáº­y: {confidence * 100:.2f}%**")
            
            elif option == "âœï¸ Váº½ sá»‘":
                canvas_result = st_canvas(
                    fill_color="white", stroke_width=15, stroke_color="black",
                    background_color="white", width=280, height=280, drawing_mode="freedraw", key="canvas"
                )
                if st.button("ğŸ”® Dá»± Ä‘oÃ¡n"):
                    if canvas_result.image_data is not None:
                        processed_canvas = preprocess_canvas_image(canvas_result.image_data)
                        model = st.session_state['model']
                        prediction = model.predict(processed_canvas)
                        predicted_digit = np.argmax(prediction)
                        confidence = np.max(prediction)
                        st.write(f"ğŸ¯ **Dá»± Ä‘oÃ¡n: {predicted_digit}**")
                        st.write(f"ğŸ”¢ **Äá»™ tin cáº­y: {confidence * 100:.2f}%**")
    
    with tab4:
        st.write("##### MLflow Tracking")
        
        runs = mlflow.search_runs(order_by=["start_time desc"])
        if not runs.empty:
            runs["model_custom_name"] = runs["tags.mlflow.runName"]
            
            search_model_name = st.text_input("ğŸ” Nháº­p tÃªn mÃ´ hÃ¬nh Ä‘á»ƒ tÃ¬m kiáº¿m:", "")
            if search_model_name:
                filtered_runs = runs[runs["model_custom_name"].str.contains(search_model_name, case=False, na=False)]
            else:
                filtered_runs = runs
            
            if not filtered_runs.empty:
                st.write("##### ğŸ“œ Danh sÃ¡ch mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u:")
                available_columns = [col for col in [
                    "model_custom_name", "start_time",
                    "metrics.train_accuracy", "metrics.val_accuracy", "metrics.test_accuracy",
                    "metrics.cv_mean_accuracy", "metrics.labeled_samples"
                ] if col in filtered_runs.columns]
                display_df = filtered_runs[available_columns]
                display_df = display_df.rename(columns={"model_custom_name": "Custom Model Name"})
                st.dataframe(display_df)
                
                selected_model_name = st.selectbox("ğŸ“ Chá»n má»™t mÃ´ hÃ¬nh Ä‘á»ƒ xem chi tiáº¿t:",
                                                  filtered_runs["model_custom_name"].tolist())
                if selected_model_name:
                    selected_run = filtered_runs[filtered_runs["model_custom_name"] == selected_model_name].iloc[0]
                    run_details = mlflow.get_run(selected_run["run_id"])
                    custom_name = run_details.data.tags.get('mlflow.runName', 'KhÃ´ng cÃ³ tÃªn')
                    st.write(f"##### ğŸ” Chi tiáº¿t mÃ´ hÃ¬nh: `{custom_name}`")
                    
                    st.write("ğŸ“Œ **Tham sá»‘:**")
                    for key, value in run_details.data.params.items():
                        st.write(f"- **{key}**: {value}")
                    
                    st.write("ğŸ“Š **Metric:**")
                    for key, value in run_details.data.metrics.items():
                        st.write(f"- **{key}**: {value}")
            else:
                st.write("âŒ KhÃ´ng tÃ¬m tháº¥y mÃ´ hÃ¬nh nÃ o.")
        else:
            st.write("âš ï¸ KhÃ´ng cÃ³ phiÃªn lÃ m viá»‡c nÃ o Ä‘Æ°á»£c ghi láº¡i.")

if __name__ == "__main__":
    mlflow.set_tracking_uri("http://localhost:5000")  # Cáº­p nháº­t náº¿u cáº§n
    create_streamlit_app()
