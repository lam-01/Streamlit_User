import streamlit as st
import mlflow
import mlflow.sklearn
import numpy as np
import cv2
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from streamlit_drawable_canvas import st_canvas
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics.pairwise import cosine_similarity
from streamlit_tags import st_tags
import io
import os
import tempfile
import runpy

# üìå T·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu MNIST t·ª´ OpenML
@st.cache_data
def load_data():
    mnist = fetch_openml("mnist_784", version=1, as_frame=False)
    X, y = mnist.data, mnist.target.astype(int)  # Chuy·ªÉn nh√£n v·ªÅ ki·ªÉu s·ªë nguy√™n
    X = X / 255.0  # Chu·∫©n h√≥a v·ªÅ [0,1]
    return X, y

# üìå Chia d·ªØ li·ªáu th√†nh train, validation, v√† test
@st.cache_data
def split_data(X, y, train_size=0.7, val_size=0.15, test_size=0.15, random_state=42):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X_train, y_train, test_size=val_size / (train_size + val_size), random_state=random_state
    )
    return X_train, X_val, X_test, y_train, y_val, y_test

# üìå Hu·∫•n luy·ªán m√¥ h√¨nh
def train_model(custom_model_name, model_name, params, X_train, X_val, X_test, y_train, y_val, y_test):
    if model_name == "Decision Tree":
        model = DecisionTreeClassifier(
            max_depth=params["max_depth"],
            min_samples_split=params["min_samples_split"],
            min_samples_leaf=params["min_samples_leaf"],
            criterion=params["criterion"],
            random_state=42
        )
    elif model_name == "SVM":
        model = SVC(
            kernel=params["kernel"],
            C=params["C"],
            probability=True
        )
    elif model_name="Neural Network":
        model = MLPClassifier(
        hidden_layer_sizes=(params["hidden_layer_size"],),
        max_iter=params["max_iter"],
        activation=params["activation"],
        solver=params["solver"],
        learning_rate_init=params["learning_rate"],
        random_state=42
    )
    else:
        raise ValueError("Invalid model selected!")

    model.fit(X_train, y_train)

    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)
    y_val_pred = model.predict(X_val)
    train_accuracy = accuracy_score(y_train, y_train_pred)
    val_accuracy = accuracy_score(y_val, y_val_pred)
    test_accuracy = accuracy_score(y_test, y_test_pred)
    
    with mlflow.start_run(run_name=custom_model_name):
        mlflow.log_param("model_name", model_name)
        mlflow.log_metric("train_accuracy", train_accuracy)
        mlflow.log_metric("val_accuracy", val_accuracy)
        mlflow.log_metric("test_accuracy", test_accuracy)
        mlflow.sklearn.log_model(model, model_name)
    
    return model, train_accuracy, val_accuracy, test_accuracy

# üìå X·ª≠ l√Ω ·∫£nh t·∫£i l√™n
def preprocess_uploaded_image(image):
    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    image = cv2.resize(image, (28, 28))
    image = image / 255.0
    return image.reshape(1, -1)

# üìå X·ª≠ l√Ω ·∫£nh t·ª´ v·∫Ω tay tr√™n canvas
def preprocess_canvas_image(canvas):
    image = np.array(canvas)
    image = cv2.cvtColor(image, cv2.COLOR_RGBA2GRAY)
    image = cv2.bitwise_not(image)
    image = cv2.resize(image, (28, 28))
    image = image / 255.0
    return image.reshape(1, -1)

def show_sample_images(X, y):
    st.write("**üñºÔ∏è M·ªôt v√†i m·∫´u d·ªØ li·ªáu t·ª´ MNIST**")
    fig, axes = plt.subplots(1, 10, figsize=(15, 3))
    for digit in range(10):
        idx = np.where(y == digit)[0][0]
        ax = axes[digit]
        ax.imshow(X[idx].reshape(28, 28), cmap='gray')
        ax.set_title(f"{digit}")
        ax.axis('off')
    st.pyplot(fig)

# üìå Giao di·ªán Streamlit
def create_streamlit_app():
    st.title("üî¢ Ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay")
    
    X, y = load_data()
    tab1, tab2, tab3 = st.tabs(["üìã Hu·∫•n luy·ªán", "üîÆ D·ª± ƒëo√°n", "‚ö° Mlflow"])
    
    with tab1:
        st.write(f"**S·ªë l∆∞·ª£ng m·∫´u c·ªßa b·ªô d·ªØ li·ªáu MNIST : {X.shape[0]}**")
        show_sample_images(X, y)
        
        st.write("**üìä T·ª∑ l·ªá d·ªØ li·ªáu**")
        test_size = st.slider("T·ª∑ l·ªá Test (%)", min_value=5, max_value=30, value=15, step=5)
        val_size = st.slider("T·ª∑ l·ªá Validation (%)", min_value=5, max_value=30, value=15, step=5)
        
        train_size = 100 - test_size
        val_ratio = val_size / train_size
        
        if val_ratio >= 1.0:
            st.error("T·ª∑ l·ªá Validation qu√° l·ªõn so v·ªõi Train! Vui l√≤ng ƒëi·ªÅu ch·ªânh l·∫°i.")
        else:
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size/100, random_state=42)
            X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_ratio, random_state=42)
        
            data_ratios = pd.DataFrame({
                "T·∫≠p d·ªØ li·ªáu": ["Train", "Validation", "Test"],
                "T·ª∑ l·ªá (%)": [train_size - val_size, val_size, test_size],
                "S·ªë l∆∞·ª£ng m·∫´u": [len(X_train), len(X_val), len(X_test)]
            })
            st.table(data_ratios)

        st.write("**üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh**")
        custom_model_name = st.text_input("Nh·∫≠p t√™n m√¥ h√¨nh ƒë·ªÉ l∆∞u v√†o MLflow:")
        model_name = st.selectbox("üîç Ch·ªçn m√¥ h√¨nh", ["Decision Tree", "SVM"])
        params = {}

        if model_name == "Decision Tree":
            params["criterion"] = st.selectbox("üìè Ti√™u ch√≠ ƒë√°nh gi√°", ["gini", "entropy", "log_loss"], help="""- **Gini impurity** ƒëo l∆∞·ªùng x√°c su·∫•t m·ªôt m·∫´u ƒë∆∞·ª£c ch·ªçn ng·∫´u nhi√™n t·ª´ t·∫≠p d·ªØ li·ªáu b·ªã ph√¢n lo·∫°i sai 
            n·∫øu n√≥ ƒë∆∞·ª£c g√°n nh√£n ng·∫´u nhi√™n theo ph√¢n ph·ªëi c·ªßa c√°c l·ªõp trong t·∫≠p d·ªØ li·ªáu.
            \n- **Entropy** ƒëo l∆∞·ªùng m·ª©c ƒë·ªô h·ªón lo·∫°n ho·∫∑c kh√¥ng ch·∫Øc ch·∫Øn trong t·∫≠p d·ªØ li·ªáu. N√≥ d·ª±a tr√™n kh√°i ni·ªám entropy trong l√Ω thuy·∫øt th√¥ng tin.
            \n- **Log loss (hay cross-entropy)** ƒëo l∆∞·ªùng s·ª± kh√°c bi·ªát gi·ªØa ph√¢n ph·ªëi x√°c su·∫•t th·ª±c t·∫ø v√† ph√¢n ph·ªëi x√°c su·∫•t d·ª± ƒëo√°n. N√≥ th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng trong c√°c b√†i to√°n ph√¢n lo·∫°i x√°c su·∫•t.
            """)
            params["max_depth"] = st.slider("üå≥ ƒê·ªô s√¢u t·ªëi ƒëa (max_depth)", 1, 30, 15, help="""- **max_depth** l√† tham s·ªë gi·ªõi h·∫°n ƒë·ªô s√¢u t·ªëi ƒëa c·ªßa c√¢y quy·∫øt ƒë·ªãnh. ƒê·ªô s√¢u c·ªßa c√¢y ƒë∆∞·ª£c t√≠nh 
            t·ª´ n√∫t g·ªëc (root) ƒë·∫øn n√∫t l√° (leaf) xa nh·∫•t.
            \n N·∫øu (max_depth > 25) qu√° l·ªõn, c√¢y c√≥ th·ªÉ tr·ªü n√™n ph·ª©c t·∫°p v√† d·ªÖ b·ªã overfitting (h·ªçc thu·ªôc d·ªØ li·ªáu hu·∫•n luy·ªán nh∆∞ng k√©m hi·ªáu qu·∫£ tr√™n d·ªØ li·ªáu m·ªõi).
            \n N·∫øu (max_depth < 10) qu√° nh·ªè, c√¢y c√≥ th·ªÉ qu√° ƒë∆°n gi·∫£n v√† d·∫´n ƒë·∫øn underfitting (kh√¥ng h·ªçc ƒë∆∞·ª£c ƒë·ªß th√¥ng tin t·ª´ d·ªØ li·ªáu).""")
            params["min_samples_split"] = st.slider("üîÑ S·ªë m·∫´u t·ªëi thi·ªÉu ƒë·ªÉ chia nh√°nh (min_samples_split)", 2, 10, 5, help="""
            \n- **min_samples_split** l√† s·ªë l∆∞·ª£ng m·∫´u t·ªëi thi·ªÉu c·∫ßn thi·∫øt ƒë·ªÉ chia m·ªôt n√∫t (node) th√†nh c√°c n√∫t con. N·∫øu s·ªë l∆∞·ª£ng m·∫´u t·∫°i m·ªôt n√∫t √≠t h∆°n gi√° tr·ªã n√†y, n√∫t ƒë√≥ s·∫Ω kh√¥ng ƒë∆∞·ª£c chia ti·∫øp.
            \n Gi√° tr·ªã l·ªõn h∆°n (5-10) gi√∫p ngƒÉn ch·∫∑n vi·ªác chia nh√°nh qu√° m·ª©c, t·ª´ ƒë√≥ gi·∫£m nguy c∆° overfitting.
            \n Gi√° tr·ªã nh·ªè h∆°n (2-4) cho ph√©p c√¢y chia nh√°nh nhi·ªÅu h∆°n, nh∆∞ng c√≥ th·ªÉ d·∫´n ƒë·∫øn c√¢y ph·ª©c t·∫°p h∆°n.
            
            """)
            params["min_samples_leaf"] = st.slider("üçÉ S·ªë m·∫´u t·ªëi thi·ªÉu ·ªü l√° (min_samples_leaf)", 1, 10, 2, help="""
            \n- **min_samples_leaf** l√† s·ªë l∆∞·ª£ng m·∫´u t·ªëi thi·ªÉu c·∫ßn thi·∫øt t·∫°i m·ªói n√∫t l√° (leaf node). N·∫øu m·ªôt ph√¢n chia d·∫´n ƒë·∫øn m·ªôt l√° c√≥ √≠t m·∫´u h∆°n gi√° tr·ªã n√†y, ph√¢n chia ƒë√≥ s·∫Ω kh√¥ng ƒë∆∞·ª£c th·ª±c hi·ªán.
            \n Gi√° tr·ªã l·ªõn h∆°n (5-10) gi√∫p ngƒÉn ch·∫∑n vi·ªác t·∫°o ra c√°c l√° qu√° nh·ªè, t·ª´ ƒë√≥ gi·∫£m nguy c∆° overfitting.
            \n Gi√° tr·ªã nh·ªè h∆°n (1-4) cho ph√©p c√¢y t·∫°o ra c√°c l√° nh·ªè h∆°n, nh∆∞ng c√≥ th·ªÉ d·∫´n ƒë·∫øn c√¢y ph·ª©c t·∫°p h∆°n.
            """)
        elif model_name == "SVM":
            params["kernel"] = st.selectbox("‚öôÔ∏è Kernel", ["linear", "rbf", "poly", "sigmoid"], help="...")
            params["C"] = st.slider("üîß Tham s·ªë C ", 0.1, 10.0, 1.0, help="...")
        elif model_name=="Neural Network":
            params["hidden_layer_size"] = st.slider("K√≠ch th∆∞·ªõc t·∫ßng ·∫©n", 50, 200, 100, help="S·ªë n∆°-ron trong t·∫ßng ·∫©n.")
            params["max_iter"] = st.slider("S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa", 5, 50, 10, help="S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa ƒë·ªÉ hu·∫•n luy·ªán.")
            params["activation"] = st.selectbox("H√†m k√≠ch ho·∫°t", ["relu", "tanh", "logistic"], help="H√†m k√≠ch ho·∫°t cho c√°c n∆°-ron.")
            params["solver"] = st.selectbox("B·ªô gi·∫£i t·ªëi ∆∞u", ["adam", "sgd"], help="B·ªô gi·∫£i t·ªëi ∆∞u h√≥a tr·ªçng s·ªë.")
            params["learning_rate"] = st.slider("T·ªëc ƒë·ªô h·ªçc", 0.0001, 0.01, 0.001, format="%.4f", help="T·ªëc ƒë·ªô h·ªçc ban ƒë·∫ßu.")


        if st.button("üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh"):
            with st.spinner("üîÑ ƒêang hu·∫•n luy·ªán..."):
                model, train_accuracy, val_accuracy, test_accuracy = train_model(
                    custom_model_name, model_name, params, X_train, X_val, X_test, y_train, y_val, y_test
                )
            st.success(f"‚úÖ Hu·∫•n luy·ªán xong!")
            st.write(f"üéØ **ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p train: {train_accuracy:.4f}**")
            st.write(f"üéØ **ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p validation: {val_accuracy:.4f}**")
            st.write(f"üéØ **ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p test: {test_accuracy:.4f}**")

    with tab2:
        option = st.radio("üñºÔ∏è Ch·ªçn ph∆∞∆°ng th·ª©c nh·∫≠p:", ["üìÇ T·∫£i ·∫£nh l√™n", "‚úèÔ∏è V·∫Ω s·ªë"])
        if option == "üìÇ T·∫£i ·∫£nh l√™n":
            uploaded_file = st.file_uploader("üì§ T·∫£i ·∫£nh s·ªë vi·∫øt tay (PNG, JPG)", type=["png", "jpg", "jpeg"])
            if uploaded_file is not None:
                image = cv2.imdecode(np.frombuffer(uploaded_file.read(), np.uint8), cv2.IMREAD_COLOR)
                processed_image = preprocess_uploaded_image(image)
                st.image(image, caption="üì∑ ·∫¢nh t·∫£i l√™n", use_column_width=True)
                if st.button("üîÆ D·ª± ƒëo√°n"):
                    model, train_accuracy, val_accuracy, test_accuracy = train_model(
                        custom_model_name, model_name, params, X_train, X_val, X_test, y_train, y_val, y_test
                    )
                    prediction = model.predict(processed_image)[0]
                    probabilities = model.predict_proba(processed_image)[0]
                    st.write(f"üéØ **D·ª± ƒëo√°n: {prediction}**")
                    st.write(f"üî¢ **ƒê·ªô tin c·∫≠y: {probabilities[prediction] * 100:.2f}%**")
        elif option == "‚úèÔ∏è V·∫Ω s·ªë":
            canvas_result = st_canvas(
                fill_color="white", stroke_width=15, stroke_color="black",
                background_color="white", width=280, height=280, drawing_mode="freedraw", key="canvas"
            )
            if st.button("üîÆ D·ª± ƒëo√°n"):
                if canvas_result.image_data is not None:
                    processed_canvas = preprocess_canvas_image(canvas_result.image_data)
                    model, train_accuracy, val_accuracy, test_accuracy = train_model(
                        custom_model_name, model_name, params, X_train, X_val, X_test, y_train, y_val, y_test
                    )
                    prediction = model.predict(processed_canvas)[0]
                    probabilities = model.predict_proba(processed_canvas)[0]
                    st.write(f"üéØ **D·ª± ƒëo√°n: {prediction}**")
                    st.write(f"üî¢ **ƒê·ªô tin c·∫≠y: {probabilities[prediction] * 100:.2f}%**")

    with tab3:
        st.header("üìä MLflow Tracking")
        st.write("Xem chi ti·∫øt c√°c k·∫øt qu·∫£ ƒë√£ l∆∞u trong MLflow.")

        runs = mlflow.search_runs(order_by=["start_time desc"])
        if not runs.empty:
            runs["model_custom_name"] = runs["tags.mlflow.runName"]
            model_names = runs["model_custom_name"].dropna().unique().tolist()

            search_model_name = st.text_input("üîç Nh·∫≠p t√™n m√¥ h√¨nh ƒë·ªÉ t√¨m ki·∫øm:", "")
            if search_model_name:
                filtered_runs = runs[runs["model_custom_name"].str.contains(search_model_name, case=False, na=False)]
            else:
                filtered_runs = runs

            if not filtered_runs.empty:
                st.write("### üìú Danh s√°ch m√¥ h√¨nh ƒë√£ l∆∞u:")
                # Th√™m c·ªôt params.model_name v√†o b·∫£ng v√† ƒë·ªïi t√™n th√†nh "Model Type"
                display_df = filtered_runs[["model_custom_name", "params.model_name", "run_id", "start_time", 
                                           "metrics.train_accuracy", "metrics.val_accuracy", "metrics.test_accuracy"]]
                display_df = display_df.rename(columns={
                    "model_custom_name": "Custom Model Name",
                    "params.model_name": "Model Type"
                })
                st.dataframe(display_df)

                selected_run_id = st.selectbox("üìù Ch·ªçn m·ªôt m√¥ h√¨nh ƒë·ªÉ xem chi ti·∫øt:", filtered_runs["run_id"].tolist())
                if selected_run_id:
                    run_details = mlflow.get_run(selected_run_id)
                    custom_name = run_details.data.tags.get('mlflow.runName', 'Kh√¥ng c√≥ t√™n')
                    model_type = run_details.data.params.get('model_name', 'Kh√¥ng x√°c ƒë·ªãnh')
                    st.write(f"### üîç Chi ti·∫øt m√¥ h√¨nh: `{custom_name}`")
                    st.write(f"**üìå Lo·∫°i m√¥ h√¨nh hu·∫•n luy·ªán:** {model_type}")

                    st.write("üìå **Tham s·ªë:**")
                    for key, value in run_details.data.params.items():
                        if key != 'model_name':  # ƒê√£ hi·ªÉn th·ªã model_name ·ªü tr√™n
                            st.write(f"- **{key}**: {value}")

                    st.write("üìä **Metric:**")
                    for key, value in run_details.data.metrics.items():
                        st.write(f"- **{key}**: {value}")

                    st.write("üìÇ **Artifacts:**")
                    if run_details.info.artifact_uri:
                        st.write(f"- **Artifact URI**: {run_details.info.artifact_uri}")
                    else:
                        st.write("- Kh√¥ng c√≥ artifacts n√†o.")
            else:
                st.write("‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh n√†o.")
        else:
            st.write("‚ö†Ô∏è Kh√¥ng c√≥ phi√™n l√†m vi·ªác n√†o ƒë∆∞·ª£c ghi l·∫°i.")

if __name__ == "__main__":
    create_streamlit_app()
